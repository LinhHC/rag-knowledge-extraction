[
    {
        "query": "What is the \u03b1-algorithm?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 18\n\u03b1-algorithm\nThe \u03b1-algorithmis a basicalgorithm for discovering process models from event logsIt is less complex than other advanced algorithmsIt will not be sufficient for practical application\nIdea is to identify the relations between all pairs of tasks from the workflow log to construct a process model\nDumas et al. (2018), van der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 31\nProblems with the \u03b1-Algorithm\nShort loopsa\u2192b, b\u2192ais not always (a \u01c1b) Incompleteness andnoiseFor 10 concurrent tasks, we need 10! = 3,628,800 casesMissing tasks\n Dumas et al. (2018)",
            "A-priori AlgorithmIdea\nThe A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database.The algorithm searches for all rules that have a high confidencevalue. It must now be taken into account that the important confidence of a rule is also expressed by its support values. Thus applies: Let X be an item set from the population of all items I and X\u2018 \u00ccX, then:",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 9\nA-priori AlgorithmIdea",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 27\n\u03b1-Algorithm Steps (2)\n5.Construct the asubsetby1.Eliminating a\u2192band a\u2192cif there exists some a\u2192(b#c)2.Eliminating b\u2192cand b\u2192dif there exists some (b#c)\u2192d",
            "\u03b1-Algorithm Steps (3)\n7.Construct the flow arcs in the following way1.Pattern (a): For each a\u2192b, draw an arc a to b2.Pattern (b): For each a \u2192(b#c), draw an arc from a to an XOR-split, and from there to b and c3.Pattern (c): For each (b#c)\u2192d, draw an arc from b and c to an XOR-join, and from there to d4.Pattern (d) and (e): If a task in the so constructed process model has multiple incoming or multiple outgoing arcs, bundle these arcs with an AND-splitor AND-join, respectively",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 28\n\u03b1-Algorithm Steps (3)",
            "-A-priori Algorithm-A-priori-Tid algorithm-A-priori-Hybrid Algorithm-AIS algorithmThe procedures have in common that they are often used as starting procedures in the data mining, since no assumptions are necessary to the connections of the data, which things could correlate e.g. (undirected data mining).\nNote: 100 itemsresultin generally(100 overk) item combinations.-2-itemsets: 4,950 combinations-3-itemsets: 161,700 combinations-5-itemsets: 75.287.520 combinations",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 11\nA-priori AlgorithmFrequent setsofitems\u2013Part I"
        ],
        "generated": "The \u03b1-algorithm is a basic algorithm for discovering process models from event logs. It is less complex than other advanced algorithms but may not be sufficient for practical application. The idea behind the \u03b1-algorithm is to identify the relations between all pairs of tasks from the workflow log to construct a process model.",
        "ground_truth": "The \u03b1-algorithm is a basic algorithm for discovering process models from event logs."
    },
    {
        "query": "What types of layers are in CNN?",
        "retrieved": [
            "Convolutional Neural Network: Overview\nStack layers to build a complete CNNOne type of layer is the previously mentioned \u201econvolutional layer\u201cIn total there are 4 types of layers:\u00a7Convolutional Layer (Extract features)\u00a7Pooling Layer (Reduce size)\u00a7ReLU Layer (Remove negative values \u00e0 disregard information about missing features)\u00a7Fully Connected Layer (Classify features)",
            "Our CNN Architecture contains multiple layer types:\u00a7Conv2D: CNN Layer with 32 filters, shape 3x3 with ReLU Layer appended\u00a7MaxPooling2D: Pooling layer with shape 3x3\u00a7Dropout: Randomly drop 20% of neurons to prevent overfitting\u00a7Flatten: Prepare filter results for classification\u00a7Dense: Fully connected layers for classificationfrom keras.models import Sequentialfrom keras.layers import Dense, Flatten, Dropoutfrom keras.layers import Conv2D, MaxPooling2Dmodel = Sequential()model.add(Conv2D(32, (3,",
            "Deep Learning\nConvolutional Neural Networks",
            "Deep Learning\nConvolutional Neural Networks - MNIST",
            "References & WebLinks\n\u00a7GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A.:Deep Learning (2016), P.330ff.\u00a7LECUN, YANN; BENGIO, YOSHUA: Convolutional Networks for Images, Speech, and Time-Series. In M. A. Arbib(Ed.),The handbook of brain theory and neural networksMIT Press (1995).\u00a7ROHRER, BRANDON: How Convolutional Neural Networks work. https://www.youtube.com/watch?v=FmpDIaiMIeA\u00a7STANFORDCS231NCLASSNOTES: Convolutional Neural Networks for Visual Recognition: http://cs231n.github.io/convolutional-networks/",
            "refers  to  the  use  of  multiple  layers  (ranging  from  three  to  several  hundred  or\nthousands) in the network. Methods used can be either supervised, semi-supervised or\nunsupervised.[2]\nSome common deep learning network architectures include fully connected networks,\ndeep  belief  networks,  recurrent  neural  networks,  convolutional  neural  networks,\ngenerative  adversarial  networks,  transformers,  and  neural  radiance  fields.  These",
            "The success in image classification was then extended to the more challenging task of\ngenerating  descriptions  (captions)  for  images,  often  as  a  combination  of  CNNs  and\nLSTMs.[123][124][125]\nIn  2014,  the  state  of  the  art  was  training  \u201cvery  deep  neural  network\u201d  with  20  to  30\nlayers.[126]  Stacking  too  many  layers  led  to  a  steep  reduction  in  training\naccuracy,[127]  known  as  the  \"degradation\"  problem.[128]  In  2015,  two  techniques",
            "layer may attempt to identify basic shapes such as lines and circles, the second layer\nmay compose and encode arrangements of edges, the third layer may encode a nose\nand eyes, and the fourth layer may recognize that the image contains a face.\nImportantly,  a  deep  learning  process  can  learn  which  features  to  optimally  place  at\nwhich  level  on  its  own.  Prior  to  deep  learning,  machine  learning  techniques  often",
            "Deep learning architectures for convolutional neural networks (CNNs) with convolutional\nlayers and downsampling layers began with the Neocognitron introduced by Kunihiko\nFukushima in 1979, though not trained by backpropagation.[45][46]\nBackpropagation  is  an  efficient  application  of  the  chain  rule  derived  by  Gottfried\nWilhelm  Leibniz  in  1673[47]  to  networks  of  differentiable  nodes.  The  terminology",
            "Convolutional Layer\nAccepts input of size !!\u00d7#!\u00d7$!(width times height times number of color channels for images)Requires four hyperparameters:\u00a7Number of filters %\u00a7Their spatial extent (receptive field) &\u00a7The stride '\u00a7The amount of zero padding (Produces an output of size: !\"\u00d7#\"\u00d7$\"-!\"=#!$%&\"'(++ -#\"=)!$%&\"'(++-$\"=%Number of weights: &\u2217&\u2217$!\u2217%Common values for hyperparameters: -=3,0=1,2=1"
        ],
        "generated": "The types of layers in a Convolutional Neural Network (CNN) are:\n1. Convolutional Layer (Extract features)\n2. Pooling Layer (Reduce size)\n3. ReLU Layer (Remove negative values)\n4. Fully Connected Layer (Classify features)",
        "ground_truth": "Convolution Layer, Pooling Layer, ReLu Layer, Fully Connected Layer."
    },
    {
        "query": "What is the definition of a data scientist from Davenport & Patil (2012)?",
        "retrieved": [
            "of these areas.\u201d\nDhar (2013) \u201crequires an integrated skill set spanning mathematics, machine learning, artificial\nintelligence, statistics, databases, and optimization, along with a deep understanding of the\ncraft of problem formulation to engineer effective solutions.\u201d\nDavenport & Patil (2012) \u201cthe people who understand how to fish out answers to important business questions from\ntoday\u2019s tsunami of unstructured information.\u201d",
            "Data Science: Advanced Analytics\nIntroduction",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 5\nA Definition of Data Scienceby Provost & Fawcett (2013)\nTo understand Data Science, it requires to understand the 1) principles, 2) concepts, 3) techniques, 4) technologies and5) processes behind it!",
            "Data Science: Advanced Analytics\nContent",
            "\u201cExtracting useful knowledge from data to solve business problems can be treated systematicallyby following a  process with reasonably well-defined stages.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 20\nSome Definitions\u2026 \u2026 collected by Chatfield et al. (2014)\nSource Definition: Data scientists are \u2026\nGranville (2014) \u201cnot statisticians, nor data analysts, nor computer scientists, nor software engineers, nor\nbusiness analysts. They have some knowledge in each of these areas but also some outside\nof these areas.\u201d",
            "explore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "classification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,",
            "Structuring the Field:3) Data Science Techniques",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 8\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nCritical consideration on the application in questionExample questions:Does the pattern lead to better decisions than some reasonable alternative?How well would one have done by chance? How well would one do with a smart \u2018\u2018default\u2019\u2019 alternative?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 7\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\n1.Structured approach towards analytical problem2.Careful analysis of the problemExamples of common process/ procedure models:Knowledge Discovery in Databases (KDD)Sample, Explore, Modify, Model, Asess (SEMMA)More details later\u2026"
        ],
        "generated": "According to Davenport & Patil (2012), a data scientist is described as \"the people who understand how to fish out answers to important business questions from today\u2019s tsunami of unstructured information.\"",
        "ground_truth": "Data scientists are the people who understand how to fish out answers to important business questions from today\u2019s tsunami of unstructured information."
    },
    {
        "query": "What is text mining?",
        "retrieved": [
            "From a process perspective, text mining includes both the collection and preparation of texts and the exploitation of the results.Analysis techniques are used to evaluate and generate the text mining results.\nThe processing and analysis steps are integrated as functions in application systems.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 7\nDefinition of Text MiningUnderstanding of terms in the context of the lecture\nSources: Schieber & Hilbert (2014c), p. 13\nThe term text mining refers to the analytical process for computer-assisted knowledge generation from text data.",
            "Many text mining techniques have their origins in data mining, and often classical data mining techniques can also be applied to text data, provided that the data is available in a suitable structure.In the literature, the vector space model according to Salton et al. (1975) is mostly used for this purpose, whereby the text data areavailable in a structured tabular form:Terms and documents are transformed into a matrixThe lines list the termsIn the columns the documents are listedThe",
            "The processing and analysis steps are integrated as functions in application systems.\nText data can be both internal and external to the company; in the context of data processing, one also speaks of unstructured data.The goal of text mining is to generate new knowledge to be translated into action.",
            "Text Mining\nProceduremodel: Text miningprocedure",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 6\nDefinition of Text MiningUnderstanding of the term in the literature\nSources: Schieber & Hilbert (2014c), p. 13\nInformation extraction\n\u2022Extraction of passages from texts\u2022Annotation of these passages with attributes\u2022Ex: \u2022Recognition of companies and people\u2022Assignment of functions of a person in the company\u2022Source: Hotho et al. (2005), p. 45ff.\nAnalysis method",
            "Text mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff.",
            "Text Mining in the Big Data EnvironmentThe amount of available texts increases extremely in Web 2.0 (keyword: user-generated content)Social networks, forums and blogs can be interesting sources for product improvements, marketing activities or opinion analysisText processing and analysis is very computationally intensive even for a few documentsBig Data technologies enable high-performance and scalable analysis systemsEx: Hadoop-based systemsDistributed File Systems (Hadoop Distributed File",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 21\nThe text mining process at a glance"
        ],
        "generated": "Text mining refers to the analytical process for computer-assisted knowledge generation from text data.",
        "ground_truth": "The term text mining refers to the analytical process for computer-assisted knowledge generation from text data."
    },
    {
        "query": "What are the four quality criteria?",
        "retrieved": [
            "Basics ofsegmentation\nEvaluation criteria",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "In this step, it is checked whether the initial question could be answered by the text mining process. Here are assessthe results from the upstream step of applying the analytical methods using quality criteria appropriate to the method, andMatch the results from the upstream step of applying the analysis procedures with the problem definitionIf the check is positive, the next process step is executed.If the test is negative, it must first be analyzed where improvements are needed (preparation,",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 24\nExamplesofqualityindicesPart 2\n\u2015Evaluation of the classification on the basis of disimilarity\n\u2015Evaluation of the classification on the basis of heterogeneity and on the basis of disimilarity.\n1\nK, L\nKL\nb( ) c  v(K ,L)\n-\n\u00ce\n\u00b9\n\u00e6\u00f6\n\u00e7\u00f7= \u00d7 \u00e7\u00f7\n\u00e7\u00f7\u00e8\u00f8\n\u00e5K\nK\n1\nK, LK\nKL\nb( )  h(K )  v(K ,L)\n-\n\u00ce\u00ce\n\u00b9\n\u00e6\u00f6\n\u00e6\u00f6 \u00e7\u00f7= \u00d7\u00e7\u00f7 \u00e7\u00f7\u00e8\u00f8 \u00e7\u00f7\u00e8\u00f8\n\u00e5\u00e5 KK\nK",
            "low).Aggregation and ranking of ratingsInvestigation of particularly critically evaluated product properties",
            "\u2015In general, the quality index falls as the number of classes increases. \u2015A conflict of objectives arises between\u2022as small a number of classes as possible and\u2022quality index as small as possible.Decision support: elbow criterionWith the help of this so-called criterion, the \"optimal\" choice of the number of classes can be made. The decision is made in favor of the number of classes s* with the quality b*, which is the same with \u2022a reduction in the number of classes sleads to a sharp increase in",
            "A distinction is made between measures for evaluating the\u2015Heterogeneity of a class (intra-class dissimilarity) -heterogeneity indices\u2015Difference of two classes (interclass difference) -dissimilarity indices\u2015Quality of a segmentation (quality index) -quality indices",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 25\nThe problemofqualityindices",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 41\nVariety of Data Analysis TechniquesWhat is best practice?\nWhat are the most commonly usedtechniques/algorithms?"
        ],
        "generated": "The four quality criteria mentioned in the context are:\n1. Fitness - ability to replay\n2. Simplicity (Occam's razor) - simplest model to explain behavior is the best model\n3. Precision - degree of behavior allowed by the model, but not in the logs (do not underfit)\n4. Generalization - work with incomplete behavior (do not overfit)",
        "ground_truth": "Fitness, Simplicity, Precision, Generalization."
    },
    {
        "query": "What are the challenges of text mining?",
        "retrieved": [
            "Text mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff.",
            "Text Mining in the Big Data EnvironmentThe amount of available texts increases extremely in Web 2.0 (keyword: user-generated content)Social networks, forums and blogs can be interesting sources for product improvements, marketing activities or opinion analysisText processing and analysis is very computationally intensive even for a few documentsBig Data technologies enable high-performance and scalable analysis systemsEx: Hadoop-based systemsDistributed File Systems (Hadoop Distributed File",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 10\nText mining challenges",
            "Text Mining\nProceduremodel: Text miningprocedure",
            "Many text mining techniques have their origins in data mining, and often classical data mining techniques can also be applied to text data, provided that the data is available in a suitable structure.In the literature, the vector space model according to Salton et al. (1975) is mostly used for this purpose, whereby the text data areavailable in a structured tabular form:Terms and documents are transformed into a matrixThe lines list the termsIn the columns the documents are listedThe",
            "From a process perspective, text mining includes both the collection and preparation of texts and the exploitation of the results.Analysis techniques are used to evaluate and generate the text mining results.\nThe processing and analysis steps are integrated as functions in application systems.",
            "The processing and analysis steps are integrated as functions in application systems.\nText data can be both internal and external to the company; in the context of data processing, one also speaks of unstructured data.The goal of text mining is to generate new knowledge to be translated into action."
        ],
        "generated": "The challenges of text mining include very large amounts of text data, high dimensionality, noise in the data, understanding the results, and the fact that texts are usually not intended for computer-based processing due to their complex and little standardized structure. Additionally, language, morphology, syntax, and semantics strongly depend on the author and the target audience of the text, making text mining more challenging.",
        "ground_truth": "Very large amounts of (text) data, High dimensionality, 'Noise' in the data, Understanding the results, Texts are usually not intended for computer-based processing."
    },
    {
        "query": "What is data mining explained by Cabena et al. (1997)?",
        "retrieved": [
            "\u201eData Mining, as we use the term, is the exploration and analysis, by automatic or semiautomatic means, of large quantities of data in order to discover meaningful patterns and rules.\u201c(Berry et al. 1997)",
            "Data Mining\n...from semi-structured& unstructuredtext data\ne.g. documents, e-mails,...\nText mining\n...from web-based data\ne.g. web pages, log files,...\nWeb Mining\nWeb Usage MiningWeb Content MiningWeb Structure Mining",
            "IntroductionDefinition and Data Mining context\nOne possible definition:\nIn the context of data mining:-A portion of the observed data is generated by an unknown, anomalous process-This process differs from the standard processUntil now: -Assumption of one process that generates the data-Data Mining models reflecting that processNow: Interesting new observations that indicate differing mechanism behind data",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 21\nData MiningDefinition and context\n\u201eData Mining is the process of extracting previously unknown, valid, and actionable informationfrom large databases and then using the information to make crucial business decisions.\u201c(Cabena et al. 1997)",
            "Statistics  and  mathematical  optimization  (mathematical  programming)  methods\ncomprise the foundations of machine learning. Data mining is a related field of study,\nfocusing on exploratory data analysis (EDA) via unsupervised learning.[6][7]\nFrom  a  theoretical  viewpoint,  probably  approximately  correct  learning  provides  a\nframework for describing machine learning.\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 5\nIntroductionDefinition and Data Mining context\nOne possible definition:",
            "Many reporting and analytic tools already work with data warehouses\nCasati et al. (2017)",
            "Databases with Noise. Proceedings of the 2nd International Conference on Knowledge Discovery and Data mining, 226-231",
            "Provisioning of toolsfor process-basedmultidimensional analysisand navigation\nDistributionand presentationof analysis results\nKueng et al. (2001), List et al. (2002), Becker et al. (2006)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 8\nDifferentiation from data and web mining\nSources: Liu (2007), p. 6ff.; Stoffel (2009), p. 9ff.\nData sources\nData types\nAnalytical process for computer-aided knowledge generation....\n...from structured data\ne.g. relational databases, data warehouse\nData Mining\n...from semi-structured& unstructuredtext data\ne.g. documents, e-mails,...\nText mining",
            "Atahighlevel,datascienceisasetoffundamentalprinciplesthatsupportandguidetheprincipledextractionofinformationandknowledgefromdata.Possiblythemostcloselyrelatedconcepttodatascienceisdatamining-theactualextractionofknowledgefromdataviatechnologiesthatincorporatetheseprinciples.Therearehundredsofdifferentdataminingalgorithms,andagreatdealofdetailtothemethodsofthefield.Wearguethatunderlyingallthesemanydetailsisamuchsmallerandmoreconcisesetoffundamentalprinciples."
        ],
        "generated": "According to Cabena et al. (1997), data mining is defined as the process of extracting previously unknown, valid, and actionable information from large databases and using that information to make crucial business decisions.",
        "ground_truth": "Data Mining is the process of extracting previously unknown, valid, and actionable information from large databases and then using the information to make crucial business decisions."
    },
    {
        "query": "What are process models in business informatics?",
        "retrieved": [
            "Process models in business informaticsProcess models specify the sequence in which certain activitiesshouldbe carried out or proceduresshouldbe used in order to successfully complete (IT) projects; this serves on the one hand to structuretasksand on the other hand to reduce complexity within these projects.Process models such as the KDD, SEMMA or CRISP-DM processstructure phases and tasks of the data mining processSources: Fil\u00df et al. (2005, p. 184; Gutzwiller (1994), p. 32;Jablonski (1997), p.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 19\nProcedure model according to Schieber & Hilbert\nProcess models such as the KDD, SEMMA or CRISP-DM process structure phases and tasks of the data mining processAnalogously, the procedure model according to Schieber & Hilbert structures the phases and tasks of the text mining processSources: Kurgan & Musilek (2006), p. 9ff.; Schieber & Hilbert (2014a), p. 45",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 18\nProcess models and proceduresLiterature Review: Implications",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?"
        ],
        "generated": "Process models in business informatics specify the sequence in which certain activities should be carried out or procedures should be used in order to successfully complete (IT) projects. They serve to structure tasks and reduce complexity within these projects. Examples of process models include KDD, SEMMA, and CRISP-DM, which structure phases and tasks of the data mining process.",
        "ground_truth": "Process models specify the sequence in which certain activities should be carried out or procedures should be used in order to successfully complete (IT) projects; this serves on the one hand to structure tasks and on the other hand to reduce complexity within these projects."
    },
    {
        "query": "Why is data visualization so important for Data Science?",
        "retrieved": [
            "Importance of Visualization\nWhy is data visualization so important?\u201cBecause of the way the human brain processes information, using charts or graphs to visualize large amounts of complex data is easier than poring over spreadsheets or reports. Data visualization is a quick, easy way to convey concepts in a universal manner \u2013and you can experiment with different scenarios by making slight adjustments.\u201d (SAS, 2017)",
            "Structuring the Field:1) Data Science Principles",
            "Structuring the Field:Understanding Data Science",
            "Structuring the Field:2) Data Science Concepts",
            "Structuring the Field:3) Data Science Techniques",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 35\nImportance of Visualization",
            "Structuring the Field:4) Data Science Technologies",
            "Data Science: Advanced Analytics\nIntroduction",
            "explore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "\u201cExtracting useful knowledge from data to solve business problems can be treated systematicallyby following a  process with reasonably well-defined stages.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "\u201cThe relationship between the business problem and the analytics solution often can be decomposed into tractable sub-problems via the framework of analyzing expected value.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)\n\u201cInformation technology can be used to find informative data items from within a large body of data.\u201d"
        ],
        "generated": "Data visualization is important for Data Science because it allows for the easier processing of large amounts of complex data. The human brain processes information more effectively through charts or graphs compared to poring over spreadsheets or reports. Visualization helps convey concepts in a universal manner and enables experimentation with different scenarios by making slight adjustments.",
        "ground_truth": "Because of the way the human brain processes information, using charts or graphs to visualize large amounts of complex data is easier than poring over spreadsheets or reports. Data visualization is a quick, easy way to convey concepts in a universal manner \u2013 and you can experiment with different scenarios by making slight adjustments."
    },
    {
        "query": "What are types of anomalies?",
        "retrieved": [
            "Anomaly Detection\nMethods",
            "Anomaly Detection\nIntroduction",
            "MethodsCriteria: Type of anomaly\nPoint Anomalies: -A single data object is considered to benot \u201enormal\u201c in relation to the rest of the data -Example: \u201eAmount spend\u201c in credit fraud is very high compared to usual behaviorContextual Anomalies:-A single data point is only anomalous in a certain context-The context in form of context variables sets the neighborhood and defines normal behavior-E.g.observed temperature is normal during winter but are anomalous in JuneContextual Anomaly",
            "IntroductionOverview\nAnomalous patterns are often referred to as anomalies, outliers, discordant observations, exceptions, aberrations, surprises, peculiarities orcontaminants in different application domainsWe will use the term anomalyMain reference: Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A Survey. ACM Computing Surveys, 41(3), 1\u201358.",
            "Even though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of",
            "unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to\ndetect the micro-clusters formed by these patterns.[74]\nThree  broad  categories  of  anomaly  detection  techniques  exist.[75]  Unsupervised\nanomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised",
            "MethodsCriteria for anomaly detection problem definition\nThere is NO general approach that works for all application domainsDifferent problem definitionsdepending on some basic criteria:-Nature of data-Labels-Anomaly Type-OutputAnomaly Detection methods can be found in many research fields:-Machine Learning (Data Mining)-Statistics-Information Theory-Spectral Theory-\u2026"
        ],
        "generated": "Based on the provided context, the types of anomalies mentioned are Point Anomalies and Contextual Anomalies.",
        "ground_truth": "Point Anomalies, Contextual Anomalies, Collective Anomalies."
    },
    {
        "query": "What is the definition of Deep Learning by Najafabadi et al. (2016)?",
        "retrieved": [
            "belief networks.[8][12]\nThe  term  Deep  Learning  was  introduced  to  the  machine  learning  community  by  Rina\nDechter in 1986,[13] and to artificial neural networks by Igor Aizenberg and colleagues",
            "A special class of Machine Learning algorithms is Deep Learning.\u201cThe main concept in deep leaning algorithms is automating the extraction of representations(abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representation.\u201d(Najafabadi et al., 2016)\u201cThese algorithms are largely motivated by the field of artificial intelligence, which has the general goal of emulating the human brain\u2019s abilityto observe, analyze, learn,",
            "Deep LearningDeep neural network architectures\n\u201cDeep learning is a relatively new term, although it has existed prior to the recent dramatic uptick in online searches. Enjoying a surge in research and industry, due mainly to its incredible successes in a number ofdifferent areas, deep learning is the process of applying deep neural network technologies -that is, neural network architectures with multiple hidden layers of neurons-to solve problems.\u201d(KDnuggets, 2016)\n(Source: Chen & Lin, 2014)",
            "Deep Learning\nDeep learning is a subset of machine learning that focuses on utilizing neural networks\nto  perform  tasks  such  as  classification,  regression,  and  representation  learning.  The\nfield  takes  inspiration  from  biological  neuroscience  and  is  centered  around  stacking\nartificial neurons into layers and \"training\" them to process data. The adjective \"deep\"\nrefers  to  the  use  of  multiple  layers  (ranging  from  three  to  several  hundred  or",
            "Fundamentally, deep learning refers to a class of machine learning algorithms in which\na hierarchy of layers is used to transform input data into a progressively more abstract\nand  composite  representation.  For  example,  in  an  image  recognition  model,  the  raw\ninput may be an image (represented as a tensor of pixels). The first representational\nlayer may attempt to identify basic shapes such as lines and circles, the second layer",
            "Deep Learning\nConvolutional Neural Networks",
            "which has the general goal of emulating the human brain\u2019s abilityto observe, analyze, learn, and make decisions, especially for extremely complex problems.\u201d (Najafabadi et al., 2016)",
            "A variety of approaches have been used to investigate the plausibility of deep learning\nmodels  from  a  neurobiological  perspective.  On  the  one  hand,  several  variants  of  the\nbackpropagation  algorithm  have  been  proposed  in  order  to  increase  its  processing\nrealism.[257][258]  Other  researchers  have  argued  that  unsupervised  forms  of  deep\nlearning,  such  as  those  based  on  hierarchical  generative  models  and  deep  belief",
            "References & WebLinks\n\u00a7GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A.:Deep Learning (2016), P.330ff.\u00a7LECUN, YANN; BENGIO, YOSHUA: Convolutional Networks for Images, Speech, and Time-Series. In M. A. Arbib(Ed.),The handbook of brain theory and neural networksMIT Press (1995).\u00a7ROHRER, BRANDON: How Convolutional Neural Networks work. https://www.youtube.com/watch?v=FmpDIaiMIeA\u00a7STANFORDCS231NCLASSNOTES: Convolutional Neural Networks for Visual Recognition: http://cs231n.github.io/convolutional-networks/"
        ],
        "generated": "The definition of Deep Learning by Najafabadi et al. (2016) is: \"The main concept in deep learning algorithms is automating the extraction of representations (abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representation.\"",
        "ground_truth": "The main concept in deep learning algorithms is automating the extraction of representations (abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representations."
    },
    {
        "query": "What is Agglomerative Clustering?",
        "retrieved": [
            "Furthermore, one still distinguishes: \u2015Agglomerativeand divisive methods. The former start from one-element classes and combine elements into classes step by step. Divisive methods,on the other hand, start from an initial decomposition which is refined (i.e., divided) step by step. \u2015Single-modal methods that group objects or features into classes, and dual-modalmethods that simultaneously classify objects and features of a data matrix.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 10\nHierarchicalClustering Methods\nSegmentation methods that construct a sequence of partitions on the basis ofa set of objects N.\nAgglomerative ClusteringEach object initially represents a cluster of its own. Then clusters are successively merged until the desired cluster structure is obtained.",
            "Several clustering algorithms force every instance to be assigned to some cluster.Several clustering based techniques are effective only when the anomalies do not form significant clusters among themselves.\nThe computational complexity for clustering the data is often a bottleneck.",
            "HierarchicalClustering Methods\nforSegmentation",
            "Idea 1: Normal data instances belong to a cluster in the data, while anomalies do not belong to any cluster:Requires cluster method that does not put every data point into clustersE.g.: DBSCAN, ROCK, WaveCluster, FindOutIdea 2: Normal data instances lie close to their closest cluster centroid, while anomalies are far away from their closest cluster centroid:Commonused methods are SOM, K-means, Expectation MaximizationSemi-supervised approach can be used to improve resultsIdea 1 and 2 arenot",
            "Density BasedClustering Methods\nforSegmentation",
            "Basics ofsegmentation\nCluster types",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 6\nSubdivision ofclusterapproachesAgglomerativeand single-modal methods",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 3\nClustering Methods\nPartitionalClustering K-Means& K-MedoidsFor n objects or data tuples, a partitioning method constructs k partitions of the data, where each partition represents a cluster k <= n.\nHierarchicalClustering Agglomerative, DivisiveGroupingdata objects into a tree (dendrogram) of clusters",
            "Interpretation ofa Dendrogram\nAbrupt changesin thevalueofthequalitycriterionallowconclusionstobedrawnabouttheappropriatenumberofclasses(EB).Similarobjectsaremergedearly, dissimilarobjectslater; outliersareassignedtoa large clusteronlyat theend.The classstructureis\u2015stable, ifdifferent methodsleadtosimilarresults, \u2015intensive, ifclassesofcomparablesizearesuccessivelymergedand \u2015weak, ifsuccessivelyonlyneighboringsingleobjectsareadded."
        ],
        "generated": "Agglomerative Clustering is a hierarchical clustering method where each object initially represents a cluster of its own, and then clusters are successively merged until the desired cluster structure is obtained.",
        "ground_truth": "Each object initially represents a cluster of its own. Then clusters are successively merged until the desired cluster structure is obtained."
    },
    {
        "query": "What is segmentation or cluster analysis used for?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 2\nRecap: Aims of the cluster analysis\nSegmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that\u2022between the elements of the same classes the greatest possible similarity,\u2022between the elements of different classes the greatest possible diversity is achieved",
            "Basics ofsegmentation\nCluster types",
            "Aimsoftheclusteranalysis\n\u2015Segmentationorcluster analysis is used to group objects and/or characteristics into classes or groups, so that-between the elements of thesame classes as similar as possible,-between the elements of different classes the greatest possible dissimilarityis achieved.\u2015The clusters are not known beforehand.\u2015So-calledunsupervised learning methods are used, for example.",
            "HierarchicalClustering Methods\nforSegmentation",
            "Procedureand application\n1) First, sdifferent class centers are determined if possible.2) After that, the remaining elements are assigned to the nearest class center. Application of heuristics:\u2015Determination of initial segmentations that can be iteratively improved using other methods.\u2015Determination of segmentations when very large data sets preclude other methods for computation time reasons.",
            "Clustering basedAdvantages\nClustering based techniques can operate in an unsupervised mode.Such techniques can often be adapted to other complex data types by simply plugging in a clustering algorithm that can handle the particular datatype.The testing phase for clustering basedtechniques is fast since the number of clusters against which every test instance needs to be compared is a small constant.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 35\nClustering basedAdvantages",
            "PartionalClustering Methods\nforSegmentation",
            "Basics ofSegmentation\nIntroduction"
        ],
        "generated": "Segmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that between the elements of the same classes the greatest possible similarity, and between the elements of different classes the greatest possible diversity is achieved.",
        "ground_truth": "Segmentation or cluster analysis is used to group objects and/or characteristics into classes or groups, so that - between the elements of the same classes as similar as possible, - between the elements of different classes the greatest possible dissimilarity is achieved."
    },
    {
        "query": "What are anomaly detection methods?",
        "retrieved": [
            "Anomaly Detection\nMethods",
            "Anomaly Detection\nIntroduction",
            "Data Science: Advanced Analytics\nAnomaly Detection",
            "Even though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of",
            "virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation, etc. that are used in another context.",
            "Idea: Normal data instances occur in high probability regions of a stochastic model, while anomalies occur in the low probability regions of the stochastic model.Parametric approaches: -The normal data is assumed to be generated from a probability distribution -The inverse of the probability of an observation to be generated from such a distribution is considered as anomaly score \u00f0small probability means high chance of anomaly-Statistical tests are widely usedNon-parametric methods:-No",
            "unless aggregated appropriately. Instead, a cluster analysis algorithm may be able to\ndetect the micro-clusters formed by these patterns.[74]\nThree  broad  categories  of  anomaly  detection  techniques  exist.[75]  Unsupervised\nanomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised",
            "Structuring the Field:3) Data Science Techniques",
            "IntroductionOverview\nAnomalous patterns are often referred to as anomalies, outliers, discordant observations, exceptions, aberrations, surprises, peculiarities orcontaminants in different application domainsWe will use the term anomalyMain reference: Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A Survey. ACM Computing Surveys, 41(3), 1\u201358.",
            "\u201cAn Outlier is an observation which deviates so much from the otherobservations as to arouse suspicions that it was generated by a differentmechanism\u201d (Hawkins, 1980)Source: Hawkins D. 1980. Identification of Outliers. Chapman and Hall."
        ],
        "generated": "Anomaly detection methods are techniques used to identify anomalous patterns or outliers in data. These methods typically assume that anomalies are rare compared to normal instances and can include approaches such as SVM, clustering, kernel density estimation, parametric and non-parametric methods, statistical tests, and cluster analysis algorithms.",
        "ground_truth": "Classification based, neighbor based, clustering based, statistical methods, information theory based, spectral theory based."
    },
    {
        "query": "What are the different types of analytics?",
        "retrieved": [
            "Different Types of AnalyticsTaking responsibilities for dedicated analytical tasks\nDescriptive AnalyticsQuestion: \u201cWhat is happening right now/ what happened in the past?\u201d Summarizingcollected data from various sources and providing aggregated measures and visualizationsIncluding traditional business intelligence tools: e.g.reports, dashboards, querying, online analytical processing (OLAP)",
            "Data Science: Advanced Analytics\nContent",
            "Data Science: Advanced Analytics\nIntroduction",
            "Data Science: Advanced Analytics \nProcess Analytics",
            "Diagnostic AnalyticsQuestion: \u201cWhy did/ does it happen?\u201dExplanatory empirical modeling based on statistical inference and causal hypotheses testing\nPredictive AnalyticsQuestion: \u201cWhat is likely to happen?\u201dDeveloping prediction models with high accuracy by using a large amount of historical data, detecting complexandnon-trivial relationshipsand providing predictions and equivalent probability scores on new unclassified observations",
            "classification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,",
            "Structuring the Field:3) Data Science Techniques",
            "Anomaly Detection\nMethods",
            "Furthermore, one still distinguishes: \u2015Agglomerativeand divisive methods. The former start from one-element classes and combine elements into classes step by step. Divisive methods,on the other hand, start from an initial decomposition which is refined (i.e., divided) step by step. \u2015Single-modal methods that group objects or features into classes, and dual-modalmethods that simultaneously classify objects and features of a data matrix.",
            "Structuring the Field:4) Data Science Technologies",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 24\nDifferent Types of AnalyticsTaking responsibilities for dedicated analytical tasks"
        ],
        "generated": "The different types of analytics mentioned in the context are Descriptive Analytics, Diagnostic Analytics, and Predictive Analytics.",
        "ground_truth": "Descriptive Analytics, Diagnostic Analytics, Predictive Analytics, Prescriptive Analytics"
    },
    {
        "query": "In what categories can Machine Learning tasks be classified?",
        "retrieved": [
            "Machine Learning tasks can be classified into three broad categories of learning problems:Supervised Learning:The algorithm is given training data which contains examples of the input vectors along with their correspondingtarget vectors as the \u201ccorrect answer\u201d and the goal is to learn a general rule/ model that maps inputs to outputs.Examples: classification, regressionUnsupervised Learning: Principle: No labels (i.e.target values) are given to the algorithm, leaving it on its own to find",
            "definition of the tasks in which machine learning is concerned offers a fundamentally\noperational definition rather than defining the field in cognitive terms. This follows Alan\nTuring's  proposal  in  his  paper  \"Computing  Machinery  and  Intelligence\",  in  which  the\nquestion \"Can machines think?\" is replaced with the question \"Can machines do what\nwe (as thinking entities) can do?\".[19]\nModern-day  machine  learning  has  two  objectives.   One  is  to  classify  data  based  on",
            "Modern-day  machine  learning  has  two  objectives.   One  is  to  classify  data  based  on\nmodels which have been developed; the other purpose is to make predictions for future\noutcomes based on these models. A hypothetical algorithm specific to classifying data\nmay use computer vision of moles coupled with supervised learning in order to train it\nto  classify  the  cancerous  moles.  A  machine  learning  algorithm  for  stock  trading  may",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 28\nMachine Learning CategorizationDifferent types of learning problems",
            "Machine Learning\nMachine  learning  (ML)  is  a  field  of  study  in  artificial  intelligence  concerned  with  the\ndevelopment and study of statistical algorithms that can learn from data and generalize\nto  unseen  data,  and  thus  perform  tasks  without  explicit  instructions.[1]  Within  a\nsubdiscipline in machine learning, advances in the field of deep learning have allowed\nneural  networks,  a  class  of  statistical  algorithms,  to  surpass  many  previous  machine",
            "Types  of  supervised-learning  algorithms  include  active  learning,  classification  and\nregression.[50] Classification algorithms are used when the outputs are restricted to a\nlimited set of values, and regression algorithms are used when the outputs may have\nany numerical value within a range. As an example, for a classification algorithm that\nfilters emails, the input would be an incoming email, and the output would be the name",
            "polynomial time.\nMachine  learning  approaches  are  traditionally  divided  into  three  broad  categories,\nwhich  correspond  to  learning  paradigms,  depending  on  the  nature  of  the  \"signal\"  or\n\"feedback\" available to the learning system:\nAlthough each algorithm has advantages and limitations, no single algorithm works for\nall problems.[45][46][47]\nSupervised  learning  algorithms  build  a  mathematical  model  of  a  set  of  data  that",
            "boundary,  low  samples,  and  ambiguous  class  issues  that  standard  machine  learning\napproach  tend  to  have  difficulty  resolving.[4][9]  However,  the  computational\ncomplexity of these algorithms are dependent on the number of propositions (classes),\nand  can  lead  to  a  much  higher  computation  time  when  compared  to  other  machine\nlearning approaches.\nTypically, machine learning models require a high quantity of reliable data to perform"
        ],
        "generated": "Machine Learning tasks can be classified into three broad categories: Supervised Learning, Unsupervised Learning, and Reinforcement Learning.",
        "ground_truth": "Supervised Learning, Unsupervised Learning, Reinforcement Learning"
    },
    {
        "query": "What type of units are in ANN?",
        "retrieved": [
            "Artificial Neural Networks (ANN)Recap: Example Network descriptionStructure:\u00a7An input layer with 3 input units\u00a7A hidden layer with 4 hidden units\u00a7An output layer with 2 output unitsConnections and weights:\u00a7Every unit of a layer is connected to every unit of the following layer\u00a7Those connections are not all of the same strength, instead they are weighted\u00a7Those weights are the parameter of an ANN model and need to be learnedFeed forward run:\u00a7Once the weights are learned, a new input vector can be",
            "Artificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in",
            "traditional computer algorithm using rule-based programming.\nAn ANN is based on a collection of connected units called artificial neurons, (analogous\nto biological neurons in a biological brain). Each connection (synapse) between neurons\ncan  transmit  a  signal  to  another  neuron.  The  receiving  (postsynaptic)  neuron  can\nprocess  the  signal(s)  and  then  signal  downstream  neurons  connected  to  it.  Neurons",
            "surveys such as the one by Bishop.[27]\nThere  are  two  types  of  artificial  neural  network  (ANN):  feedforward  neural  network\n(FNN) or multilayer perceptron (MLP) and recurrent neural networks (RNN). RNNs have\ncycles in their connectivity structure, FNNs don't. In the 1920s, Wilhelm Lenz and Ernst\nIsing  created  the  Ising  model[28][29]  which  is  essentially  a  non-learning  RNN\narchitecture  consisting  of  neuron-like  threshold  elements.  In  1972,  Shun'ichi  Amari",
            "systems  \"learn\"  to  perform  tasks  by  considering  examples,  generally  without  being\nprogrammed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"artificial\nneurons\", which loosely model the neurons in a biological brain. Each connection, like\nthe  synapses  in  a  biological  brain,  can  transmit  information,  a  \"signal\",  from  one\nartificial neuron to another. An artificial neuron that receives a signal can process it and"
        ],
        "generated": "The type of units in an Artificial Neural Network (ANN) are input units, hidden units, and output units.",
        "ground_truth": "Input Units, Hidden Units, Output Units."
    },
    {
        "query": "What are process mining challenges?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 7\nProcess Mining Challenges",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 35\nChallenges in Process Mining\nnon-fitting model\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 36\nChallenges in Process Mining\nUnderfitting Model\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 34\nChallenges in Process Mining\ntarget model\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 37\nChallenges in Process Mining\nOverfitting Model\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 33\nChallenges in Process Mining\nfrequent behavior\ntrace in the log\nAll behavior (including noise)\nvan der Aalst (2017)",
            "\u201cProcess mining adds the process perspective to machine learning and data mining\u201d\n\u201cProcess mining brings together traditional model-based process analysis and data-centric analysis techniques\u201d\nvan der Aalst (2017)"
        ],
        "generated": "Process mining challenges include non-fitting models, underfitting models, target models, overfitting models, and dealing with frequent behavior and noise in traces in the log.",
        "ground_truth": "Correlation challenge, Timestamps challenge, longevity challenge, scoping challenge, granularity challenge."
    },
    {
        "query": "What are the application domains of anomaly detection?",
        "retrieved": [
            "Anomaly Detection\nMethods",
            "Anomaly Detection\nIntroduction",
            "Data Science: Advanced Analytics\nAnomaly Detection",
            "MethodsCriteria for anomaly detection problem definition\nThere is NO general approach that works for all application domainsDifferent problem definitionsdepending on some basic criteria:-Nature of data-Labels-Anomaly Type-OutputAnomaly Detection methods can be found in many research fields:-Machine Learning (Data Mining)-Statistics-Information Theory-Spectral Theory-\u2026",
            "IntroductionOverview\nDescription: Detections of patterns that do not conform to \u201enormal\u201c behavior\nApplication domains:-Fraud Detection (e.g., credit card fraud, tax fraud, etc.)-Intrusion Detection in cyber security-Fault Detection in safety critical systems-Military surveillance of enemies-\u2026Importance of anomalies: Anomalies often are indicators for situations that require critical decisionsExample: An anomalous pattern in network traffic could indicate a hacker attack",
            "Even though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of",
            "virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation, etc. that are used in another context."
        ],
        "generated": "The application domains of anomaly detection include fraud detection (e.g., credit card fraud, tax fraud), intrusion detection in cyber security, fault detection in safety critical systems, military surveillance of enemies, and more.",
        "ground_truth": "- Fraud Detection (e.g., credit card fraud, tax fraud, etc.) - Intrusion Detection in cyber security - Fault Detection in safety critical systems - Military surveillance of enemies."
    },
    {
        "query": "How many credits does this course give?",
        "retrieved": [
            "Credit points: \n5\nAssessment:\n120min exam (ONYX-Exam \u2013 further information during the semester) \nAll information: in OPAL - https://bildungsportal.sachsen.de/opal/auth/RepositoryEntry/16864575517",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 12\nCourse Information \u2013\nextracts of the module guide \u201cDiplom Wirtschaftsinformatik\u201d\nCreditability:  \nMA-WW-WINF-0416b D-WW-WINF-0416b \nMaster: BWL, VWL, Wing, Winfo, Wip\u00e4d\nDiploma: Wing, Winfo\nCredit points: \n5\nAssessment:\n120min exam (ONYX-Exam \u2013 further information during the semester)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 13\nCourse structure\nLecture:\n\u2022 Will be provided on a weekly basis as video \nlectures on video campus Sachsen\n\u2022 first upload date: 19.04.2023\nExercises:\n\u2022 3 Virtual Exercises as MS Teams Call\n\u2022 free Python courses on DataCamp\nTrial exam: 30 min online (OPAL)\nExam:\n\u2022 120 min online (hybrid PC-Pool via OPAL)\u200b\n\u2022 Thrusday, August the 3-th.",
            "The following applies to transactions in general:Transactions consist of item quantity and transaction time. Often, information on behavior over time is available in addition to the transactions.  -Market Basket analysis: Payment by credit card or customer card; -Delivery Providers: collection of customer information e.g. based on orders received.However, this information is not usedin classical association analysis, although the inclusion of this additional information can significantly",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 10\nConcept of this course -> Flipped Classroom\nTraditional classroom:\nFrontal teaching of main topics\nStudents expected to deepen understanding by \nexercises on their own\nFlipped classroom:\nshift the classic explanation phases from frontal \nteaching to self-study\nIn depth understanding by working through exercise \ntogether with teaching staff",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 26\nElbow diagram\nb*\ns* Class number s\nb(K)\n2 43 65 871\nHint:The choice of the number of classes falls in favor of the number s*=4. The choice of the two-class solution is also justifiable.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 15\nDataCamp\nYou can explore further courses and programming languages in the catalog. \nThese are the main dashboards for the course. You can view your assignments, your\nprogress and the progress of your fellow students.\nAssignments:\nYou can filter all \nyour assignments\nfor this course.\nFully completed\ntasks will be\ndisplayed as\ncompleted.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 3",
            "Structuring the Field:4) Data Science Technologies",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 67\nDocument preparationWeightingand reducingterms",
            "(Source: SoongsilUniversity, 2016)"
        ],
        "generated": "This course gives 5 credits.",
        "ground_truth": "5"
    },
    {
        "query": "What type of layers are in ANN?",
        "retrieved": [
            "Artificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in",
            "Artificial Neural Networks (ANN)Recap: Example Network descriptionStructure:\u00a7An input layer with 3 input units\u00a7A hidden layer with 4 hidden units\u00a7An output layer with 2 output unitsConnections and weights:\u00a7Every unit of a layer is connected to every unit of the following layer\u00a7Those connections are not all of the same strength, instead they are weighted\u00a7Those weights are the parameter of an ANN model and need to be learnedFeed forward run:\u00a7Once the weights are learned, a new input vector can be",
            "surveys such as the one by Bishop.[27]\nThere  are  two  types  of  artificial  neural  network  (ANN):  feedforward  neural  network\n(FNN) or multilayer perceptron (MLP) and recurrent neural networks (RNN). RNNs have\ncycles in their connectivity structure, FNNs don't. In the 1920s, Wilhelm Lenz and Ernst\nIsing  created  the  Ising  model[28][29]  which  is  essentially  a  non-learning  RNN\narchitecture  consisting  of  neuron-like  threshold  elements.  In  1972,  Shun'ichi  Amari",
            "crosses that threshold. Typically, artificial neurons are aggregated into layers. Different\nlayers  may  perform  different  kinds  of  transformations  on  their  inputs.  Signals  travel\nfrom the first layer (the input layer) to the last layer (the output layer), possibly after\ntraversing the layers multiple times.\nThe original goal of the ANN approach was to solve problems in the same way that a\nhuman brain would. However, over time, attention moved to performing specific tasks,",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 4\nExample ANN 1 hidden layer, 3 input nodes, 4 hidden nodes, 2 output nodes\nArtificial Neural Networks (ANN)Recap: Classic ANN architecture and example calculation",
            "for \"conceptual and engineering breakthroughs that have made deep neural networks a\ncritical component of computing\".[142]\nArtificial  neural  networks  (ANNs)  or  connectionist  systems  are  computing  systems\ninspired by the biological neural networks that constitute animal brains. Such systems",
            "traditional computer algorithm using rule-based programming.\nAn ANN is based on a collection of connected units called artificial neurons, (analogous\nto biological neurons in a biological brain). Each connection (synapse) between neurons\ncan  transmit  a  signal  to  another  neuron.  The  receiving  (postsynaptic)  neuron  can\nprocess  the  signal(s)  and  then  signal  downstream  neurons  connected  to  it.  Neurons"
        ],
        "generated": "The types of layers in an Artificial Neural Network (ANN) are Input Layer, Hidden Layer(s), and Output Layer.",
        "ground_truth": "Input Layer, Hidden Layer, Output Layer."
    },
    {
        "query": "What is the A-priori algorithm?",
        "retrieved": [
            "A-priori AlgorithmIdea\nThe A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database.The algorithm searches for all rules that have a high confidencevalue. It must now be taken into account that the important confidence of a rule is also expressed by its support values. Thus applies: Let X be an item set from the population of all items I and X\u2018 \u00ccX, then:",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 9\nA-priori AlgorithmIdea",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 10\nA-priori AlgorithmProcesssteps\nThe following steps are to be completed during rule generation using the A-priori algorithm.must be completed:Step 1: Compute the (frequent) item sets whose support values are at least equal to the minimum support (\u00e0frequent item set X ).\nStep 2: For each subset X' of a frequent item set X holds:",
            "-A-priori Algorithm-A-priori-Tid algorithm-A-priori-Hybrid Algorithm-AIS algorithmThe procedures have in common that they are often used as starting procedures in the data mining, since no assumptions are necessary to the connections of the data, which things could correlate e.g. (undirected data mining).\nNote: 100 itemsresultin generally(100 overk) item combinations.-2-itemsets: 4,950 combinations-3-itemsets: 161,700 combinations-5-itemsets: 75.287.520 combinations",
            "Provided that frequent item sets with n elements exist, the A priori algorithm requires n iterations ( 1 MB shopping cart analyzable in seconds).Algorithm discovers thousands of rules.Visualizationor browsingis necessary:-Rules with very high support or confidence values are mostly already known.-The so called \"medium\" rulesare mainly interesting.\u00e0Thus, additional statistical key figures are necessary for the evaluation.Many external influencing factorsremain unconsidered, since transaction",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 11\nA-priori AlgorithmFrequent setsofitems\u2013Part I",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 13\nA-priori AlgorithmExample\u2013Part I\nDetermination of association rulesfor transaction data of a supermarket\nKunde Artikel\n1 Wein, Lachs, Baguette\n2 Wein, Lachs, Sahne\n3 Wein, K\u00e4se, \n4 Lachs, Baguette, Wein\n5 Wein, Lachs, Baguette, Sahne\n6 K\u00e4se\nArtikel\nTransaktion, die \nArtikel umfasst\nSupport des \nArtikels\nWein 1,2,3,4,5 5/6 = 83,3 %\nLachs 1,2,4,5 4/6 = 66,6 %"
        ],
        "generated": "The A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database. It searches for all rules that have a high confidence value by computing frequent item sets whose support values are at least equal to the minimum support. The algorithm requires multiple iterations to discover thousands of rules and is often used as a starting procedure in data mining without the need for assumptions about the connections of the data.",
        "ground_truth": "The A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database. The algorithm searches for all rules that have a high confidence value. It must now be taken into account that the important confidence of a rule is also expressed by its support values."
    },
    {
        "query": "What are items regarding Association Analysis?",
        "retrieved": [
            "Itemsare uninterpretable, discrete things or entities. The set of all items is denoted by I.An association rule A \u00e0B consists of a set of items A in the rule bodyand a set of items B in the rule head, where A and B must be disjoint.Each transaction tconsists of a set of items. The transactions considered in the association analysis are combined into a database D.A transaction t satisfies a rule A \u00e0B if (A\u00c8B) \u00cdt, i.e., if all items contained in the rule also occur in the transaction.",
            "The following applies to transactions in general:Transactions consist of item quantity and transaction time. Often, information on behavior over time is available in addition to the transactions.  -Market Basket analysis: Payment by credit card or customer card; -Delivery Providers: collection of customer information e.g. based on orders received.However, this information is not usedin classical association analysis, although the inclusion of this additional information can significantly",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 4\nAssociationAnalysisBasic Terms",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 8\nAssociationAnalysisAlgorithmoverview\nSince the data sets are typically very large, efficient algorithms are required.The algorithms themselves generally search for all association rules that meet predefined minimum confidence and minimum support.Depending on how this is done, different procedures are known. The best known methods are from Agrarwal:",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 28\nAssociationAnalysis Multidimensional Variant\nClub Karstadt registrationform\nSpecial offer, Postalcode, branch,quantity,price,tag ...\nNote: To account for the \"environment\" variables, they are included and treated in the same way as the previous items (products) in the analysis.",
            "The ideacan be described as follows:-So-called association rules should be found that describe the correlation between items that occur together. -Thus, the identification of items A that imply the occurrence of other items B within a transaction should succeed. -A discovered relationshipbetween two or more items can then be represented as a rule of the form \"If item(set) A, then item(set) B\"or A \u00e0B, respectively. Examplesinclude the following:-Point-of-sale transactions-Financialand banking",
            "pricing or product placements. In addition to market basket analysis, association rules\nare  employed  today  in  application  areas  including  Web  usage  mining,  intrusion\ndetection, continuous production, and bioinformatics. In contrast with sequence mining,\nassociation rule learning typically does not consider the order of items either within a\ntransaction or across transactions.\nLearning  classifier  systems  (LCS)  are  a  family  of  rule-based  machine  learning",
            "Association rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting",
            "association analysis, although the inclusion of this additional information can significantly increase the meaningfulness of the rules (\u00e0sequence analysis)."
        ],
        "generated": "Items regarding Association Analysis are uninterpretable, discrete things or entities denoted by I. An association rule A \u00e0B consists of a set of items A in the rule body and a set of items B in the rule head, where A and B must be disjoint. Each transaction t consists of a set of items, and transactions considered in the association analysis are combined into a database D. A transaction t satisfies a rule A \u00e0B if (A\u00c8B) \u00cdt, meaning all items contained in the rule also occur in the transaction.",
        "ground_truth": "Items are uninterpretable, discrete things or entities."
    },
    {
        "query": "What types of statistics are there?",
        "retrieved": [
            "Even when the statistical assumption can be reasonably justified, there are several hypothesis test statistics that can be applied to detect anomalies; choosing the right one often poses a problem.\nHistogram based techniques are relatively simple to implement, but a key shortcoming of such techniques for multivariate data is that they are not able to capture the interactions between different attributes.",
            "means high chance of anomaly-Statistical tests are widely usedNon-parametric methods:-No probability distribution is assumed a-priori-Insteadthe distribution form is estimated based on the data",
            "Structuring the Field:3) Data Science Techniques",
            "Statistics= teaching in dealing with quantitative information (= data)\u2022Descriptiveor InductiveDescriptive StatisticsTask: Data should be prepared and graphically displayed.\u2022Concentration of the underlying extensive database on a few meaningful measures.\u2022In extreme cases, it is possible that a single number characterizes the entire data setInductive statisticsSummary of all methods needed for rational decision making under uncertainty or risk.Task: The properties of the population are derived",
            "\u201cStatistics:\u2022The science of the collection, organization, and interpretation of data, including the design of surveys and experiments. \u2022Statistical techniques are often used to make judgments about what relationships between variables could have occurred by chance (the \u201cnull hypothesis\u201d), and what relationships between variables likely result from some kind of underlying causal relationship (i.e., that are \u201cstatistically significant\u201d).\u2022Statistical techniques are also used to reduce the",
            "Different Types of AnalyticsTaking responsibilities for dedicated analytical tasks\nDescriptive AnalyticsQuestion: \u201cWhat is happening right now/ what happened in the past?\u201d Summarizingcollected data from various sources and providing aggregated measures and visualizationsIncluding traditional business intelligence tools: e.g.reports, dashboards, querying, online analytical processing (OLAP)",
            "Diagnostic AnalyticsQuestion: \u201cWhy did/ does it happen?\u201dExplanatory empirical modeling based on statistical inference and causal hypotheses testing\nPredictive AnalyticsQuestion: \u201cWhat is likely to happen?\u201dDeveloping prediction models with high accuracy by using a large amount of historical data, detecting complexandnon-trivial relationshipsand providing predictions and equivalent probability scores on new unclassified observations",
            "Furthermore, one still distinguishes: \u2015Agglomerativeand divisive methods. The former start from one-element classes and combine elements into classes step by step. Divisive methods,on the other hand, start from an initial decomposition which is refined (i.e., divided) step by step. \u2015Single-modal methods that group objects or features into classes, and dual-modalmethods that simultaneously classify objects and features of a data matrix.",
            "decision making under uncertainty or risk.Task: The properties of the population are derived from the data of the sample.\u2022Basis of inductive statistics: probability theory\u2022Objective: The statistical methods of inductive statistics serve to make predictions (e.g., about risks).",
            "Structuring the Field:4) Data Science Technologies",
            "(i.e., that are \u201cstatistically significant\u201d).\u2022Statistical techniques are also used to reduce the likelihood of Type I errors (\u201cfalse positives\u201d) and Type II errors (\u201cfalse negatives\u201d).\u201d(Manyika et al., 2011)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 39\nVariety of Data Analysis TechniquesWhich one to choose?\nHow do we know which technique/algorithm to choose?"
        ],
        "generated": "Based on the context provided, there are two types of statistics mentioned:\n\n1. Descriptive Statistics: This type of statistics involves dealing with quantitative information (data) by preparing and graphically displaying it. It focuses on summarizing the data into meaningful measures and can sometimes be represented by a single number characterizing the entire dataset.\n\n2. Inductive Statistics: This type of statistics involves deriving properties of the population based on the data. It includes all methods needed for rational decision-making under uncertainty or risk.",
        "ground_truth": "Descriptive statistics, Inductive statistics"
    },
    {
        "query": "What is Diversive Clustering?",
        "retrieved": [
            "DiversiveClusteringAll objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained.\n\u2022Starting point is the class of all objects.\u2022Successive transition to finer decompositions\u2022Termination as soon as given criterion is fulfilled",
            "Furthermore, one still distinguishes: \u2015Agglomerativeand divisive methods. The former start from one-element classes and combine elements into classes step by step. Divisive methods,on the other hand, start from an initial decomposition which is refined (i.e., divided) step by step. \u2015Single-modal methods that group objects or features into classes, and dual-modalmethods that simultaneously classify objects and features of a data matrix.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 2\nRecap: Aims of the cluster analysis\nSegmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that\u2022between the elements of the same classes the greatest possible similarity,\u2022between the elements of different classes the greatest possible diversity is achieved",
            "Basics ofsegmentation\nCluster types",
            "Several clustering algorithms force every instance to be assigned to some cluster.Several clustering based techniques are effective only when the anomalies do not form significant clusters among themselves.\nThe computational complexity for clustering the data is often a bottleneck.",
            "Aimsoftheclusteranalysis\n\u2015Segmentationorcluster analysis is used to group objects and/or characteristics into classes or groups, so that-between the elements of thesame classes as similar as possible,-between the elements of different classes the greatest possible dissimilarityis achieved.\u2015The clusters are not known beforehand.\u2015So-calledunsupervised learning methods are used, for example.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 35\nClustering basedAdvantages",
            "Clustering basedAdvantages\nClustering based techniques can operate in an unsupervised mode.Such techniques can often be adapted to other complex data types by simply plugging in a clustering algorithm that can handle the particular datatype.The testing phase for clustering basedtechniques is fast since the number of clusters against which every test instance needs to be compared is a small constant.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 34\nClustering basedOverview",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 5\nSubdivision ofclusterapproachesDisjunctiveand exhaustive methods"
        ],
        "generated": "Diversive Clustering is a clustering method where all objects initially belong to one cluster, which is then divided into sub-clusters. These sub-clusters are successively divided into their own sub-clusters until the desired cluster structure is obtained. The process continues until a given criterion is fulfilled.",
        "ground_truth": "All objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained."
    },
    {
        "query": "What is anomaly detection?",
        "retrieved": [
            "Anomaly Detection\nIntroduction",
            "Anomaly Detection\nMethods",
            "Data Science: Advanced Analytics\nAnomaly Detection",
            "IntroductionOverview\nDescription: Detections of patterns that do not conform to \u201enormal\u201c behavior\nApplication domains:-Fraud Detection (e.g., credit card fraud, tax fraud, etc.)-Intrusion Detection in cyber security-Fault Detection in safety critical systems-Military surveillance of enemies-\u2026Importance of anomalies: Anomalies often are indicators for situations that require critical decisionsExample: An anomalous pattern in network traffic could indicate a hacker attack",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 9\nMethodsCriteria for anomaly detection problem definition",
            "Distinction:-Anomaly Detection deals with detecting interesting, non-normal patterns-In contrast noise removal deals with detection and removal of unwanted outliersthat are not of interest-Novelty detection deals with new patterns that in contrast to anomalies can also be part of the \u201enormal\u201c behavior-The methods used are fairly similar, however anomaly detection seems to offer the biggest range of methods",
            "Even though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of",
            "MethodsCriteria for anomaly detection problem definition\nThere is NO general approach that works for all application domainsDifferent problem definitionsdepending on some basic criteria:-Nature of data-Labels-Anomaly Type-OutputAnomaly Detection methods can be found in many research fields:-Machine Learning (Data Mining)-Statistics-Information Theory-Spectral Theory-\u2026"
        ],
        "generated": "Anomaly detection is the process of detecting patterns that do not conform to normal behavior in various application domains such as fraud detection, intrusion detection in cybersecurity, fault detection in safety critical systems, military surveillance, and more. Anomalies are often indicators for situations that require critical decisions, such as detecting hacker attacks through anomalous patterns in network traffic.",
        "ground_truth": "Detections of patterns that do not conform to 'normal' behavior."
    },
    {
        "query": "What is a hierarchy regarding segmentation?",
        "retrieved": [
            "Quasi-hierarchicalsegmentationExample\nA quasi-hierarchy is a union of non-disjoint segmentations, i.e., a sequence of non-disjoint segmentations for one class, two classes, ..., n classes. An overlap of classes is not excluded. Furthermore, it holds that the union of all real subsets of a class K yields just K again.K= { {1}, ..., {5}, {1,2,3} {2,4,5}, {1,2,3,4,5} }\n1 2 3 4 5\n1 2 3 4 5\n1\n 2\n 3\n 4\n 5\n2.",
            "Basics ofSegmentation\nIntroduction",
            "\u2015Hierarchicalsegmentation methods are characterized by the fact that a cluster located at a higher fusion level completely contains the corresponding clusters located at a lower level. \u2015Non-hierarchical methods arebased on optimization methods that estimate class membership or attempt to iteratively improve classification quality by swapping elements between classes. \u2015Furthermore, a distinction is made between sharpand fuzzy segmentations. In the sharp approach, each object -if assigned to at",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 9\nHierarchicalsegmentationExample\nA hierarchy is a union of disjoint segmentations, i.e., a sequence of disjoint segmentations for one class, two classes, ..., n classes. An overlap of the classes is excluded.K= { {1}, ..., {5}, {1,2,3}, {4,5}, {1,2,3,4,5} }\"Union of decompositions\"\n1\n 2\n 3\n 4\n 5\n1 2 3 4 5\n1 2 3 4 5",
            "Basics ofsegmentation\nLaunch heuristics",
            "HierarchicalClustering Methods\nforSegmentation",
            "Basics ofsegmentation\nEvaluation criteria",
            "Basics ofsegmentation\nCluster types"
        ],
        "generated": "A hierarchy regarding segmentation is a union of disjoint segmentations, which means it is a sequence of disjoint segmentations for one class, two classes, ..., n classes where an overlap of the classes is excluded.",
        "ground_truth": "A hierarchy is a union of disjoint segmentations, i.e., a sequence of disjoint segmentations for one class, two classes, ..., n classes. An overlap of the classes is excluded."
    },
    {
        "query": "What is the definition of Machine Learning by Samuel (1959)?",
        "retrieved": [
            "The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and\npioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym\nself-teaching computers was also used in this time period.[10][11]",
            "\u201cMachine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.\u201d (Samuel, 1959)\u201cA subspecialty of computer science (within a field historically called \u201cartificial intelligence\u201d) concerned with the design and development of algorithms that allow computers to evolve behaviors based on empirical data. A major focus of machine learning research is to automatically learn to recognize complex patterns and make intelligent decisions based on data.\u201d",
            "Although the earliest machine learning model was introduced in the 1950s when Arthur\nSamuel  invented  a  program  that  calculated  the  winning  chance  in  checkers  for  each\nside, the history of machine learning roots back to decades of human desire and effort\nto study human cognitive processes.[12] In 1949, Canadian psychologist Donald Hebb\npublished the book The Organization of Behavior, in which he introduced a theoretical",
            "Tom  M.  Mitchell  provided  a  widely  quoted,  more  formal  definition  of  the  algorithms\nstudied  in  the  machine  learning  field:  \"A  computer  program  is  said  to  learn  from\nexperience E with respect to some class of tasks T and performance measure P if its\nperformance at tasks in T, as measured by P,  improves with experience E.\"[18] This\ndefinition of the tasks in which machine learning is concerned offers a fundamentally",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 27\nMachine LearningA formal problem definition proposed by Mitchell (1997)\nGoal: Generalize the experience in a way that allows to improve your performance on the task.Given:a task T,a performance measure P,some experience E with the taskExamples:",
            "Machine Learning\nMachine  learning  (ML)  is  a  field  of  study  in  artificial  intelligence  concerned  with  the\ndevelopment and study of statistical algorithms that can learn from data and generalize\nto  unseen  data,  and  thus  perform  tasks  without  explicit  instructions.[1]  Within  a\nsubdiscipline in machine learning, advances in the field of deep learning have allowed\nneural  networks,  a  class  of  statistical  algorithms,  to  surpass  many  previous  machine",
            "to automatically learn to recognize complex patterns and make intelligent decisions based on data.\u201d (Manyikaet al., 2011)Machine Learning explores the study and construction of algorithms that can learn from and make predictions on data. Such algorithms overcome following strictly static program instructions by making data-driven predictions or decisions through building a model from sample inputs. (Bishop, 2006)"
        ],
        "generated": "The definition of Machine Learning by Samuel (1959) is: \"Field of study that gives computers the ability to learn without being explicitly programmed.\"",
        "ground_truth": "Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed."
    }
]