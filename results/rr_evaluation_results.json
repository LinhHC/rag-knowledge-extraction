[
    {
        "query": "What is a hierarchy regarding segmentation?",
        "retrieved": [
            "\u2015Hierarchicalsegmentation methods are characterized by the fact that a cluster located at a higher fusion level completely contains the corresponding clusters located at a lower level. \u2015Non-hierarchical methods arebased on optimization methods that estimate class membership or attempt to iteratively improve classification quality by swapping elements between classes. \u2015Furthermore, a distinction is made between sharpand fuzzy segmentations. In the sharp approach, each object -if assigned to at",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 9\nHierarchicalsegmentationExample\nA hierarchy is a union of disjoint segmentations, i.e., a sequence of disjoint segmentations for one class, two classes, ..., n classes. An overlap of the classes is excluded.K= { {1}, ..., {5}, {1,2,3}, {4,5}, {1,2,3,4,5} }\"Union of decompositions\"\n1\n 2\n 3\n 4\n 5\n1 2 3 4 5\n1 2 3 4 5",
            "Quasi-hierarchicalsegmentationExample\nA quasi-hierarchy is a union of non-disjoint segmentations, i.e., a sequence of non-disjoint segmentations for one class, two classes, ..., n classes. An overlap of classes is not excluded. Furthermore, it holds that the union of all real subsets of a class K yields just K again.K= { {1}, ..., {5}, {1,2,3} {2,4,5}, {1,2,3,4,5} }\n1 2 3 4 5\n1 2 3 4 5\n1\n 2\n 3\n 4\n 5\n2.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 7\nSubdivision ofclusterapproachesHierarchicaland sharp methods\n\u2015Hierarchicalsegmentation methods are characterized by the fact that a cluster located at a higher fusion level completely contains the corresponding clusters located at a lower level. \u2015Non-hierarchical methods arebased on optimization methods that estimate class membership or attempt to iteratively improve classification quality by swapping elements between classes. \u2015Furthermore, a distinction is made between sharpand fuzzy segmentations. In the sharp approach, each object -if assigned to at least one class -is uniquely assigned to the corresponding class. In the fuzzy approach, there is no clear assignment to a class. Instead, share values are assigned that determine the degree to which an object belongs to a class.",
            "Basics ofSegmentation\nIntroduction",
            "Basics ofsegmentation\nLaunch heuristics",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 10\nQuasi-hierarchicalsegmentationExample\nA quasi-hierarchy is a union of non-disjoint segmentations, i.e., a sequence of non-disjoint segmentations for one class, two classes, ..., n classes. An overlap of classes is not excluded. Furthermore, it holds that the union of all real subsets of a class K yields just K again.K= { {1}, ..., {5}, {1,2,3} {2,4,5}, {1,2,3,4,5} }\n1 2 3 4 5\n1 2 3 4 5\n1\n 2\n 3\n 4\n 5\n2.",
            "Basics ofsegmentation\nCluster types",
            "Basics ofsegmentation\nEvaluation criteria",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 11\nChoice ofsegmentationtype \nFurther requirements for the classification type arise \u2015from the problem definition,\u2015of the required number of classes, \u2015Upper or lower limits for the number of objectsin the classes \u2015etc. The segmentation method is then also derived from the desired classification type.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 5\nSubdivision ofclusterapproachesDisjunctiveand exhaustive methods\n\u2015First, a distinction is made between disjointand non-disjointsegmentations, where in the first case a given element may be assigned to only one class, in the second case to several classes.\u2015A segmentation K = {K1, K2, ... } of the set !is thus called \u2022disjointif holds:\"!,\"\"$,%\u2260'\"(=\u00d8\u2022non-disjointif holds:\"!,\"\"$,\u2203,$:,\"!\u2227,\"\",%\u2260'\u2015In addition, a distinction is also made between exhaustivemethods, in which each element is assigned to at least one class, and non-exhaustivemethods, which allow unclassified elements.\u2015A segmentation K = {K1, K2, ... } of the set !is thus called \u2022exhaustiveif applies:\u2022non-exhaustiveif applies:/#!\u2208%\"!=!/#!\u2208%\"!\u2282!",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 5\nPartionalClustering Methods\nPartitioning methods are segmentation methods which divide the set of objects N on the basis of a fixed number of classes s in such a way that the computed segmentation or partition Kminimizes a given quality index b(K):\n{ }\ns\n1s i i j(( N ) ) i1\nmin b( ) : K , ,K ,    K N,    K K\u00ce\u00c3 \u00c3 =\n\u00ec\u00fc == \u00c7 = \u00c6\u00ed\u00fd\u00ee\u00fe\nK UK",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 39\nVariety of Data Analysis TechniquesWhich one to choose?\nHow do we know which technique/algorithm to choose?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 9\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nBreaking down the business problem into componentsReduce complexity/ increase transparency\nUsage of information technology to compute standard measures to quickly identify objects of interestFor example: Computation of correlation measures between hundreds of variables\n\u201cThe relationship between the business problem and the analytics solution often can be decomposed into tractable sub-problems via the framework of analyzing expected value.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)\n\u201cInformation technology can be used to find informative data items from within a large body of data.\u201d",
            "7-level CNN by Yann LeCun et al., that classifies digits, was applied by several banks to\nrecognize hand-written numbers on checks  digitized in 32x32 pixel images.[64]\nRecurrent  neural  networks  (RNN)[28][30]  were  further  developed  in  the  1980s.\nRecurrence is used for sequence processing, and when a recurrent network is unrolled,\nit mathematically resembles a deep feedforward layer. Consequently, they have similar\nproperties and issues, and their developments had mutual influences. In RNN, two early\ninfluential  works  were  the  Jordan  network  (1986)[65]  and  the  Elman  network\n(1990),[66] which applied RNN to study problems in cognitive psychology.\nIn  the  1980s,  backpropagation  did  not  work  well  for  deep  learning  with  long  credit\nassignment paths. To overcome this problem, in 1991, J\u00fcrgen Schmidhuber proposed a\nhierarchy  of  RNNs  pre-trained  one  level  at  a  time  by  self-supervised  learning  where\neach RNN tries to predict its own next input, which is the next unexpected input of the\nRNN  below.[67][68]  This  \"neural  history  compressor\"  uses  predictive  coding   to  learn\ninternal  representations  at  multiple  self-organizing  time  scales.  This  can  substantially\nfacilitate downstream deep learning. The RNN hierarchy can be collapsed into a single\nRNN,  by   distilling  a  higher  level  chunker  network  into  a  lower  level  automatizer\nnetwork.[67][68][31]  In  1993,  a  neural  history  compressor  solved  a  \"Very  Deep\nLearning\" task that required more than 1000 subsequent layers in an RNN unfolded in\ntime.[69] The \"P\" in ChatGPT refers to such pre-training.\nSepp  Hochreiter's  diploma  thesis  (1991)[70]  implemented  the  neural  history\ncompressor,[67] and identified and analyzed the vanishing gradient problem.[70][71]",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 81\nText mining methodsDependency analyses\nDependency analyses map dependencies between termsIn contrast to classification and segmentation methods, these dependencies are calculated over the entire data setThis means that these results apply to all documents in the datasetBy determining term dependencies and linking these terms to term networks, ontologies can be created automatically\nMethods used in the literature:Association analysisCoocurrence analysis",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 54\nDocument preparationSemantic analysis\nTarget: Examination of linguistic aspects of the textsStudy of the meaning of words in the sentenceProcedure:Collocations: Collocations frequently occurring word combinations that are found in a certain discourse area.Thesauruses and ontologies:Ontologiesform concepts and relationship between these terms and servetherepresentation of knowledgestructures; thus they enable computers both logical reasoningand the recognition of context.\nTerme filtern\nLexikalische \nAnalyse \ndurchf\u00fchren\nSyntaktische \nAnalyse \ndurchf\u00fchren\nSemantische \nAnalyse \ndurchf\u00fchren\nZus\u00e4tzliche \nHilfsmittelProblemstellung",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 5\nAssociationAnalysisSupport and Confidence\n{ }tD ( AB ) tsup( A B ) D\n\u00ce\u00c8 \u00cd\u00ae =\n{ }\n{ }\ntD ( AB ) t sup( A B )conf(A B ) tD A t s u p ( A )\n\u00ce\u00c8 \u00cd \u00ae\u00ae == \u00ce\u00cd\nThe Supportof a rule is defined as the proportion of transactions from D that satisfy that rule:\nThe Confidenceof a rule is defined as the proportion of transactions involving A and B in the set of transactions satisfying the rule body A. The formal representation is:",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "classification or predictions. This technique allows reconstruction of the inputs coming\nfrom the unknown data-generating distribution, while not being necessarily faithful to\nconfigurations that are implausible under that distribution. This replaces manual feature\nengineering, and allows a machine to both learn the features and use them to perform\na specific task.\nFeature  learning  can  be  either  supervised  or  unsupervised.  In  supervised  feature\nlearning,  features  are  learned  using  labeled  input  data.  Examples  include  artificial\nneural  networks,  multilayer  perceptrons,  and  supervised  dictionary  learning.  In\nunsupervised  feature  learning,  features  are  learned  with  unlabeled  input  data.  \nExamples include dictionary learning, independent component analysis, autoencoders,\nmatrix factorization[64] and various forms of clustering.[65][66][67]\nManifold  learning  algorithms  attempt  to  do  so  under  the  constraint  that  the  learned\nrepresentation is low-dimensional. Sparse coding algorithms attempt to do so under the\nconstraint  that  the  learned  representation  is  sparse,  meaning  that  the  mathematical\nmodel  has  many  zeros.  Multilinear  subspace  learning  algorithms  aim  to  learn\nlow-dimensional  representations  directly  from  tensor  representations  for\nmultidimensional  data,  without  reshaping  them  into  higher-dimensional  vectors.[68]\nDeep learning algorithms discover multiple levels of representation, or a hierarchy of\nfeatures, with higher-level, more abstract features defined in terms of (or generating)\nlower-level features. It has been argued that an intelligent machine is one that learns a\nrepresentation  that  disentangles  the  underlying  factors  of  variation  that  explain  the\nobserved data.[69]",
            "RFR compatible to be used in various application. [89][90]\nSupport-vector machines (SVMs), also known as support-vector networks, are a set of\nrelated supervised learning methods used for classification and regression. Given a set\nof  training  examples,  each  marked  as  belonging  to  one  of  two  categories,  an  SVM\ntraining algorithm builds a model that predicts whether a new example falls into one\ncategory.[91] An SVM training algorithm is a non-probabilistic, binary, linear classifier,\nalthough methods such as Platt scaling exist to use SVM in a probabilistic classification\nsetting.  In  addition  to  performing  linear  classification,  SVMs  can  efficiently  perform  a\nnon-linear  classification  using  what  is  called  the  kernel  trick,  implicitly  mapping  their\ninputs into high-dimensional feature spaces.\nRegression analysis encompasses a large variety of statistical methods to estimate the\nrelationship  between  input  variables  and  their  associated  features.  Its  most  common\nform  is  linear  regression,  where  a  single  line  is  drawn  to  best  fit  the  given  data\naccording to a mathematical criterion such as ordinary least squares. The latter is often\nextended  by  regularization  methods  to  mitigate  overfitting  and  bias,  as  in  ridge\nregression.  When  dealing  with  non-linear  problems,  go-to  models  include  polynomial\nregression  (for  example,  used  for  trendline  fitting  in  Microsoft  Excel[92]),  logistic\nregression  (often  used  in  statistical  classification)  or  even  kernel  regression,  which\nintroduces non-linearity by taking advantage of the kernel trick to implicitly map input\nvariables to higher-dimensional space.\nMultivariate  linear  regression  extends  the  concept  of  linear  regression  to  handle",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 32\nStatisticsDefinition\n\u201cStatistics:\u2022The science of the collection, organization, and interpretation of data, including the design of surveys and experiments. \u2022Statistical techniques are often used to make judgments about what relationships between variables could have occurred by chance (the \u201cnull hypothesis\u201d), and what relationships between variables likely result from some kind of underlying causal relationship (i.e., that are \u201cstatistically significant\u201d).\u2022Statistical techniques are also used to reduce the likelihood of Type I errors (\u201cfalse positives\u201d) and Type II errors (\u201cfalse negatives\u201d).\u201d(Manyika et al., 2011)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 20\nSome Definitions\u2026 \u2026 collected by Chatfield et al. (2014)\nSource Definition: Data scientists are \u2026\nGranville (2014) \u201cnot statisticians, nor data analysts, nor computer scientists, nor software engineers, nor\nbusiness analysts. They have some knowledge in each of these areas but also some outside\nof these areas.\u201d\nDhar (2013) \u201crequires an integrated skill set spanning mathematics, machine learning, artificial\nintelligence, statistics, databases, and optimization, along with a deep understanding of the\ncraft of problem formulation to engineer effective solutions.\u201d\nDavenport & Patil (2012) \u201cthe people who understand how to fish out answers to important business questions from\ntoday\u2019s tsunami of unstructured information.\u201d\nMohanty et al. (2013) \u201cthe practitioners of the analytics models solving business problems. They incorporate\nadvanced analytical approaches using sophisticated analytics and data visualization tools to\ndiscover patterns in data. In many cases, these practitioners work with well-established\nanalytics techniques such as logistic regression methods, clustering methods, and\nclassification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,\nexplore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "meaning  that  even  the  coders  of  the  algorithm  cannot  audit  the  pattern  that  the\nmachine extracted out of the data.[123] The House of Lords Select Committee, which\nclaimed that such an \"intelligence system\" that could have a \"substantial impact on an\nindividual's  life\"  would  not  be  considered  acceptable  unless  it  provided  \"a  full  and\nsatisfactory explanation for the decisions\" it makes.[123]\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a\ncollision.[124]  Attempts  to  use  machine  learning  in  healthcare  with  the  IBM  Watson\nsystem  failed  to  deliver  even  after  years  of  time  and  billions  of  dollars\ninvested.[125][126] Microsoft's Bing Chat chatbot has been reported to produce hostile\nand offensive response against its users.[127]\nMachine  learning  has  been  used  as  a  strategy  to  update  the  evidence  related  to  a\nsystematic review and increased reviewer burden related to the growth of biomedical\nliterature. While it has improved with training sets, it has not yet developed sufficiently\nto reduce the workload burden without limiting the necessary sensitivity for the findings\nresearch themselves.[128]\nExplainable  AI  (XAI),  or  Interpretable  AI,  or  Explainable  Machine  Learning  (XML),  is\nartificial intelligence (AI) in which humans can understand the decisions or predictions\nmade  by  the  AI.[129]  It  contrasts  with  the  \"black  box\"  concept  in  machine  learning\nwhere even its designers cannot explain why an AI arrived at a specific decision.[130]\nBy  refining  the  mental  models  of  users  of  AI-powered  systems  and  dismantling  their\nmisconceptions,  XAI  promises  to  help  users  perform  more  effectively.  XAI  may  be  an"
        ],
        "generated": "A hierarchy regarding segmentation is a union of disjoint segmentations, where there is a sequence of disjoint segmentations for one class, two classes, and so on, up to n classes. In this hierarchy, an overlap of the classes is excluded.",
        "ground_truth": "A hierarchy is a union of disjoint segmentations, i.e., a sequence of disjoint segmentations for one class, two classes, ..., n classes. An overlap of the classes is excluded."
    },
    {
        "query": "What are the application domains of anomaly detection?",
        "retrieved": [
            "MethodsCriteria for anomaly detection problem definition\nThere is NO general approach that works for all application domainsDifferent problem definitionsdepending on some basic criteria:-Nature of data-Labels-Anomaly Type-OutputAnomaly Detection methods can be found in many research fields:-Machine Learning (Data Mining)-Statistics-Information Theory-Spectral Theory-\u2026",
            "Anomaly Detection\nIntroduction",
            "Data Science: Advanced Analytics\nAnomaly Detection",
            "Anomaly Detection\nMethods",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 9\nMethodsCriteria for anomaly detection problem definition\nThere is NO general approach that works for all application domainsDifferent problem definitionsdepending on some basic criteria:-Nature of data-Labels-Anomaly Type-OutputAnomaly Detection methods can be found in many research fields:-Machine Learning (Data Mining)-Statistics-Information Theory-Spectral Theory-\u2026",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 43\nAnomaly DetectionSummary\nEven though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation, etc. that are used in another context.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 4\nIntroductionOverview\nAnomalous patterns are often referred to as anomalies, outliers, discordant observations, exceptions, aberrations, surprises, peculiarities orcontaminants in different application domainsWe will use the term anomalyMain reference: Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A Survey. ACM Computing Surveys, 41(3), 1\u201358. \nDistinction:-Anomaly Detection deals with detecting interesting, non-normal patterns-In contrast noise removal deals with detection and removal of unwanted outliersthat are not of interest-Novelty detection deals with new patterns that in contrast to anomalies can also be part of the \u201enormal\u201c behavior-The methods used are fairly similar, however anomaly detection seems to offer the biggest range of methods",
            "In particular, in the context of abuse and network intrusion detection, the interesting\nobjects are often not rare objects, but unexpected bursts of inactivity. This pattern does\nnot  adhere  to  the  common  statistical  definition  of  an  outlier  as  a  rare  object.  Many\noutlier detection methods (in particular, unsupervised algorithms) will fail on such data\nunless aggregated appropriately. Instead, a cluster analysis algorithm may be able to\ndetect the micro-clusters formed by these patterns.[74]\nThree  broad  categories  of  anomaly  detection  techniques  exist.[75]  Unsupervised\nanomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised\nanomaly detection techniques require a data set that has been labeled as \"normal\" and\n\"abnormal\"  and  involves  training  a  classifier  (the  key  difference  from  many  other\nstatistical  classification  problems  is  the  inherently  unbalanced  nature  of  outlier\ndetection).  Semi-supervised  anomaly  detection  techniques  construct  a  model\nrepresenting normal behavior from a given normal training data set and then test the\nlikelihood of a test instance to be generated by the model.\nRobot learning is inspired by a multitude of machine learning methods, starting from\nsupervised  learning,  reinforcement  learning,[76][77]  and  finally  meta-learning  (e.g.\nMAML).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 7\nIntroductionChallenges\nDefining anormal region which encompasses every possible normal behavior is very difficult. When anomalies are the result of malicious actions, the malicious adversaries often adapt themselves to make the anomalous observations appear like normal.In many domains normal behavior keeps evolving and a current notion of normal behavior might not be sufficiently representative in the future.The exact notion of an anomaly is different for different application domains.\nAvailability of labeled data for training/validation of models used by anomaly detection techniques is usually a major issue.\nOften the data contains noise which tends to be similar tothe actual anomalies and hence is difficult to distinguish and remove.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 13\nMethodsCriteria: Data labels and Output\nTo classifya data instance as normal or anomalous one can use labels:Labeling data is costly and expensiveGetting labels for all kinds of anomalous behavior is nearly impossibleNormal class easier to labelDepending on the availability of labeled data there are three approaches:Supervised anomaly detection:assumes labels for both classesSemi-supervised: only assumes labels for the normal classUnsupervised: does not assume labelsThe outputsof an anomaly detection method can be:Scores: Scores how unusual the anomaly is compared to normal; ranking of the data objects possibleLabels: Labels the data instance either anomalous or normal",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 40\nStatistical methodsNon-parametric methods\nHistogram based:-(1) Build a histogram to resemble the distribution f of the data-(2) Anomaly score based on the height of the bin in which the data object falls; simpler version: if it does not fit to any binit is considered an anomaly-Definition for bin size is the key factor:\u00a7If there are small bins only, many normal cases fall in rare bins\u00a7If there are large bins only, many rare cases end up in normal bins-Multivariate version: Combine univariate scores to a data set score-Variants are often timesused in Intrusion detection (ALAD and PHAD)Kernel Function based:-Similar toparametric anomaly detection but the probability function is estimated based on the data-E.g.: ParzenWindow Estimation",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 39\nStatistical methodsParametric methods: other methods\nRegression based:(1) Regression is estimated(2) for each data object the residual score resembles the anomaly scoreSome criteria used to detect anomalies in a regressions setting:\u2014AIC: anomalies influence regression results\u2014Robust regression: should be used to avoid anomaly influences \u00f0residuals for anomalies are considerably larger in this setting\u2014ARIMA/ARMA: detection of anomalies in a time series settingMixture distribution based: Two approaches -Different distributions for normal data and anomalies or mixed distribution for only the normal class",
            "One  of  the  most  prominent  application  fields  is  medical  computer  vision,  or  medical\nimage  processing,  characterized  by  the  extraction  of  information  from  image  data  to\ndiagnose a patient. An example of this is the detection of tumours, arteriosclerosis or\nother  malign  changes,  and  a  variety  of  dental  pathologies;  measurements  of  organ\ndimensions, blood flow, etc. are another example. It also supports medical research by\nproviding  new  information:  e.g.,  about  the  structure  of  the  brain  or  the  quality  of\nmedical  treatments.  Applications  of  computer  vision  in  the  medical  area  also  include\nenhancement of images interpreted by humans\u2014ultrasonic images or X-ray images, for\nexample\u2014to reduce the influence of noise.\nA second application area in computer vision is in industry, sometimes called machine\nvision,  where  information  is  extracted  for  the  purpose  of  supporting  a  production\nprocess.  One  example  is  quality  control  where  details  or  final  products  are  being\nautomatically  inspected  in  order  to  find  defects.  One  of  the  most  prevalent  fields  for\nsuch  inspection  is  the  Wafer  industry  in  which  every  single  Wafer  is  being  measured\nand inspected for inaccuracies or defects to prevent a computer chip from coming to\nmarket in an unusable manner. Another example is a measurement of the position and\norientation  of  details  to  be  picked  up  by  a  robot  arm.  Machine  vision  is  also  heavily\nused in the agricultural processes to remove undesirable foodstuff from bulk material, a\nprocess called optical sorting.[32]\nMilitary applications are probably one of the largest areas of computer vision[citation\nneeded].  The  obvious  examples  are  the  detection  of  enemy  soldiers  or  vehicles  and\nmissile guidance. More advanced systems for missile guidance send the missile to an\narea  rather  than  a  specific  target,  and  target  selection  is  made  when  the  missile",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "and providing high-level information about the environment and the robot\nBesides the above-mentioned views on computer vision, many of the related research\ntopics  can  also  be  studied  from  a  purely  mathematical  point  of  view.  For  example,\nmany  methods  in  computer  vision  are  based  on  statistics,  optimization  or  geometry.\nFinally,  a  significant  part  of  the  field  is  devoted  to  the  implementation  aspect  of\ncomputer  vision;  how  existing  methods  can  be  realized  in  various  combinations  of\nsoftware  and  hardware,  or  how  these  methods  can  be  modified  in  order  to  gain\nprocessing speed without losing too much performance. Computer vision is also used in\nfashion eCommerce, inventory management, patent search, furniture, and the beauty\nindustry.[23]\nThe fields most closely related to computer vision are image processing, image analysis\nand  machine  vision.  There  is  a  significant  overlap  in  the  range  of  techniques  and\napplications that these cover. This implies that the basic techniques that are used and\ndeveloped in these fields are similar, something which can be interpreted as there is\nonly one field with different names. On the other hand, it appears to be necessary for\nresearch groups, scientific journals, conferences, and companies to present or market\nthemselves  as  belonging  specifically  to  one  of  these  fields  and,  hence,  various\ncharacterizations  which  distinguish  each  of  the  fields  from  the  others  have  been\npresented. In image processing, the input is an image and the output is an image as\nwell,  whereas  in  computer  vision,  an  image  or  a  video  is  taken  as  an  input  and  the\noutput could be an enhanced image, an understanding of the content of an image or\neven behavior of a computer system based on such understanding."
        ],
        "generated": "The application domains of anomaly detection include medical computer vision, industry (machine vision), military applications, and various other fields such as agriculture and quality control.",
        "ground_truth": "- Fraud Detection (e.g., credit card fraud, tax fraud, etc.) - Intrusion Detection in cyber security - Fault Detection in safety critical systems - Military surveillance of enemies."
    },
    {
        "query": "What are the different types of analytics?",
        "retrieved": [
            "Different Types of AnalyticsTaking responsibilities for dedicated analytical tasks\nDescriptive AnalyticsQuestion: \u201cWhat is happening right now/ what happened in the past?\u201d Summarizingcollected data from various sources and providing aggregated measures and visualizationsIncluding traditional business intelligence tools: e.g.reports, dashboards, querying, online analytical processing (OLAP)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 24\nDifferent Types of AnalyticsTaking responsibilities for dedicated analytical tasks\nDescriptive AnalyticsQuestion: \u201cWhat is happening right now/ what happened in the past?\u201d Summarizingcollected data from various sources and providing aggregated measures and visualizationsIncluding traditional business intelligence tools: e.g.reports, dashboards, querying, online analytical processing (OLAP)\nDiagnostic AnalyticsQuestion: \u201cWhy did/ does it happen?\u201dExplanatory empirical modeling based on statistical inference and causal hypotheses testing\nPredictive AnalyticsQuestion: \u201cWhat is likely to happen?\u201dDeveloping prediction models with high accuracy by using a large amount of historical data, detecting complexandnon-trivial relationshipsand providing predictions and equivalent probability scores on new unclassified observations\nPrescriptive AnalyticsQuestions: \u201cWhat should be done / why should it be done?\u201dMathematical techniques (e.g.optimization, simulation) that computationally determine a set of high-value alternative actions or decisions given a complex set of objectives, requirements and constraints",
            "Data Science: Advanced Analytics \nProcess Analytics",
            "Diagnostic AnalyticsQuestion: \u201cWhy did/ does it happen?\u201dExplanatory empirical modeling based on statistical inference and causal hypotheses testing\nPredictive AnalyticsQuestion: \u201cWhat is likely to happen?\u201dDeveloping prediction models with high accuracy by using a large amount of historical data, detecting complexandnon-trivial relationshipsand providing predictions and equivalent probability scores on new unclassified observations",
            "Data Science: Advanced Analytics\nContent",
            "Data Science: Advanced Analytics\nIntroduction",
            "classification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 42\nTop Techniquesidentified by TDWI Research\n\u201cWhat are the most popular techniques for predictive analytics in your organization?\u201d\nReference: Fern Halper: Predictive Analytics for Business Advantage. TDWI Best Practice Report. TDWI Research, First Quarter, 2014.\n5%5%6%11%12%16%17%30%47%51%57%59%\n6%7%2%10%11%18%7%28%45%40%57%47%\n0%10%20%30%40%50%60%Ensemble learningSupport vector machinesAssociation rule learningOther regressionTime series modelsDecision trees\nInvestigatingActive",
            "Structuring the Field:3) Data Science Techniques",
            "Anomaly Detection\nMethods",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 9\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nBreaking down the business problem into componentsReduce complexity/ increase transparency\nUsage of information technology to compute standard measures to quickly identify objects of interestFor example: Computation of correlation measures between hundreds of variables\n\u201cThe relationship between the business problem and the analytics solution often can be decomposed into tractable sub-problems via the framework of analyzing expected value.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)\n\u201cInformation technology can be used to find informative data items from within a large body of data.\u201d",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 20\nSome Definitions\u2026 \u2026 collected by Chatfield et al. (2014)\nSource Definition: Data scientists are \u2026\nGranville (2014) \u201cnot statisticians, nor data analysts, nor computer scientists, nor software engineers, nor\nbusiness analysts. They have some knowledge in each of these areas but also some outside\nof these areas.\u201d\nDhar (2013) \u201crequires an integrated skill set spanning mathematics, machine learning, artificial\nintelligence, statistics, databases, and optimization, along with a deep understanding of the\ncraft of problem formulation to engineer effective solutions.\u201d\nDavenport & Patil (2012) \u201cthe people who understand how to fish out answers to important business questions from\ntoday\u2019s tsunami of unstructured information.\u201d\nMohanty et al. (2013) \u201cthe practitioners of the analytics models solving business problems. They incorporate\nadvanced analytical approaches using sophisticated analytics and data visualization tools to\ndiscover patterns in data. In many cases, these practitioners work with well-established\nanalytics techniques such as logistic regression methods, clustering methods, and\nclassification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,\nexplore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 10\nMethodsCriteria: Nature of Input Data\nRecall that input data are attributes (variables) measured for data instances(or data objects), e.g.measuring weight and blood pressure (attributes) of several patients (data objects) in a hospital \nScale: Attributes can be measured on different scale levels (nominal, ordinal, interval, ratio) \u00f0different techniques for different scale levels\nRelationship between data instances: data objects can have different types of relationship to each other-Sequential-Spatial-Graph data\u00f0Those relationships can be useful to determine anomalies",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 24\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n2.1 Introduction to Segmentation\n2.2 Cluster types\n2.3 Distance measures\n2.4 Evaluation criteria \n2.5 Start heuristics",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 3\nArtificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in the input layer, you have as many nodes as input varibales + a constant (=bias)\u00a7Hidden units: Nodes in the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing the various outputs-Connection:\u00a7Each node is connected to the succeeding node (one direction only)\u00a7Each connection has a weight that need to be learned from the data\nIdothecalculations)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 19\nDifferent Expectations\u2026\u2026 what people think I do \nWhat my friends think I \ndo\nWhat my mother thinks I \ndo\nWhat my boss thinks I do\nWhat I really doWhat I think I doWhat society thinks I do",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 31\nNeighbor basedRelative density: LOF Variations\nVariations:ODIN:simpler version of LOFMDEF:variation of LOF \u2013based on the standard deviation of the local densitiesCOF:variation with an incremental calculation of the k-neighborhoodOther variations to improve computation time and support for other data types (e.g.sequence data)LOF vs. COF neighborhood",
            "is composed of handwritten digits and includes 60,000 training examples and 10,000\ntest  examples.  As  with  TIMIT,  its  small  size  lets  users  test  multiple  configurations.  A\ncomprehensive list of results on this set is available.[185]\nDeep  learning-based  image  recognition  has  become  \"superhuman\",  producing  more\naccurate results than human contestants. This first occurred in 2011 in recognition of\ntraffic signs, and in 2014, with recognition of human faces.[186][187]\nDeep learning-trained vehicles now interpret 360\u00b0 camera views.[188] Another example\nis  Facial  Dysmorphology  Novel  Analysis  (FDNA)  used  to  analyze  cases  of  human\nmalformation connected to a large database of genetic syndromes.\nClosely  related  to  the  progress  that  has  been  made  in  image  recognition  is  the\nincreasing  application  of  deep  learning  techniques  to  various  visual  art  tasks.  DNNs\nhave proven themselves capable, for example, of\nNeural  networks  have  been  used  for  implementing  language  models  since  the  early\n2000s.[150]  LSTM  helped  to  improve  machine  translation  and  language\nmodeling.[151][152][153]\nOther  key  techniques  in  this  field  are  negative  sampling[191]  and  word  embedding.\nWord embedding, such as word2vec, can be thought of as a representational layer in a",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail."
        ],
        "generated": "The different types of analytics mentioned in the context are:\n1. Descriptive Analytics\n2. Diagnostic Analytics\n3. Predictive Analytics\n4. Prescriptive Analytics",
        "ground_truth": "Descriptive Analytics, Diagnostic Analytics, Predictive Analytics, Prescriptive Analytics"
    },
    {
        "query": "What types of layers are in CNN?",
        "retrieved": [
            "Our CNN Architecture contains multiple layer types:\u00a7Conv2D: CNN Layer with 32 filters, shape 3x3 with ReLU Layer appended\u00a7MaxPooling2D: Pooling layer with shape 3x3\u00a7Dropout: Randomly drop 20% of neurons to prevent overfitting\u00a7Flatten: Prepare filter results for classification\u00a7Dense: Fully connected layers for classificationfrom keras.models import Sequentialfrom keras.layers import Dense, Flatten, Dropoutfrom keras.layers import Conv2D, MaxPooling2Dmodel = Sequential()model.add(Conv2D(32, (3,",
            "Convolutional Neural Network: Overview\nStack layers to build a complete CNNOne type of layer is the previously mentioned \u201econvolutional layer\u201cIn total there are 4 types of layers:\u00a7Convolutional Layer (Extract features)\u00a7Pooling Layer (Reduce size)\u00a7ReLU Layer (Remove negative values \u00e0 disregard information about missing features)\u00a7Fully Connected Layer (Classify features)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 27\n3. Build layers\nOur CNN Architecture contains multiple layer types:\u00a7Conv2D: CNN Layer with 32 filters, shape 3x3 with ReLU Layer appended\u00a7MaxPooling2D: Pooling layer with shape 3x3\u00a7Dropout: Randomly drop 20% of neurons to prevent overfitting\u00a7Flatten: Prepare filter results for classification\u00a7Dense: Fully connected layers for classificationfrom keras.models import Sequentialfrom keras.layers import Dense, Flatten, Dropoutfrom keras.layers import Conv2D, MaxPooling2Dmodel = Sequential()model.add(Conv2D(32, (3, 3), input_shape=(x_train.shape[1:]), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Conv2D(32, (3, 3), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Dropout(0.2))model.add(Flatten())model.add(Dense(128, activation='relu'))model.add(Dense(num_classes, activation='softmax'))model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 12\nConvolutional Neural Network: Overview\nStack layers to build a complete CNNOne type of layer is the previously mentioned \u201econvolutional layer\u201cIn total there are 4 types of layers:\u00a7Convolutional Layer (Extract features)\u00a7Pooling Layer (Reduce size)\u00a7ReLU Layer (Remove negative values \u00e0 disregard information about missing features)\u00a7Fully Connected Layer (Classify features)\nLECUN, YANN; BENGIO, YOSHUA: Convolutional Networks for Images, Speech, and Time-Series. In M. A. Arbib(Ed.),The handbook of brain theory and neural networksMIT Press (1995).\nConvolution\nReLU\nPooling\u2026\nFully-ConnectedThis is a face",
            "Deep Learning\nConvolutional Neural Networks",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 13\nExample to explain layers\nWe will take a look at the following imageQuestion: Is this an X or a 0?\nThe computer can only see the numbers representing the colorNote: This example only has one color channel (black or white) to keep it simple\nImages from: ROHRER, BRANDON: How Convolutional Neural Networks work. https://www.youtube.com/watch?v=FmpDIaiMIeA",
            "Deep learning architectures for convolutional neural networks (CNNs) with convolutional\nlayers and downsampling layers began with the Neocognitron introduced by Kunihiko\nFukushima in 1979, though not trained by backpropagation.[45][46]\nBackpropagation  is  an  efficient  application  of  the  chain  rule  derived  by  Gottfried\nWilhelm  Leibniz  in  1673[47]  to  networks  of  differentiable  nodes.  The  terminology\n\"back-propagating  errors\"  was  actually  introduced  in  1962  by  Rosenblatt,[37]  but  he\ndid  not  know  how  to  implement  this,  although  Henry  J.  Kelley  had  a  continuous\nprecursor of backpropagation in 1960 in the context of control theory.[48] The modern\nform  of  backpropagation  was  first  published  in  Seppo  Linnainmaa's  master  thesis\n(1970).[49][50][31]  G.M.  Ostrovski  et  al.  republished  it  in  1971.[51][52]  Paul  Werbos\napplied backpropagation to neural networks in 1982[53] (his 1974 PhD thesis, reprinted\nin  a  1994  book,[54]  did  not  yet  describe  the  algorithm[52]).  In  1986,  David  E.\nRumelhart et al. popularised backpropagation but did not cite the original work.[55][56]\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply\nCNN  to  phoneme  recognition.  It  used  convolutions,  weight  sharing,  and\nbackpropagation.[57][58]  In 1988, Wei Zhang applied a backpropagation-trained CNN\nto alphabet recognition.[59] \nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP\ncodes on mail. Training required 3 days.[60] In 1990, Wei Zhang implemented a CNN on\noptical computing hardware.[61] In 1991, a CNN was applied to medical image object\nsegmentation[62] and breast cancer detection in mammograms.[63] LeNet-5 (1998), a",
            "Deep Learning\nConvolutional Neural Networks - MNIST",
            "refers  to  the  use  of  multiple  layers  (ranging  from  three  to  several  hundred  or\nthousands) in the network. Methods used can be either supervised, semi-supervised or\nunsupervised.[2]\nSome common deep learning network architectures include fully connected networks,\ndeep  belief  networks,  recurrent  neural  networks,  convolutional  neural  networks,\ngenerative  adversarial  networks,  transformers,  and  neural  radiance  fields.  These",
            "DNNs  can  model  complex  non-linear  relationships.  DNN  architectures  generate\ncompositional  models  where  the  object  is  expressed  as  a  layered  composition  of\nprimitives.[147]  The  extra  layers  enable  composition  of  features  from  lower  layers,\npotentially modeling complex data with fewer units than a similarly performing shallow\nnetwork.[7]  For  instance,  it  was  proved  that  sparse  multivariate  polynomials  are\nexponentially easier to approximate with DNNs than with shallow networks.[148]\nDeep architectures include many variants of a few basic approaches. Each architecture\nhas  found  success  in  specific  domains.  It  is  not  always  possible  to  compare  the\nperformance of multiple architectures, unless they have been evaluated on the same\ndata sets.[146]\nDNNs are typically feedforward networks in which data flows from the input layer to the\noutput layer without looping back. At first, the DNN creates a map of virtual neurons\nand assigns random numerical values, or \"weights\", to connections between them. The\nweights and inputs are multiplied and return an output between 0 and 1. If the network\ndid  not  accurately  recognize  a  particular  pattern,  an  algorithm  would  adjust  the\nweights.[149]  That  way  the  algorithm  can  make  certain  parameters  more  influential,\nuntil it determines the correct mathematical manipulation to fully process the data.\nRecurrent  neural  networks,  in  which  data  can  flow  in  any  direction,  are  used  for\napplications  such  as  language  modeling.[150][151][152][153][154]  Long  short-term",
            "Convolutional Layer\nAccepts input of size !!\u00d7#!\u00d7$!(width times height times number of color channels for images)Requires four hyperparameters:\u00a7Number of filters %\u00a7Their spatial extent (receptive field) &\u00a7The stride '\u00a7The amount of zero padding (Produces an output of size: !\"\u00d7#\"\u00d7$\"-!\"=#!$%&\"'(++ -#\"=)!$%&\"'(++-$\"=%Number of weights: &\u2217&\u2217$!\u2217%Common values for hyperparameters: -=3,0=1,2=1",
            "Neural  networks  have  been  used  on  a  variety  of  tasks,  including  computer  vision,\nspeech  recognition,  machine  translation,  social  network  filtering,  playing  board  and\nvideo games and medical diagnosis.\nAs of 2017, neural networks typically have a few thousand to a few million units and\nmillions of connections. Despite this number being several order of magnitude less than\nthe number of neurons on a human brain, these networks can perform many tasks at a\nlevel beyond that of humans (e.g., recognizing faces, or playing \"Go\"[144]).\nA  deep  neural  network  (DNN)  is  an  artificial  neural  network  with  multiple  layers\nbetween the input and output layers.[7][9] There are different types of neural networks\nbut they always consist of the same components: neurons, synapses, weights, biases,\nand  functions.[145]  These  components  as  a  whole  function  in  a  way  that  mimics\nfunctions of the human brain, and can be trained like any other ML algorithm.[citation\nneeded]\nFor  example,  a  DNN  that  is  trained  to  recognize  dog  breeds  will  go  over  the  given\nimage and calculate the probability that the dog in the image is a certain breed. The\nuser can review the results and select which probabilities the network should display\n(above  a  certain  threshold,  etc.)  and  return  the  proposed  label.  Each  mathematical\nmanipulation as such is considered a layer, [146] and complex DNN have many layers,\nhence the name \"deep\" networks.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 3\nArtificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in the input layer, you have as many nodes as input varibales + a constant (=bias)\u00a7Hidden units: Nodes in the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing the various outputs-Connection:\u00a7Each node is connected to the succeeding node (one direction only)\u00a7Each connection has a weight that need to be learned from the data\nIdothecalculations)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 22\nReferences & WebLinks\n\u00a7GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A.:Deep Learning (2016), P.330ff.\u00a7LECUN, YANN; BENGIO, YOSHUA: Convolutional Networks for Images, Speech, and Time-Series. In M. A. Arbib(Ed.),The handbook of brain theory and neural networksMIT Press (1995).\u00a7ROHRER, BRANDON: How Convolutional Neural Networks work. https://www.youtube.com/watch?v=FmpDIaiMIeA\u00a7STANFORDCS231NCLASSNOTES: Convolutional Neural Networks for Visual Recognition: http://cs231n.github.io/convolutional-networks/",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 28\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n6.1 Interpretation problem \n6.2 Convolutional Neural Networks\n6.3 MNIST\u200b-Database\n6.4 Long Short-Term Memory",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 43\nAnomaly DetectionSummary\nEven though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation, etc. that are used in another context.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?"
        ],
        "generated": "The types of layers in a Convolutional Neural Network (CNN) are:\n1. Convolutional Layer (Extract features)\n2. Pooling Layer (Reduce size)\n3. ReLU Layer (Remove negative values)\n4. Fully Connected Layer (Classify features)",
        "ground_truth": "Convolution Layer, Pooling Layer, ReLu Layer, Fully Connected Layer."
    },
    {
        "query": "What is anomaly detection?",
        "retrieved": [
            "Anomaly Detection\nIntroduction",
            "Anomaly Detection\nMethods",
            "Data Science: Advanced Analytics\nAnomaly Detection",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 4\nIntroductionOverview\nAnomalous patterns are often referred to as anomalies, outliers, discordant observations, exceptions, aberrations, surprises, peculiarities orcontaminants in different application domainsWe will use the term anomalyMain reference: Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A Survey. ACM Computing Surveys, 41(3), 1\u201358. \nDistinction:-Anomaly Detection deals with detecting interesting, non-normal patterns-In contrast noise removal deals with detection and removal of unwanted outliersthat are not of interest-Novelty detection deals with new patterns that in contrast to anomalies can also be part of the \u201enormal\u201c behavior-The methods used are fairly similar, however anomaly detection seems to offer the biggest range of methods",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 43\nAnomaly DetectionSummary\nEven though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation, etc. that are used in another context.",
            "In particular, in the context of abuse and network intrusion detection, the interesting\nobjects are often not rare objects, but unexpected bursts of inactivity. This pattern does\nnot  adhere  to  the  common  statistical  definition  of  an  outlier  as  a  rare  object.  Many\noutlier detection methods (in particular, unsupervised algorithms) will fail on such data\nunless aggregated appropriately. Instead, a cluster analysis algorithm may be able to\ndetect the micro-clusters formed by these patterns.[74]\nThree  broad  categories  of  anomaly  detection  techniques  exist.[75]  Unsupervised\nanomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised\nanomaly detection techniques require a data set that has been labeled as \"normal\" and\n\"abnormal\"  and  involves  training  a  classifier  (the  key  difference  from  many  other\nstatistical  classification  problems  is  the  inherently  unbalanced  nature  of  outlier\ndetection).  Semi-supervised  anomaly  detection  techniques  construct  a  model\nrepresenting normal behavior from a given normal training data set and then test the\nlikelihood of a test instance to be generated by the model.\nRobot learning is inspired by a multitude of machine learning methods, starting from\nsupervised  learning,  reinforcement  learning,[76][77]  and  finally  meta-learning  (e.g.\nMAML).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 13\nMethodsCriteria: Data labels and Output\nTo classifya data instance as normal or anomalous one can use labels:Labeling data is costly and expensiveGetting labels for all kinds of anomalous behavior is nearly impossibleNormal class easier to labelDepending on the availability of labeled data there are three approaches:Supervised anomaly detection:assumes labels for both classesSemi-supervised: only assumes labels for the normal classUnsupervised: does not assume labelsThe outputsof an anomaly detection method can be:Scores: Scores how unusual the anomaly is compared to normal; ranking of the data objects possibleLabels: Labels the data instance either anomalous or normal",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 7\nIntroductionChallenges\nDefining anormal region which encompasses every possible normal behavior is very difficult. When anomalies are the result of malicious actions, the malicious adversaries often adapt themselves to make the anomalous observations appear like normal.In many domains normal behavior keeps evolving and a current notion of normal behavior might not be sufficiently representative in the future.The exact notion of an anomaly is different for different application domains.\nAvailability of labeled data for training/validation of models used by anomaly detection techniques is usually a major issue.\nOften the data contains noise which tends to be similar tothe actual anomalies and hence is difficult to distinguish and remove.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 39\nStatistical methodsParametric methods: other methods\nRegression based:(1) Regression is estimated(2) for each data object the residual score resembles the anomaly scoreSome criteria used to detect anomalies in a regressions setting:\u2014AIC: anomalies influence regression results\u2014Robust regression: should be used to avoid anomaly influences \u00f0residuals for anomalies are considerably larger in this setting\u2014ARIMA/ARMA: detection of anomalies in a time series settingMixture distribution based: Two approaches -Different distributions for normal data and anomalies or mixed distribution for only the normal class",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 8\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nCritical consideration on the application in questionExample questions:Does the pattern lead to better decisions than some reasonable alternative?How well would one have done by chance? How well would one do with a smart \u2018\u2018default\u2019\u2019 alternative?\n\u201cEvaluatingdata-science results requires careful consideration of the context in which they will be used.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "meaning  that  even  the  coders  of  the  algorithm  cannot  audit  the  pattern  that  the\nmachine extracted out of the data.[123] The House of Lords Select Committee, which\nclaimed that such an \"intelligence system\" that could have a \"substantial impact on an\nindividual's  life\"  would  not  be  considered  acceptable  unless  it  provided  \"a  full  and\nsatisfactory explanation for the decisions\" it makes.[123]\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a\ncollision.[124]  Attempts  to  use  machine  learning  in  healthcare  with  the  IBM  Watson\nsystem  failed  to  deliver  even  after  years  of  time  and  billions  of  dollars\ninvested.[125][126] Microsoft's Bing Chat chatbot has been reported to produce hostile\nand offensive response against its users.[127]\nMachine  learning  has  been  used  as  a  strategy  to  update  the  evidence  related  to  a\nsystematic review and increased reviewer burden related to the growth of biomedical\nliterature. While it has improved with training sets, it has not yet developed sufficiently\nto reduce the workload burden without limiting the necessary sensitivity for the findings\nresearch themselves.[128]\nExplainable  AI  (XAI),  or  Interpretable  AI,  or  Explainable  Machine  Learning  (XML),  is\nartificial intelligence (AI) in which humans can understand the decisions or predictions\nmade  by  the  AI.[129]  It  contrasts  with  the  \"black  box\"  concept  in  machine  learning\nwhere even its designers cannot explain why an AI arrived at a specific decision.[130]\nBy  refining  the  mental  models  of  users  of  AI-powered  systems  and  dismantling  their\nmisconceptions,  XAI  promises  to  help  users  perform  more  effectively.  XAI  may  be  an",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 13\nExample to explain layers\nWe will take a look at the following imageQuestion: Is this an X or a 0?\nThe computer can only see the numbers representing the colorNote: This example only has one color channel (black or white) to keep it simple\nImages from: ROHRER, BRANDON: How Convolutional Neural Networks work. https://www.youtube.com/watch?v=FmpDIaiMIeA"
        ],
        "generated": "Anomaly detection is the process of identifying and detecting patterns or instances that deviate from normal behavior or expected outcomes in a given dataset. It involves distinguishing anomalies, outliers, discordant observations, exceptions, or surprises from the regular patterns in various application domains. Anomaly detection methods aim to detect interesting, non-normal patterns and can be used in different fields such as machine learning, statistics, information theory, and spectral theory.",
        "ground_truth": "Detections of patterns that do not conform to 'normal' behavior."
    },
    {
        "query": "What is the A-priori algorithm?",
        "retrieved": [
            "A-priori AlgorithmIdea\nThe A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database.The algorithm searches for all rules that have a high confidencevalue. It must now be taken into account that the important confidence of a rule is also expressed by its support values. Thus applies: Let X be an item set from the population of all items I and X\u2018 \u00ccX, then:",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 9\nA-priori AlgorithmIdea\nThe A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database.The algorithm searches for all rules that have a high confidencevalue. It must now be taken into account that the important confidence of a rule is also expressed by its support values. Thus applies: Let X be an item set from the population of all items I and X\u2018 \u00ccX, then: \nSupport values, in turn, represent frequencies of item sets in the population.\nsup( X )conf( (X X) X) sup( X X ')\n\u00a2\u00a2-\u00ae = -",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 9\nA-priori AlgorithmIdea",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 10\nA-priori AlgorithmProcesssteps\nThe following steps are to be completed during rule generation using the A-priori algorithm.must be completed:Step 1: Compute the (frequent) item sets whose support values are at least equal to the minimum support (\u00e0frequent item set X ).\nStep 2: For each subset X' of a frequent item set X holds:",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 11\nA-priori AlgorithmFrequent setsofitems\u2013Part I\nFrom this follows the procedure for the calculation of the frequent item sets:1.Successive calculation of frequent item sets with i = 1,2,3,... Items2.Summary of the frequent item sets with i items to the set Ii, d.h. Ii= {X : X is frequent item set, \u00eaX \u00ea= i }3.For X \u00ceIn+1applies: All n-element subsets of X are often.4.Calculation of In+1from In:\u2014N-element frequent sets are extended by one element.\u2014Check if (n +1)-elementary set is also frequent.If yes, take over the (n +1)-elementary set in In+1\nFor X\u2018 \u00cdX applies: support (X\u2018) \u00b3support (X)    \u00deIfX isfrequent item set, thenalso X\u2018.Fromthe inversionofthe implicationfollowsimmediatelythe A priori property:Ifa k-itemsetisnot frequent, thena k+1 itemsetcontainingitasa subsetcannotbefrequent either.",
            "-A-priori Algorithm-A-priori-Tid algorithm-A-priori-Hybrid Algorithm-AIS algorithmThe procedures have in common that they are often used as starting procedures in the data mining, since no assumptions are necessary to the connections of the data, which things could correlate e.g. (undirected data mining).\nNote: 100 itemsresultin generally(100 overk) item combinations.-2-itemsets: 4,950 combinations-3-itemsets: 161,700 combinations-5-itemsets: 75.287.520 combinations",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 10\nA-priori AlgorithmProcesssteps\nThe following steps are to be completed during rule generation using the A-priori algorithm.must be completed:Step 1: Compute the (frequent) item sets whose support values are at least equal to the minimum support (\u00e0frequent item set X ).\nStep 2: For each subset X' of a frequent item set X holds:\nFormation of all rules whose Confidence is at least equal to the minimum Confidence.\nsup( X )conf( (X X) X) sup( X X ')\n\u00a2\u00a2-\u00ae = -",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 12\nA-priori AlgorithmFrequent setsofitems\u2013Part II\n5.\n1.Initialization:smin= valuefor minimumsupportn = 1I = \u00c6Hn= { {i } : i isan item}\n3. DetermineIn= {H \u00ceHn: support (H) \u00b3smin}Set I = I \u00c8In\n{ } { } { }{ }n1 1 n1 1 n1 j nHi , . . . , i : j : 1 j n 1 : i , . . . , i i I++ += \"\u00a3 \u00a3 + -\u00ce\nNote: Ifthealgorithmends, thenforall elementsofthesetsofI1, ..., In, onecomputestheassociatedruleswiththeirmeasuresofinterestandselectstherelevant ones.\n2. Determinein the databaseD for all H \u00ceHnthe Support\n4. IfIn= \u00d8, thenoutputsetI asthe result.\nset n = n + 16. Go to2",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Types  of  supervised-learning  algorithms  include  active  learning,  classification  and\nregression.[50] Classification algorithms are used when the outputs are restricted to a\nlimited set of values, and regression algorithms are used when the outputs may have\nany numerical value within a range. As an example, for a classification algorithm that\nfilters emails, the input would be an incoming email, and the output would be the name\nof the folder in which to file the email. Examples of regression would be predicting the\nheight of a person, or the future temperature.[51]\nSimilarity  learning  is  an  area  of  supervised  machine  learning  closely  related  to\nregression and classification, but the goal is to learn from examples using a similarity\nfunction  that  measures  how  similar  or  related  two  objects  are.  It  has  applications  in\nranking,  recommendation  systems,  visual  identity  tracking,  face  verification,  and\nspeaker verification.\nUnsupervised  learning  algorithms  find  structures  in  data  that  has  not  been  labeled,\nclassified  or  categorized.  Instead  of  responding  to  feedback,  unsupervised  learning\nalgorithms  identify  commonalities  in  the  data  and  react  based  on  the  presence  or\nabsence  of  such  commonalities  in  each  new  piece  of  data.  Central  applications  of\nunsupervised  machine  learning  include  clustering,  dimensionality  reduction,[7]  and\ndensity estimation.[52]\nCluster analysis is the assignment of a set of observations into subsets (called clusters)\nso  that  observations  within  the  same  cluster  are  similar  according  to  one  or  more",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "DNNs  can  model  complex  non-linear  relationships.  DNN  architectures  generate\ncompositional  models  where  the  object  is  expressed  as  a  layered  composition  of\nprimitives.[147]  The  extra  layers  enable  composition  of  features  from  lower  layers,\npotentially modeling complex data with fewer units than a similarly performing shallow\nnetwork.[7]  For  instance,  it  was  proved  that  sparse  multivariate  polynomials  are\nexponentially easier to approximate with DNNs than with shallow networks.[148]\nDeep architectures include many variants of a few basic approaches. Each architecture\nhas  found  success  in  specific  domains.  It  is  not  always  possible  to  compare  the\nperformance of multiple architectures, unless they have been evaluated on the same\ndata sets.[146]\nDNNs are typically feedforward networks in which data flows from the input layer to the\noutput layer without looping back. At first, the DNN creates a map of virtual neurons\nand assigns random numerical values, or \"weights\", to connections between them. The\nweights and inputs are multiplied and return an output between 0 and 1. If the network\ndid  not  accurately  recognize  a  particular  pattern,  an  algorithm  would  adjust  the\nweights.[149]  That  way  the  algorithm  can  make  certain  parameters  more  influential,\nuntil it determines the correct mathematical manipulation to fully process the data.\nRecurrent  neural  networks,  in  which  data  can  flow  in  any  direction,  are  used  for\napplications  such  as  language  modeling.[150][151][152][153][154]  Long  short-term",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail."
        ],
        "generated": "The A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database. The algorithm searches for all rules that have a high confidence value, taking into account that the important confidence of a rule is also expressed by its support values. It involves computing frequent item sets and generating rules based on minimum support and confidence values.",
        "ground_truth": "The A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database. The algorithm searches for all rules that have a high confidence value. It must now be taken into account that the important confidence of a rule is also expressed by its support values."
    },
    {
        "query": "In what categories can Machine Learning tasks be classified?",
        "retrieved": [
            "Machine Learning tasks can be classified into three broad categories of learning problems:Supervised Learning:The algorithm is given training data which contains examples of the input vectors along with their correspondingtarget vectors as the \u201ccorrect answer\u201d and the goal is to learn a general rule/ model that maps inputs to outputs.Examples: classification, regressionUnsupervised Learning: Principle: No labels (i.e.target values) are given to the algorithm, leaving it on its own to find",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 28\nMachine Learning CategorizationDifferent types of learning problems\nMachine Learning tasks can be classified into three broad categories of learning problems:Supervised Learning:The algorithm is given training data which contains examples of the input vectors along with their correspondingtarget vectors as the \u201ccorrect answer\u201d and the goal is to learn a general rule/ model that maps inputs to outputs.Examples: classification, regressionUnsupervised Learning: Principle: No labels (i.e.target values) are given to the algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal by itself (discovering hidden patterns) or a means towards a supervised approach (feature learning).Examples: cluster analysis, dimensionality reduction, density estimationReinforcement Learning:\u201c(\u2026) problem of finding suitable actions to take in a givensituation in order to maximize a reward. Here the learning algorithm is not given examples of optimal outputs, in contrast to supervised learning, but must instead discover them by a process of trial and error. Typicallythere is a sequence of states and actions in which the learning algorithm is interacting with its environment.\u201d (Bishop, 2006)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 28\nMachine Learning CategorizationDifferent types of learning problems",
            "definition of the tasks in which machine learning is concerned offers a fundamentally\noperational definition rather than defining the field in cognitive terms. This follows Alan\nTuring's  proposal  in  his  paper  \"Computing  Machinery  and  Intelligence\",  in  which  the\nquestion \"Can machines think?\" is replaced with the question \"Can machines do what\nwe (as thinking entities) can do?\".[19]\nModern-day  machine  learning  has  two  objectives.   One  is  to  classify  data  based  on",
            "Modern-day  machine  learning  has  two  objectives.   One  is  to  classify  data  based  on\nmodels which have been developed; the other purpose is to make predictions for future\noutcomes based on these models. A hypothetical algorithm specific to classifying data\nmay use computer vision of moles coupled with supervised learning in order to train it\nto  classify  the  cancerous  moles.  A  machine  learning  algorithm  for  stock  trading  may",
            "polynomial time.\nMachine  learning  approaches  are  traditionally  divided  into  three  broad  categories,\nwhich  correspond  to  learning  paradigms,  depending  on  the  nature  of  the  \"signal\"  or\n\"feedback\" available to the learning system:\nAlthough each algorithm has advantages and limitations, no single algorithm works for\nall problems.[45][46][47]\nSupervised  learning  algorithms  build  a  mathematical  model  of  a  set  of  data  that\ncontains both the inputs and the desired outputs.[48] The data, known as training data,\nconsists of a set of training examples. Each training example has one or more inputs\nand the desired output, also known as a supervisory signal. In the mathematical model,\neach training example is represented by an array or vector, sometimes called a feature\nvector, and the training data is represented by a matrix. Through iterative optimization\nof  an  objective  function,  supervised  learning  algorithms  learn  a  function  that  can  be\nused to predict the output associated with new inputs.[49] An optimal function allows\nthe algorithm to correctly determine the output for inputs that were not a part of the\ntraining data. An algorithm that improves the accuracy of its outputs or predictions over\ntime is said to have learned to perform that task.[18]",
            "Machine Learning\nMachine  learning  (ML)  is  a  field  of  study  in  artificial  intelligence  concerned  with  the\ndevelopment and study of statistical algorithms that can learn from data and generalize\nto  unseen  data,  and  thus  perform  tasks  without  explicit  instructions.[1]  Within  a\nsubdiscipline in machine learning, advances in the field of deep learning have allowed\nneural  networks,  a  class  of  statistical  algorithms,  to  surpass  many  previous  machine\nlearning approaches in performance.[2]\nML  finds  application  in  many  fields,  including  natural  language  processing,  computer\nvision,  speech  recognition,  email  filtering,  agriculture,  and  medicine.[3][4]  The\napplication of ML to business problems is known as predictive analytics.\nStatistics  and  mathematical  optimization  (mathematical  programming)  methods\ncomprise the foundations of machine learning. Data mining is a related field of study,\nfocusing on exploratory data analysis (EDA) via unsupervised learning.[6][7]\nFrom  a  theoretical  viewpoint,  probably  approximately  correct  learning  provides  a\nframework for describing machine learning.\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and\npioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym\nself-teaching computers was also used in this time period.[10][11]",
            "Types  of  supervised-learning  algorithms  include  active  learning,  classification  and\nregression.[50] Classification algorithms are used when the outputs are restricted to a\nlimited set of values, and regression algorithms are used when the outputs may have\nany numerical value within a range. As an example, for a classification algorithm that\nfilters emails, the input would be an incoming email, and the output would be the name",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 29\nMachine Learning & Deep LearningDeep Learning as a new disruptive technology\nA special class of Machine Learning algorithms is Deep Learning.\u201cThe main concept in deep leaning algorithms is automating the extraction of representations(abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representation.\u201d(Najafabadi et al., 2016)\u201cThese algorithms are largely motivated by the field of artificial intelligence, which has the general goal of emulating the human brain\u2019s abilityto observe, analyze, learn, and make decisions, especially for extremely complex problems.\u201d (Najafabadi et al., 2016)\nhttps://blogs.nvidia.com",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 25\nD) Machine Learning",
            "implementation of the social right to explanation.\nSettling on a bad, overly complex theory gerrymandered to fit all the past training data\nis  known  as  overfitting.  Many  systems  attempt  to  reduce  overfitting  by  rewarding  a\ntheory  in  accordance  with  how  well  it  fits  the  data  but  penalizing  the  theory  in\naccordance with how complex the theory is.[131]\nLearners can also disappoint by \"learning the wrong lesson\". A toy example is that an\nimage classifier trained only on pictures of brown horses and black cats might conclude\nthat all brown patches are likely to be horses.[132] A real-world example is that, unlike\nhumans,  current  image  classifiers  often  do  not  primarily  make  judgments  from  the\nspatial  relationship  between  components  of  the  picture,  and  they  learn  relationships\nbetween  pixels  that  humans  are  oblivious  to,  but  that  still  correlate  with  images  of\ncertain types of real objects. Modifying these patterns on a legitimate image can result\nin \"adversarial\" images that the system misclassifies.[133][134]\nAdversarial  vulnerabilities  can  also  result  in  nonlinear  systems,  or  from  non-pattern\nperturbations. For some systems, it is possible to change the output by only changing a\nsingle adversarially chosen pixel.[135] Machine learning models are often vulnerable to\nmanipulation or evasion via adversarial machine learning.[136]\nResearchers  have  demonstrated  how  backdoors  can  be  placed  undetectably  into\nclassifying  (e.g.,  for  categories  \"spam\"  and  well-visible  \"not  spam\"  of  posts)  machine",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 9\nInterdisciplinary interfaces\nText mining\nComputational Linguistics\u2022Computer-aided text and language processing\u2022Insb. Natural Language Processing (NLP)\nData Mining\u2022Procedure\u2022Insb. clustering and classification approaches\nStatistics\nMachine Learning\nInformation Retrieval",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 24\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n2.1 Introduction to Segmentation\n2.2 Cluster types\n2.3 Distance measures\n2.4 Evaluation criteria \n2.5 Start heuristics",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 22\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics"
        ],
        "generated": "Machine Learning tasks can be classified into three broad categories: Supervised Learning, Unsupervised Learning, and Reinforcement Learning.",
        "ground_truth": "Supervised Learning, Unsupervised Learning, Reinforcement Learning"
    },
    {
        "query": "What are process models in business informatics?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 13\nProcess models in business informaticsProcess models specify the sequence in which certain activitiesshouldbe carried out or proceduresshouldbe used in order to successfully complete (IT) projects; this serves on the one hand to structuretasksand on the other hand to reduce complexity within these projects.Process models such as the KDD, SEMMA or CRISP-DM processstructure phases and tasks of the data mining processSources: Fil\u00df et al. (2005, p. 184; Gutzwiller (1994), p. 32;Jablonski (1997), p. 489f.; Mertens (2001), p. 498; Stahlknecht & Hasenkamp (2005), p. 215\nAdapted from Chapman et al. (2000), p. 13.",
            "Process models in business informaticsProcess models specify the sequence in which certain activitiesshouldbe carried out or proceduresshouldbe used in order to successfully complete (IT) projects; this serves on the one hand to structuretasksand on the other hand to reduce complexity within these projects.Process models such as the KDD, SEMMA or CRISP-DM processstructure phases and tasks of the data mining processSources: Fil\u00df et al. (2005, p. 184; Gutzwiller (1994), p. 32;Jablonski (1997), p.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 18\nProcess models and proceduresLiterature Review: Implications\nFindingsVariety of activities and proceduresHolistic, cross-case view of the process is missingPrevious generic models show only rough flowStructural requirements fora generic process modelDesign of the procedure modelPhase arrangement and structuringFeedback loopsFunctional requirements fora generic process model Task definitionDocument preprocessingData AnalysisProcedure for the implementation of the activities",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 19\nProcedure model according to Schieber & Hilbert\nProcess models such as the KDD, SEMMA or CRISP-DM process structure phases and tasks of the data mining processAnalogously, the procedure model according to Schieber & Hilbert structures the phases and tasks of the text mining processSources: Kurgan & Musilek (2006), p. 9ff.; Schieber & Hilbert (2014a), p. 45",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 18\nProcess models and proceduresLiterature Review: Implications",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 9\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nBreaking down the business problem into componentsReduce complexity/ increase transparency\nUsage of information technology to compute standard measures to quickly identify objects of interestFor example: Computation of correlation measures between hundreds of variables\n\u201cThe relationship between the business problem and the analytics solution often can be decomposed into tractable sub-problems via the framework of analyzing expected value.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)\n\u201cInformation technology can be used to find informative data items from within a large body of data.\u201d",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 39\nVariety of Data Analysis TechniquesWhich one to choose?\nHow do we know which technique/algorithm to choose?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 8\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nCritical consideration on the application in questionExample questions:Does the pattern lead to better decisions than some reasonable alternative?How well would one have done by chance? How well would one do with a smart \u2018\u2018default\u2019\u2019 alternative?\n\u201cEvaluatingdata-science results requires careful consideration of the context in which they will be used.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 48\nConformance of Data and Resources\nParticipants usually require permissionsto execute certain activities\nPermissions are bundled for specific roles\nViolations of permissions can be checked by searching for each activity conducted by a participant whether or notan appropriate role or permission existed\nSpecific control rules which require two different persons to approve a business transaction are called separation of duties constraints\nThese rules do not necessarily involve supervisorsDumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 20\nSome Definitions\u2026 \u2026 collected by Chatfield et al. (2014)\nSource Definition: Data scientists are \u2026\nGranville (2014) \u201cnot statisticians, nor data analysts, nor computer scientists, nor software engineers, nor\nbusiness analysts. They have some knowledge in each of these areas but also some outside\nof these areas.\u201d\nDhar (2013) \u201crequires an integrated skill set spanning mathematics, machine learning, artificial\nintelligence, statistics, databases, and optimization, along with a deep understanding of the\ncraft of problem formulation to engineer effective solutions.\u201d\nDavenport & Patil (2012) \u201cthe people who understand how to fish out answers to important business questions from\ntoday\u2019s tsunami of unstructured information.\u201d\nMohanty et al. (2013) \u201cthe practitioners of the analytics models solving business problems. They incorporate\nadvanced analytical approaches using sophisticated analytics and data visualization tools to\ndiscover patterns in data. In many cases, these practitioners work with well-established\nanalytics techniques such as logistic regression methods, clustering methods, and\nclassification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,\nexplore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 21\nData MiningDefinition and context\n\u201eData Mining is the process of extracting previously unknown, valid, and actionable informationfrom large databases and then using the information to make crucial business decisions.\u201c(Cabena et al. 1997)\n\u201eData Mining, as we use the term, is the exploration and analysis, by automatic or semiautomatic means, of large quantities of data in order to discover meaningful patterns and rules.\u201c(Berry et al. 1997)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 5\nIntroductionDefinition and Data Mining context\nOne possible definition:\nIn the context of data mining:-A portion of the observed data is generated by an unknown, anomalous process-This process differs from the standard processUntil now: -Assumption of one process that generates the data-Data Mining models reflecting that processNow: Interesting new observations that indicate differing mechanism behind data\n\u201cAn Outlier is an observation which deviates so much from the otherobservations as to arouse suspicions that it was generated by a differentmechanism\u201d (Hawkins, 1980)Source: Hawkins D. 1980. Identification of Outliers. Chapman and Hall.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 19\nDifferent Expectations\u2026\u2026 what people think I do \nWhat my friends think I \ndo\nWhat my mother thinks I \ndo\nWhat my boss thinks I do\nWhat I really doWhat I think I doWhat society thinks I do",
            "modeling,  representation  of  objects  as  interconnections  of  smaller  structures,  optical\nflow, and motion estimation.[11]\nThe  next  decade  saw  studies  based  on  more  rigorous  mathematical  analysis  and\nquantitative aspects of computer vision. These include the concept of scale-space, the\ninference of shape from various cues such as shading, texture and focus, and contour\nmodels known as snakes. Researchers also realized that many of these mathematical\nconcepts  could  be  treated  within  the  same  optimization  framework  as  regularization\nand Markov random fields.[15]\nBy the 1990s, some of the previous research topics became more active than others.\nResearch  in  projective  3-D  reconstructions  led  to  better  understanding  of  camera\ncalibration.  With  the  advent  of  optimization  methods  for  camera  calibration,  it  was\nrealized that a lot of the ideas were already explored in bundle adjustment theory from\nthe  field  of  photogrammetry.  This  led  to  methods  for  sparse  3-D  reconstructions  of\nscenes from multiple images. Progress was made on the dense stereo correspondence\nproblem and further multi-view stereo techniques. At the same time, variations of graph\ncut  were  used  to  solve  image  segmentation.  This  decade  also  marked  the  first  time\nstatistical learning techniques were used in practice to recognize faces in images (see\nEigenface).  Toward  the  end  of  the  1990s,  a  significant  change  came  about  with  the\nincreased  interaction  between  the  fields  of  computer  graphics  and  computer  vision.\nThis  included  image-based  rendering,  image  morphing,  view  interpolation,  panoramic\nimage stitching and early light-field rendering.[11]\nRecent  work  has  seen  the  resurgence  of  feature-based  methods  used  in  conjunction\nwith machine learning techniques and complex optimization frameworks.[16][17]",
            "boundary,  low  samples,  and  ambiguous  class  issues  that  standard  machine  learning\napproach  tend  to  have  difficulty  resolving.[4][9]  However,  the  computational\ncomplexity of these algorithms are dependent on the number of propositions (classes),\nand  can  lead  to  a  much  higher  computation  time  when  compared  to  other  machine\nlearning approaches.\nTypically, machine learning models require a high quantity of reliable data to perform\naccurate  predictions.  When  training  a  machine  learning  model,  machine  learning\nengineers need to target and collect a large and representative sample of data. Data\nfrom the training set can be as varied as a corpus of text, a collection of images, sensor\ndata, and data collected from individual users of a service. Overfitting is something to\nwatch  out  for  when  training  a  machine  learning  model.  Trained  models  derived  from\nbiased  or  non-evaluated  data  can  result  in  skewed  or  undesired  predictions.  Biased\nmodels may result in detrimental outcomes, thereby furthering the negative impacts on\nsociety  or  objectives.  Algorithmic  bias  is  a  potential  result  of  data  not  being  fully\nprepared for training. Machine learning ethics is becoming a field of study and notably,\nbecoming integrated within machine learning engineering teams.\nFederated  learning  is  an  adapted  form  of  distributed  artificial  intelligence  to  training\nmachine  learning  models  that  decentralizes  the  training  process,  allowing  for  users'\nprivacy to be maintained by not needing to send their data to a centralized server. This\nalso  increases  efficiency  by  decentralizing  the  training  process  to  many  devices.  For\nexample,  Gboard  uses  federated  machine  learning  to  train  search  query  prediction\nmodels  on  users'  mobile  phones  without  having  to  send  individual  searches  back  to\nGoogle.[98]",
            "such  as  game  theory,  control  theory,  operations  research,  information  theory,\nsimulation-based optimization, multi-agent systems, swarm intelligence, statistics and\ngenetic algorithms. In reinforcement learning, the environment is typically represented\nas  a  Markov  decision  process  (MDP).  Many  reinforcements  learning  algorithms  use\ndynamic  programming  techniques.[56]  Reinforcement  learning  algorithms  do  not\nassume  knowledge  of  an  exact  mathematical  model  of  the  MDP  and  are  used  when\nexact models are infeasible. Reinforcement learning algorithms are used in autonomous\nvehicles or in learning to play a game against a human opponent.\nDimensionality  reduction  is  a  process  of  reducing  the  number  of  random  variables\nunder consideration by obtaining a set of principal variables.[57] In other words, it is a\nprocess  of  reducing  the  dimension  of  the  feature  set,  also  called  the  \"number  of\nfeatures\". Most of the dimensionality reduction techniques can be considered as either\nfeature  elimination  or  extraction.  One  of  the  popular  methods  of  dimensionality\nreduction  is  principal  component  analysis  (PCA).  PCA  involves  changing\nhigher-dimensional data (e.g., 3D) to a smaller space (e.g., 2D).\nThe  manifold  hypothesis  proposes  that  high-dimensional  data  sets  lie  along\nlow-dimensional  manifolds,  and  many  dimensionality  reduction  techniques  make  this\nassumption, leading to the area of manifold learning and manifold regularization.\nOther  approaches  have  been  developed  which  do  not  fit  neatly  into  this  three-fold\ncategorization, and sometimes more than one is used by the same machine learning\nsystem. For example, topic modeling, meta-learning.[58]",
            "analogous to the neural networks utilized in deep learning models. Like the neocortex,\nneural  networks  employ  a  hierarchy  of  layered  filters  in  which  each  layer  considers\ninformation  from  a  prior  layer  (or  the  operating  environment),  and  then  passes  its\noutput  (and  possibly  the  original  input),  to  other  layers.  This  process  yields  a\nself-organizing stack of transducers, well-tuned to their operating environment. A 1995\ndescription stated, \"...the infant's brain seems to organize itself under the influence of\nwaves of so-called trophic-factors ... different regions of the brain become connected\nsequentially, with one layer of tissue maturing before another and so on until the whole\nbrain is mature\".[256]\nA variety of approaches have been used to investigate the plausibility of deep learning\nmodels  from  a  neurobiological  perspective.  On  the  one  hand,  several  variants  of  the\nbackpropagation  algorithm  have  been  proposed  in  order  to  increase  its  processing\nrealism.[257][258]  Other  researchers  have  argued  that  unsupervised  forms  of  deep\nlearning,  such  as  those  based  on  hierarchical  generative  models  and  deep  belief\nnetworks,  may  be  closer  to  biological  reality.[259][260]  In  this  respect,  generative\nneural  network  models  have  been  related  to  neurobiological  evidence  about\nsampling-based processing in the cerebral cortex.[261]\nAlthough  a  systematic  comparison  between  the  human  brain  organization  and  the\nneuronal  encoding  in  deep  networks  has  not  yet  been  established,  several  analogies\nhave been reported. For example, the computations performed by deep learning units\ncould be similar to those of actual neurons[262] and neural populations.[263] Similarly,\nthe representations developed by deep learning models are similar to those measured\nin  the  primate  visual  system[264]  both  at  the  single-unit[265]  and  at  the"
        ],
        "generated": "Process models in business informatics specify the sequence in which certain activities should be carried out or procedures should be used in order to successfully complete (IT) projects. These models serve to structure tasks and reduce complexity within projects. Examples of process models include KDD, SEMMA, and CRISP-DM, which structure phases and tasks of the data mining process.",
        "ground_truth": "Process models specify the sequence in which certain activities should be carried out or procedures should be used in order to successfully complete (IT) projects; this serves on the one hand to structure tasks and on the other hand to reduce complexity within these projects."
    },
    {
        "query": "Why is data visualization so important for Data Science?",
        "retrieved": [
            "Importance of Visualization\nWhy is data visualization so important?\u201cBecause of the way the human brain processes information, using charts or graphs to visualize large amounts of complex data is easier than poring over spreadsheets or reports. Data visualization is a quick, easy way to convey concepts in a universal manner \u2013and you can experiment with different scenarios by making slight adjustments.\u201d (SAS, 2017)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 35\nImportance of Visualization\nWhy is data visualization so important?\u201cBecause of the way the human brain processes information, using charts or graphs to visualize large amounts of complex data is easier than poring over spreadsheets or reports. Data visualization is a quick, easy way to convey concepts in a universal manner \u2013and you can experiment with different scenarios by making slight adjustments.\u201d (SAS, 2017)\nAnother Example: Anscombe\u2019s Quartet4 data sets of 11 elementssame descriptive statistics for all 4 data sets\u2014mean of x = 9\u2014variance of x = 11\u2014mean of y = 7.50\u2014variance of y = 4.125\u2014correlation = 0.816\u2014linear regression line: y = 3.00 + 0.500x\n (Source: Anscombe, 1973)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 35\nImportance of Visualization",
            "Structuring the Field:Understanding Data Science",
            "\u201cEvaluatingdata-science results requires careful consideration of the context in which they will be used.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Structuring the Field:3) Data Science Techniques",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 10\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nSimilarity is one of the most important measures in Data ScienceMany ways and specifications to quantify similarity\nProblem of representation, also called \u201eoverfitting\u201c\n\u201cEntities that are similar with respect to known featuresor attributes often are similar with respect to unknown featuresor attributes.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)\n\u201cIf you look too hard at a set of data, you will find something -but it might not generalize beyond the datayou\u2019re observing.\u201d",
            "Structuring the Field:1) Data Science Principles",
            "Structuring the Field:2) Data Science Concepts",
            "Structuring the Field:4) Data Science Technologies",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 8\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nCritical consideration on the application in questionExample questions:Does the pattern lead to better decisions than some reasonable alternative?How well would one have done by chance? How well would one do with a smart \u2018\u2018default\u2019\u2019 alternative?\n\u201cEvaluatingdata-science results requires careful consideration of the context in which they will be used.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 11\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nCorrelation does not imply causation!It requires clear understanding of underlying data analysis techniques and their assumptionsWhat are the conclusions of the analysis and how can they be used for decision making?\n\u201cTo draw causal conclusions, one must pay very close attention to the presence of confounding factors, possibly unseen ones.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 20\nSome Definitions\u2026 \u2026 collected by Chatfield et al. (2014)\nSource Definition: Data scientists are \u2026\nGranville (2014) \u201cnot statisticians, nor data analysts, nor computer scientists, nor software engineers, nor\nbusiness analysts. They have some knowledge in each of these areas but also some outside\nof these areas.\u201d\nDhar (2013) \u201crequires an integrated skill set spanning mathematics, machine learning, artificial\nintelligence, statistics, databases, and optimization, along with a deep understanding of the\ncraft of problem formulation to engineer effective solutions.\u201d\nDavenport & Patil (2012) \u201cthe people who understand how to fish out answers to important business questions from\ntoday\u2019s tsunami of unstructured information.\u201d\nMohanty et al. (2013) \u201cthe practitioners of the analytics models solving business problems. They incorporate\nadvanced analytical approaches using sophisticated analytics and data visualization tools to\ndiscover patterns in data. In many cases, these practitioners work with well-established\nanalytics techniques such as logistic regression methods, clustering methods, and\nclassification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,\nexplore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 41\nVariety of Data Analysis TechniquesWhat is best practice?\nWhat are the most commonly usedtechniques/algorithms?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 21\nData MiningDefinition and context\n\u201eData Mining is the process of extracting previously unknown, valid, and actionable informationfrom large databases and then using the information to make crucial business decisions.\u201c(Cabena et al. 1997)\n\u201eData Mining, as we use the term, is the exploration and analysis, by automatic or semiautomatic means, of large quantities of data in order to discover meaningful patterns and rules.\u201c(Berry et al. 1997)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 20\nB) Data MiningThe searchforthedigital treasures\nData Mining \u2013A metaphor from the mining industryMining: The industry or activity of removing substances, such as coal, metal, gold or diamonds, from the ground by digging.\nhttp://djitz.com\nhttp://pinterest.com\nData Mining: the process of using special software to look at large amounts of computer data in order to find out useful information, for example what types of product a company's customers buy.\nhttps://dictionary.cambridge.org/de/worterbuch/englisch/mining\nhttps://dictionary.cambridge.org/de/worterbuch/englisch/data-mining",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 58\n2. Data preparation \u2013 normalization\nLSTMs are sensitive to the scale of the data\u00e0 Scale input data to values between 0 and 1Remeber to reverse this normalization when you want to display predictions\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))normalized_closing_values = scaler.fit_transform(closing_values)[...]predictions = scaler.inverse_transform(normalized_predictions)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 36\nClustering basedDisadvantages\nPerformance of clustering basedtechniques is highly dependent on the effectiveness of clustering algorithm in capturing the cluster structure of normal instances.\nMany techniques detect anomalies as a by-product of clustering, and hence are not optimized for anomaly detection.\nSeveral clustering algorithms force every instance to be assigned to some cluster.Several clustering based techniques are effective only when the anomalies do not form significant clusters among themselves.\nThe computational complexity for clustering the data is often a bottleneck.",
            "Machine Learning\nMachine  learning  (ML)  is  a  field  of  study  in  artificial  intelligence  concerned  with  the\ndevelopment and study of statistical algorithms that can learn from data and generalize\nto  unseen  data,  and  thus  perform  tasks  without  explicit  instructions.[1]  Within  a\nsubdiscipline in machine learning, advances in the field of deep learning have allowed\nneural  networks,  a  class  of  statistical  algorithms,  to  surpass  many  previous  machine\nlearning approaches in performance.[2]\nML  finds  application  in  many  fields,  including  natural  language  processing,  computer\nvision,  speech  recognition,  email  filtering,  agriculture,  and  medicine.[3][4]  The\napplication of ML to business problems is known as predictive analytics.\nStatistics  and  mathematical  optimization  (mathematical  programming)  methods\ncomprise the foundations of machine learning. Data mining is a related field of study,\nfocusing on exploratory data analysis (EDA) via unsupervised learning.[6][7]\nFrom  a  theoretical  viewpoint,  probably  approximately  correct  learning  provides  a\nframework for describing machine learning.\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and\npioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym\nself-teaching computers was also used in this time period.[10][11]",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 5\nIntroductionDefinition and Data Mining context\nOne possible definition:\nIn the context of data mining:-A portion of the observed data is generated by an unknown, anomalous process-This process differs from the standard processUntil now: -Assumption of one process that generates the data-Data Mining models reflecting that processNow: Interesting new observations that indicate differing mechanism behind data\n\u201cAn Outlier is an observation which deviates so much from the otherobservations as to arouse suspicions that it was generated by a differentmechanism\u201d (Hawkins, 1980)Source: Hawkins D. 1980. Identification of Outliers. Chapman and Hall.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 11\nMethodsCriteria: Type of anomaly\nPoint Anomalies: -A single data object is considered to benot \u201enormal\u201c in relation to the rest of the data -Example: \u201eAmount spend\u201c in credit fraud is very high compared to usual behaviorContextual Anomalies:-A single data point is only anomalous in a certain context-The context in form of context variables sets the neighborhood and defines normal behavior-E.g.observed temperature is normal during winter but are anomalous in JuneContextual Anomaly",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 42\nNormative Process Model\nFor each trace in the workflow logreplay with tokensandrecordat each step whether an activity was allowedto be executed according to the rules of the model\nIs (a, b, g, j, i, k, l) valid?\nIs (a, b, i, j, k, l) valid, too? If not, what does it violate?\nDumas et al. (2018)"
        ],
        "generated": "Data visualization is important for Data Science because it allows for the easier processing of large amounts of complex data. By using charts or graphs to visualize data, concepts can be conveyed in a universal manner, making it easier for individuals to understand and analyze the information. Additionally, data visualization allows for the exploration of different scenarios by making slight adjustments, enabling better decision-making and insights from the data.",
        "ground_truth": "Because of the way the human brain processes information, using charts or graphs to visualize large amounts of complex data is easier than poring over spreadsheets or reports. Data visualization is a quick, easy way to convey concepts in a universal manner \u2013 and you can experiment with different scenarios by making slight adjustments."
    },
    {
        "query": "What type of units are in ANN?",
        "retrieved": [
            "Artificial Neural Networks (ANN)Recap: Example Network descriptionStructure:\u00a7An input layer with 3 input units\u00a7A hidden layer with 4 hidden units\u00a7An output layer with 2 output unitsConnections and weights:\u00a7Every unit of a layer is connected to every unit of the following layer\u00a7Those connections are not all of the same strength, instead they are weighted\u00a7Those weights are the parameter of an ANN model and need to be learnedFeed forward run:\u00a7Once the weights are learned, a new input vector can be",
            "Artificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in",
            "traditional computer algorithm using rule-based programming.\nAn ANN is based on a collection of connected units called artificial neurons, (analogous\nto biological neurons in a biological brain). Each connection (synapse) between neurons\ncan  transmit  a  signal  to  another  neuron.  The  receiving  (postsynaptic)  neuron  can\nprocess  the  signal(s)  and  then  signal  downstream  neurons  connected  to  it.  Neurons",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 3\nArtificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in the input layer, you have as many nodes as input varibales + a constant (=bias)\u00a7Hidden units: Nodes in the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing the various outputs-Connection:\u00a7Each node is connected to the succeeding node (one direction only)\u00a7Each connection has a weight that need to be learned from the data\nIdothecalculations)",
            "surveys such as the one by Bishop.[27]\nThere  are  two  types  of  artificial  neural  network  (ANN):  feedforward  neural  network\n(FNN) or multilayer perceptron (MLP) and recurrent neural networks (RNN). RNNs have\ncycles in their connectivity structure, FNNs don't. In the 1920s, Wilhelm Lenz and Ernst\nIsing  created  the  Ising  model[28][29]  which  is  essentially  a  non-learning  RNN\narchitecture  consisting  of  neuron-like  threshold  elements.  In  1972,  Shun'ichi  Amari",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 5\nArtificial Neural Networks (ANN)Recap: Example Network descriptionStructure:\u00a7An input layer with 3 input units\u00a7A hidden layer with 4 hidden units\u00a7An output layer with 2 output unitsConnections and weights:\u00a7Every unit of a layer is connected to every unit of the following layer\u00a7Those connections are not all of the same strength, instead they are weighted\u00a7Those weights are the parameter of an ANN model and need to be learnedFeed forward run:\u00a7Once the weights are learned, a new input vector can be fed into the ANN and will be propagated through the net until an output is generated\u00a7Every unit (except the input units) are calculated by applying a function (mostly sigmoid or tanh) to the weighted linear combination of all units from the previous layer\u00a7See the picture in the previous slide for an example calculation\u00a7Play with ANN architectures (highly encouraged!!): http://playground.tensorflow.org/",
            "systems  \"learn\"  to  perform  tasks  by  considering  examples,  generally  without  being\nprogrammed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"artificial\nneurons\", which loosely model the neurons in a biological brain. Each connection, like\nthe  synapses  in  a  biological  brain,  can  transmit  information,  a  \"signal\",  from  one\nartificial neuron to another. An artificial neuron that receives a signal can process it and",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 10\nANN Problems: Input variances\nAssumption: Trained ANN that can recognize the imageCan it also recognize these images?Normalization required before processing by the ANN:\u00a7Align faces in the middle of the image (same orientation)\u00a7Normalize the size of the imagesComplete normalization is not possible for every taskWith a large enough dataset  (needs to cover all possiblevariations) a fully connected network could learn to ignorevariances\u00e0 Many weights would be identical (or similar) so that same shapes could be recognized across the image\u00e0 Lots of redundance in the weights\nLECUN, YANN; BENGIO, YOSHUA: Convolutional Networks for Images, Speech, and Time-Series. In M. A. Arbib(Ed.),The handbook of brain theory and neural networksMIT Press (1995).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 4\nExample ANN 1 hidden layer, 3 input nodes, 4 hidden nodes, 2 output nodes\nArtificial Neural Networks (ANN)Recap: Classic ANN architecture and example calculation",
            "systems  \"learn\"  to  perform  tasks  by  considering  examples,  generally  without  being\nprogrammed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"artificial\nneurons\", which loosely model the neurons in a biological brain. Each connection, like\nthe  synapses  in  a  biological  brain,  can  transmit  information,  a  \"signal\",  from  one\nartificial neuron to another. An artificial neuron that receives a signal can process it and\nthen  signal  additional  artificial  neurons  connected  to  it.  In  common  ANN\nimplementations, the signal at a connection between artificial neurons is a real number,\nand the output of each artificial neuron is computed by some non-linear function of the\nsum  of  its  inputs.  The  connections  between  artificial  neurons  are  called  \"edges\".\nArtificial neurons and edges typically have a weight that adjusts as learning proceeds.\nThe weight increases or decreases the strength of the signal at a connection. Artificial\nneurons may have a threshold such that the signal is only sent if the aggregate signal\ncrosses that threshold. Typically, artificial neurons are aggregated into layers. Different\nlayers  may  perform  different  kinds  of  transformations  on  their  inputs.  Signals  travel\nfrom the first layer (the input layer) to the last layer (the output layer), possibly after\ntraversing the layers multiple times.\nThe original goal of the ANN approach was to solve problems in the same way that a\nhuman brain would. However, over time, attention moved to performing specific tasks,\nleading  to  deviations  from  biology.  Artificial  neural  networks  have  been  used  on  a\nvariety  of  tasks,  including  computer  vision,  speech  recognition,  machine  translation,\nsocial network filtering, playing board and video games and medical diagnosis.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 6\nArtificial Neural Networks (ANN)Weights in ANN: Examples from Tensorflow PlaygroundDemonstration Example with direct interpretable weights (no HL):Linear separable data\nDirect connection\nNon Linearseparable data\nConnection via HL\nOnly HL determines output directly\nDemonstration Example with HL:",
            "for \"conceptual and engineering breakthroughs that have made deep neural networks a\ncritical component of computing\".[142]\nArtificial  neural  networks  (ANNs)  or  connectionist  systems  are  computing  systems\ninspired by the biological neural networks that constitute animal brains. Such systems",
            "memory is particularly effective for this use.[155][156]\nConvolutional  neural  networks  (CNNs)  are  used  in  computer  vision.[157]  CNNs  also\nhave been applied to acoustic modeling for automatic speech recognition (ASR).[158]\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues\nare overfitting and computation time.\nDNNs are prone to overfitting because of the added layers of abstraction, which allow\nthem to model rare dependencies in the training data. Regularization methods such as\nIvakhnenko's unit pruning[41] or weight decay (\n\u2113\n2\n{\\displaystyle \\ell _{2}}",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "functional programs.\nInductive  logic  programming  is  particularly  useful  in  bioinformatics  and  natural\nlanguage  processing.  Gordon  Plotkin  and  Ehud  Shapiro  laid  the  initial  theoretical\nfoundation for inductive machine learning in a logical setting.[82][83][84] Shapiro built\ntheir  first  implementation  (Model  Inference  System)  in  1981:  a  Prolog  program  that\ninductively inferred logic programs from positive and negative examples.[85] The term\ninductive  here  refers  to  philosophical  induction,  suggesting  a  theory  to  explain\nobserved facts, rather than mathematical induction, proving a property for all members\nof a well-ordered set.\nA machine learning model is a type of mathematical model that, once \"trained\" on a\ngiven dataset, can be used to make predictions or classifications on new data. During\ntraining,  a  learning  algorithm  iteratively  adjusts  the  model's  internal  parameters  to\nminimize  errors  in  its  predictions.[86]  By  extension,  the  term  \"model\"  can  refer  to\nseveral  levels  of  specificity,  from  a  general  class  of  models  and  their  associated\nlearning algorithms to a fully trained model with all its internal parameters tuned.[87]\nVarious types of models have been used and researched for machine learning systems,\npicking the best model for a task is called model selection.\nArtificial  neural  networks  (ANNs),  or  connectionist  systems,  are  computing  systems\nvaguely inspired by the biological neural networks that constitute animal brains. Such",
            "and computational resources. Various tricks, such as batching (computing the gradient\non several training examples at once rather than individual examples)[163] speed up\ncomputation. Large processing capabilities of many-core architectures (such as GPUs or\nthe  Intel  Xeon  Phi)  have  produced  significant  speedups  in  training,  because  of  the\nsuitability  of  such  processing  architectures  for  the  matrix  and  vector\ncomputations.[164][165]\nAlternatively,  engineers  may  look  for  other  types  of  neural  networks  with  more\nstraightforward  and  convergent  training  algorithms.  CMAC  (cerebellar  model\narticulation  controller)  is  one  such  kind  of  neural  network.  It  doesn't  require  learning\nrates or randomized initial weights. The training process can be guaranteed to converge\nin one step with a new batch of data, and the computational complexity of the training\nalgorithm is linear with respect to the number of neurons involved.[166][167]\nSince the 2010s, advances in both machine learning algorithms and computer hardware\nhave led to more efficient methods for training deep neural networks that contain many\nlayers of non-linear hidden units and a very large output layer.[168] By 2019, graphics\nprocessing  units  (GPUs),  often  with  AI-specific  enhancements,  had  displaced  CPUs  as\nthe  dominant  method  for  training  large-scale  commercial  cloud  AI  .[169]  OpenAI\nestimated  the  hardware  computation  used  in  the  largest  deep  learning  projects  from\nAlexNet (2012) to AlphaZero (2017) and found a 300,000-fold increase in the amount of\ncomputation required, with a doubling-time trendline of 3.4 months.[170][171]\nSpecial electronic circuits called deep learning processors were designed to speed up",
            "DNNs  can  model  complex  non-linear  relationships.  DNN  architectures  generate\ncompositional  models  where  the  object  is  expressed  as  a  layered  composition  of\nprimitives.[147]  The  extra  layers  enable  composition  of  features  from  lower  layers,\npotentially modeling complex data with fewer units than a similarly performing shallow\nnetwork.[7]  For  instance,  it  was  proved  that  sparse  multivariate  polynomials  are\nexponentially easier to approximate with DNNs than with shallow networks.[148]\nDeep architectures include many variants of a few basic approaches. Each architecture\nhas  found  success  in  specific  domains.  It  is  not  always  possible  to  compare  the\nperformance of multiple architectures, unless they have been evaluated on the same\ndata sets.[146]\nDNNs are typically feedforward networks in which data flows from the input layer to the\noutput layer without looping back. At first, the DNN creates a map of virtual neurons\nand assigns random numerical values, or \"weights\", to connections between them. The\nweights and inputs are multiplied and return an output between 0 and 1. If the network\ndid  not  accurately  recognize  a  particular  pattern,  an  algorithm  would  adjust  the\nweights.[149]  That  way  the  algorithm  can  make  certain  parameters  more  influential,\nuntil it determines the correct mathematical manipulation to fully process the data.\nRecurrent  neural  networks,  in  which  data  can  flow  in  any  direction,  are  used  for\napplications  such  as  language  modeling.[150][151][152][153][154]  Long  short-term",
            "{\\displaystyle \\{\\mathrm {onions,potatoes} \\}\\Rightarrow \\{\\mathrm {burger} \\}}\n found in the sales data of a supermarket would indicate that if a customer buys onions\nand potatoes together, they are likely to also buy hamburger meat. Such information\ncan be used as the basis for decisions about marketing activities such as promotional\npricing or product placements. In addition to market basket analysis, association rules\nare  employed  today  in  application  areas  including  Web  usage  mining,  intrusion\ndetection, continuous production, and bioinformatics. In contrast with sequence mining,\nassociation rule learning typically does not consider the order of items either within a\ntransaction or across transactions.\nLearning  classifier  systems  (LCS)  are  a  family  of  rule-based  machine  learning\nalgorithms that combine a discovery component, typically a genetic algorithm, with a\nlearning component, performing either supervised learning, reinforcement learning, or\nunsupervised  learning.  They  seek  to  identify  a  set  of  context-dependent  rules  that\ncollectively  store  and  apply  knowledge  in  a  piecewise  manner  in  order  to  make\npredictions.[81]\nInductive  logic  programming  (ILP)  is  an  approach  to  rule  learning  using  logic\nprogramming as a uniform representation for input examples, background knowledge,\nand hypotheses. Given an encoding of the known background knowledge and a set of\nexamples  represented  as  a  logical  database  of  facts,  an  ILP  system  will  derive  a\nhypothesized  logic  program  that  entails  all  positive  and  no  negative  examples.\nInductive  programming  is  a  related  field  that  considers  any  kind  of  programming\nlanguage  for  representing  hypotheses  (and  not  only  logic  programming),  such  as",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail."
        ],
        "generated": "The type of units in an Artificial Neural Network (ANN) are artificial neurons.",
        "ground_truth": "Input Units, Hidden Units, Output Units."
    },
    {
        "query": "What is the definition of Machine Learning by Samuel (1959)?",
        "retrieved": [
            "The term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and\npioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym\nself-teaching computers was also used in this time period.[10][11]",
            "\u201cMachine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.\u201d (Samuel, 1959)\u201cA subspecialty of computer science (within a field historically called \u201cartificial intelligence\u201d) concerned with the design and development of algorithms that allow computers to evolve behaviors based on empirical data. A major focus of machine learning research is to automatically learn to recognize complex patterns and make intelligent decisions based on data.\u201d",
            "Machine Learning\nMachine  learning  (ML)  is  a  field  of  study  in  artificial  intelligence  concerned  with  the\ndevelopment and study of statistical algorithms that can learn from data and generalize\nto  unseen  data,  and  thus  perform  tasks  without  explicit  instructions.[1]  Within  a\nsubdiscipline in machine learning, advances in the field of deep learning have allowed\nneural  networks,  a  class  of  statistical  algorithms,  to  surpass  many  previous  machine\nlearning approaches in performance.[2]\nML  finds  application  in  many  fields,  including  natural  language  processing,  computer\nvision,  speech  recognition,  email  filtering,  agriculture,  and  medicine.[3][4]  The\napplication of ML to business problems is known as predictive analytics.\nStatistics  and  mathematical  optimization  (mathematical  programming)  methods\ncomprise the foundations of machine learning. Data mining is a related field of study,\nfocusing on exploratory data analysis (EDA) via unsupervised learning.[6][7]\nFrom  a  theoretical  viewpoint,  probably  approximately  correct  learning  provides  a\nframework for describing machine learning.\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and\npioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym\nself-teaching computers was also used in this time period.[10][11]",
            "Although the earliest machine learning model was introduced in the 1950s when Arthur\nSamuel  invented  a  program  that  calculated  the  winning  chance  in  checkers  for  each\nside, the history of machine learning roots back to decades of human desire and effort\nto study human cognitive processes.[12] In 1949, Canadian psychologist Donald Hebb\npublished the book The Organization of Behavior, in which he introduced a theoretical",
            "Tom  M.  Mitchell  provided  a  widely  quoted,  more  formal  definition  of  the  algorithms\nstudied  in  the  machine  learning  field:  \"A  computer  program  is  said  to  learn  from\nexperience E with respect to some class of tasks T and performance measure P if its\nperformance at tasks in T, as measured by P,  improves with experience E.\"[18] This\ndefinition of the tasks in which machine learning is concerned offers a fundamentally\noperational definition rather than defining the field in cognitive terms. This follows Alan\nTuring's  proposal  in  his  paper  \"Computing  Machinery  and  Intelligence\",  in  which  the\nquestion \"Can machines think?\" is replaced with the question \"Can machines do what\nwe (as thinking entities) can do?\".[19]\nModern-day  machine  learning  has  two  objectives.   One  is  to  classify  data  based  on\nmodels which have been developed; the other purpose is to make predictions for future\noutcomes based on these models. A hypothetical algorithm specific to classifying data\nmay use computer vision of moles coupled with supervised learning in order to train it\nto  classify  the  cancerous  moles.  A  machine  learning  algorithm  for  stock  trading  may\ninform the trader of future potential predictions.[20]\nAs  a  scientific  endeavor,  machine  learning  grew  out  of  the  quest  for  artificial\nintelligence  (AI).  In  the  early  days  of  AI  as  an  academic  discipline,  some  researchers\nwere interested in having machines learn from data. They attempted to approach the\nproblem  with  various  symbolic  methods,  as  well  as  what  were  then  termed  \"neural\nnetworks\"; these were mostly perceptrons and other models that were later found to be\nreinventions  of  the  generalized  linear  models  of  statistics.[22]  Probabilistic  reasoning",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 26\nMachine Learning\n\u201cMachine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.\u201d (Samuel, 1959)\u201cA subspecialty of computer science (within a field historically called \u201cartificial intelligence\u201d) concerned with the design and development of algorithms that allow computers to evolve behaviors based on empirical data. A major focus of machine learning research is to automatically learn to recognize complex patterns and make intelligent decisions based on data.\u201d (Manyikaet al., 2011)Machine Learning explores the study and construction of algorithms that can learn from and make predictions on data. Such algorithms overcome following strictly static program instructions by making data-driven predictions or decisions through building a model from sample inputs. (Bishop, 2006)\n(Source: SoongsilUniversity, 2016)",
            "Although the earliest machine learning model was introduced in the 1950s when Arthur\nSamuel  invented  a  program  that  calculated  the  winning  chance  in  checkers  for  each\nside, the history of machine learning roots back to decades of human desire and effort\nto study human cognitive processes.[12] In 1949, Canadian psychologist Donald Hebb\npublished the book The Organization of Behavior, in which he introduced a theoretical\nneural structure formed by certain interactions among nerve cells.[13] Hebb's model of\nneurons  interacting  with  one  another  set  a  groundwork  for  how  AIs  and  machine\nlearning  algorithms  work  under  nodes,  or  artificial  neurons  used  by  computers  to\ncommunicate data.[12] Other researchers who have studied human cognitive systems\ncontributed  to  the  modern  machine  learning  technologies  as  well,  including  logician\nWalter  Pitts  and  Warren  McCulloch,  who  proposed  the  early  mathematical  models  of\nneural networks to come up with algorithms that mirror human thought processes.[12]\nBy  the  early  1960s,  an  experimental  \"learning  machine\"  with  punched  tape  memory,\ncalled Cybertron, had been developed by Raytheon Company to analyse sonar signals,\nelectrocardiograms, and speech patterns using rudimentary reinforcement learning. It\nwas  repetitively  \"trained\"  by  a  human  operator/teacher  to  recognize  patterns  and\nequipped  with  a  \"goof\"  button  to  cause  it  to  reevaluate  incorrect  decisions.[14]  A\nrepresentative book on research into machine learning during the 1960s was Nilsson's\nbook  on  Learning  Machines,  dealing  mostly  with  machine  learning  for  pattern\nclassification.[15]  Interest  related  to  pattern  recognition  continued  into  the  1970s,  as\ndescribed by Duda and Hart in 1973.[16] In 1981 a report was given on using teaching\nstrategies  so  that  an  artificial  neural  network  learns  to  recognize  40  characters  (26\nletters, 10 digits, and 4 special symbols) from a computer terminal.[17]",
            "Tom  M.  Mitchell  provided  a  widely  quoted,  more  formal  definition  of  the  algorithms\nstudied  in  the  machine  learning  field:  \"A  computer  program  is  said  to  learn  from\nexperience E with respect to some class of tasks T and performance measure P if its\nperformance at tasks in T, as measured by P,  improves with experience E.\"[18] This\ndefinition of the tasks in which machine learning is concerned offers a fundamentally",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 28\nMachine Learning CategorizationDifferent types of learning problems\nMachine Learning tasks can be classified into three broad categories of learning problems:Supervised Learning:The algorithm is given training data which contains examples of the input vectors along with their correspondingtarget vectors as the \u201ccorrect answer\u201d and the goal is to learn a general rule/ model that maps inputs to outputs.Examples: classification, regressionUnsupervised Learning: Principle: No labels (i.e.target values) are given to the algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal by itself (discovering hidden patterns) or a means towards a supervised approach (feature learning).Examples: cluster analysis, dimensionality reduction, density estimationReinforcement Learning:\u201c(\u2026) problem of finding suitable actions to take in a givensituation in order to maximize a reward. Here the learning algorithm is not given examples of optimal outputs, in contrast to supervised learning, but must instead discover them by a process of trial and error. Typicallythere is a sequence of states and actions in which the learning algorithm is interacting with its environment.\u201d (Bishop, 2006)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 29\nMachine Learning & Deep LearningDeep Learning as a new disruptive technology\nA special class of Machine Learning algorithms is Deep Learning.\u201cThe main concept in deep leaning algorithms is automating the extraction of representations(abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representation.\u201d(Najafabadi et al., 2016)\u201cThese algorithms are largely motivated by the field of artificial intelligence, which has the general goal of emulating the human brain\u2019s abilityto observe, analyze, learn, and make decisions, especially for extremely complex problems.\u201d (Najafabadi et al., 2016)\nhttps://blogs.nvidia.com",
            "meaning  that  even  the  coders  of  the  algorithm  cannot  audit  the  pattern  that  the\nmachine extracted out of the data.[123] The House of Lords Select Committee, which\nclaimed that such an \"intelligence system\" that could have a \"substantial impact on an\nindividual's  life\"  would  not  be  considered  acceptable  unless  it  provided  \"a  full  and\nsatisfactory explanation for the decisions\" it makes.[123]\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a\ncollision.[124]  Attempts  to  use  machine  learning  in  healthcare  with  the  IBM  Watson\nsystem  failed  to  deliver  even  after  years  of  time  and  billions  of  dollars\ninvested.[125][126] Microsoft's Bing Chat chatbot has been reported to produce hostile\nand offensive response against its users.[127]\nMachine  learning  has  been  used  as  a  strategy  to  update  the  evidence  related  to  a\nsystematic review and increased reviewer burden related to the growth of biomedical\nliterature. While it has improved with training sets, it has not yet developed sufficiently\nto reduce the workload burden without limiting the necessary sensitivity for the findings\nresearch themselves.[128]\nExplainable  AI  (XAI),  or  Interpretable  AI,  or  Explainable  Machine  Learning  (XML),  is\nartificial intelligence (AI) in which humans can understand the decisions or predictions\nmade  by  the  AI.[129]  It  contrasts  with  the  \"black  box\"  concept  in  machine  learning\nwhere even its designers cannot explain why an AI arrived at a specific decision.[130]\nBy  refining  the  mental  models  of  users  of  AI-powered  systems  and  dismantling  their\nmisconceptions,  XAI  promises  to  help  users  perform  more  effectively.  XAI  may  be  an",
            "to gain high-level understanding from digital images or videos. From the perspective of\nengineering, it seeks to automate tasks that the human visual system can do.[5][6][7]\n\"Computer  vision  is  concerned  with  the  automatic  extraction,  analysis,  and\nunderstanding  of  useful  information  from  a  single  image  or  a  sequence  of  images.  It\ninvolves the development of a theoretical and algorithmic basis to achieve automatic\nvisual  understanding.\"[8]  As  a  scientific  discipline,  computer  vision  is  concerned  with\nthe  theory  behind  artificial  systems  that  extract  information  from  images.  The  image\ndata can take many forms, such as video sequences, views from multiple cameras, or\nmulti-dimensional  data  from  a  medical  scanner.[9]  As  a  technological  discipline,\ncomputer vision seeks to apply its theories and models for the construction of computer\nvision systems. Machine vision refers to a systems engineering discipline, especially in\nthe context of factory automation. In more recent times, the terms computer vision and\nmachine vision have converged to a greater degree.[10]:\u200a13\u200a\nIn the late 1960s, computer vision began at universities that were pioneering artificial\nintelligence.  It  was  meant  to  mimic  the  human  visual  system  as  a  stepping  stone  to\nendowing robots with intelligent behavior.[11] In 1966, it was believed that this could\nbe achieved through an undergraduate summer project,[12] by attaching a camera to a\ncomputer and having it \"describe what it saw\".[13][14]\nWhat distinguished computer vision from the prevalent field of digital image processing\nat that time was a desire to extract three-dimensional structure from images with the\ngoal  of  achieving  full  scene  understanding.  Studies  in  the  1970s  formed  the  early\nfoundations  for  many  of  the  computer  vision  algorithms  that  exist  today,  including\nextraction  of  edges  from  images,  labeling  of  lines,  non-polyhedral  and  polyhedral",
            "Deep learning architectures for convolutional neural networks (CNNs) with convolutional\nlayers and downsampling layers began with the Neocognitron introduced by Kunihiko\nFukushima in 1979, though not trained by backpropagation.[45][46]\nBackpropagation  is  an  efficient  application  of  the  chain  rule  derived  by  Gottfried\nWilhelm  Leibniz  in  1673[47]  to  networks  of  differentiable  nodes.  The  terminology\n\"back-propagating  errors\"  was  actually  introduced  in  1962  by  Rosenblatt,[37]  but  he\ndid  not  know  how  to  implement  this,  although  Henry  J.  Kelley  had  a  continuous\nprecursor of backpropagation in 1960 in the context of control theory.[48] The modern\nform  of  backpropagation  was  first  published  in  Seppo  Linnainmaa's  master  thesis\n(1970).[49][50][31]  G.M.  Ostrovski  et  al.  republished  it  in  1971.[51][52]  Paul  Werbos\napplied backpropagation to neural networks in 1982[53] (his 1974 PhD thesis, reprinted\nin  a  1994  book,[54]  did  not  yet  describe  the  algorithm[52]).  In  1986,  David  E.\nRumelhart et al. popularised backpropagation but did not cite the original work.[55][56]\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply\nCNN  to  phoneme  recognition.  It  used  convolutions,  weight  sharing,  and\nbackpropagation.[57][58]  In 1988, Wei Zhang applied a backpropagation-trained CNN\nto alphabet recognition.[59] \nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP\ncodes on mail. Training required 3 days.[60] In 1990, Wei Zhang implemented a CNN on\noptical computing hardware.[61] In 1991, a CNN was applied to medical image object\nsegmentation[62] and breast cancer detection in mammograms.[63] LeNet-5 (1998), a",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 9\nMethodsCriteria for anomaly detection problem definition\nThere is NO general approach that works for all application domainsDifferent problem definitionsdepending on some basic criteria:-Nature of data-Labels-Anomaly Type-OutputAnomaly Detection methods can be found in many research fields:-Machine Learning (Data Mining)-Statistics-Information Theory-Spectral Theory-\u2026",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 39\nVariety of Data Analysis TechniquesWhich one to choose?\nHow do we know which technique/algorithm to choose?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 41\nDocument preparationLinguistic preparation\nActivitiesFilter termsPerform lexical analysisPerform syntactic analysisPerform semantic analysisFocal points of the technical preparationExamination of linguistic aspects ofthe textsProcesses that define terms on the basis of linguisticpropertiesRecognizesyntacticand semanticelements\nTerme filtern\nLexikalische \nAnalyse \ndurchf\u00fchren\nSyntaktische \nAnalyse \ndurchf\u00fchren\nSemantische \nAnalyse \ndurchf\u00fchren\nZus\u00e4tzliche \nHilfsmittelProblemstellung",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 5\nAssociationAnalysisSupport and Confidence\n{ }tD ( AB ) tsup( A B ) D\n\u00ce\u00c8 \u00cd\u00ae =\n{ }\n{ }\ntD ( AB ) t sup( A B )conf(A B ) tD A t s u p ( A )\n\u00ce\u00c8 \u00cd \u00ae\u00ae == \u00ce\u00cd\nThe Supportof a rule is defined as the proportion of transactions from D that satisfy that rule:\nThe Confidenceof a rule is defined as the proportion of transactions involving A and B in the set of transactions satisfying the rule body A. The formal representation is:",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 22\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 25\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n3.1 Partitioned Cluster Methods\n3.2 Hierarchical Cluster Methods",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 29\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n7.1 Anomaly Detection Introduction\n7.2 Methods",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 102\nOutcome evaluation \nInputProblemResultsActivitiesSelect key figuresEvaluate resultsReview procedure and define next steps\nText-Mining-\nVerfahren \nanwenden\nProblemstellung\nErgebnisse\nErgebnisse evaluieren und interpretieren\nKennzahlen \nausw\u00e4hlen\nErgebnisse \nauswerten\nVorgehen \n\u00fcberpr\u00fcfen und \nn\u00e4chste \nSchritte \ndefinieren\nMa\u00dfnahmen \nableiten und \nErgebnisse \nanwenden",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)"
        ],
        "generated": "The definition of Machine Learning by Samuel (1959) is: \"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\"",
        "ground_truth": "Machine Learning: Field of study that gives computers the ability to learn without being explicitly programmed."
    },
    {
        "query": "What is data mining explained by Cabena et al. (1997)?",
        "retrieved": [
            "\u201eData Mining, as we use the term, is the exploration and analysis, by automatic or semiautomatic means, of large quantities of data in order to discover meaningful patterns and rules.\u201c(Berry et al. 1997)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 21\nData MiningDefinition and context\n\u201eData Mining is the process of extracting previously unknown, valid, and actionable informationfrom large databases and then using the information to make crucial business decisions.\u201c(Cabena et al. 1997)\n\u201eData Mining, as we use the term, is the exploration and analysis, by automatic or semiautomatic means, of large quantities of data in order to discover meaningful patterns and rules.\u201c(Berry et al. 1997)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 21\nData MiningDefinition and context\n\u201eData Mining is the process of extracting previously unknown, valid, and actionable informationfrom large databases and then using the information to make crucial business decisions.\u201c(Cabena et al. 1997)",
            "Statistics  and  mathematical  optimization  (mathematical  programming)  methods\ncomprise the foundations of machine learning. Data mining is a related field of study,\nfocusing on exploratory data analysis (EDA) via unsupervised learning.[6][7]\nFrom  a  theoretical  viewpoint,  probably  approximately  correct  learning  provides  a\nframework for describing machine learning.\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and",
            "IntroductionDefinition and Data Mining context\nOne possible definition:\nIn the context of data mining:-A portion of the observed data is generated by an unknown, anomalous process-This process differs from the standard processUntil now: -Assumption of one process that generates the data-Data Mining models reflecting that processNow: Interesting new observations that indicate differing mechanism behind data",
            "Data Mining\n...from semi-structured& unstructuredtext data\ne.g. documents, e-mails,...\nText mining\n...from web-based data\ne.g. web pages, log files,...\nWeb Mining\nWeb Usage MiningWeb Content MiningWeb Structure Mining",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 20\nB) Data MiningThe searchforthedigital treasures\nData Mining \u2013A metaphor from the mining industryMining: The industry or activity of removing substances, such as coal, metal, gold or diamonds, from the ground by digging.\nhttp://djitz.com\nhttp://pinterest.com\nData Mining: the process of using special software to look at large amounts of computer data in order to find out useful information, for example what types of product a company's customers buy.\nhttps://dictionary.cambridge.org/de/worterbuch/englisch/mining\nhttps://dictionary.cambridge.org/de/worterbuch/englisch/data-mining",
            "Databases with Noise. Proceedings of the 2nd International Conference on Knowledge Discovery and Data mining, 226-231",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 70\nDocument preparationCustomize data structure\nMany text mining techniques have their origins in data mining, and often classical data mining techniques can also be applied to text data, provided that the data is available in a suitable structure.In the literature, the vector space model according to Salton et al. (1975) is mostly used for this purpose, whereby the text data areavailable in a structured tabular form:Terms and documents are transformed into a matrixThe lines list the termsIn the columns the documents are listedThe intersections show whether a term occurs in a document or not\nTerme \nindexieren und \ngewichten\nDatenstruktur \nanpassen\nVorbereitende \nAnalysen \ndurchf\u00fchren\nTerme \nreduzieren\nD1D2D3T11 0 1T20 0 1T31 1 0",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 10\nText mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff.",
            "Many reporting and analytic tools already work with data warehouses\nCasati et al. (2017)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 6\nDefinition of Text MiningUnderstanding of the term in the literature\nSources: Schieber & Hilbert (2014c), p. 13\nInformation extraction\n\u2022Extraction of passages from texts\u2022Annotation of these passages with attributes\u2022Ex: \u2022Recognition of companies and people\u2022Assignment of functions of a person in the company\u2022Source: Hotho et al. (2005), p. 45ff.\nAnalysis method\n\u2022Methods for computer-aided text analysis \u2022(semi-)automatic structuring of texts\u2022Ex:\u2022Text Clustering\u2022Text Categorization \u2022Sources: He (2013), p. 501; Heyer et al. (2006), p. 3.\nKnowledge generation process\n\u2022Analogous to the KDD process for data mining according to Fayyad (1996), p. 9.\u2022Knowledge Discovery in Textual Databases (KDT)\u2022Process includes, among other things, phases for the selection, preparation and analysis of text data\u2022Sources: Feldman & Dagan (1995), p. 112; Hippner & Rentzmann (2006), p. 287.",
            "Atahighlevel,datascienceisasetoffundamentalprinciplesthatsupportandguidetheprincipledextractionofinformationandknowledgefromdata.Possiblythemostcloselyrelatedconcepttodatascienceisdatamining-theactualextractionofknowledgefromdataviatechnologiesthatincorporatetheseprinciples.Therearehundredsofdifferentdataminingalgorithms,andagreatdealofdetailtothemethodsofthefield.Wearguethatunderlyingallthesemanydetailsisamuchsmallerandmoreconcisesetoffundamentalprinciples.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 19\nProcedure model according to Schieber & Hilbert\nProcess models such as the KDD, SEMMA or CRISP-DM process structure phases and tasks of the data mining processAnalogously, the procedure model according to Schieber & Hilbert structures the phases and tasks of the text mining processSources: Kurgan & Musilek (2006), p. 9ff.; Schieber & Hilbert (2014a), p. 45\nAufgaben \ndefinieren\nDokumente \nselektieren und \nuntersuchen\nDokumente \naufbereiten\nText-Mining-\nVerfahren \nanwenden\nErgebnisse \nevaluieren und \ninterpretieren\nMa\u00dfnahmen \nableiten und \nErgebnisse \nanwenden\nProblemstellung\nQuellsysteme Ergebnisse\nZus\u00e4tzliche \nHilfsmittel\nMa\u00dfnahmenArbeitsbereich",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 20\nSome Definitions\u2026 \u2026 collected by Chatfield et al. (2014)\nSource Definition: Data scientists are \u2026\nGranville (2014) \u201cnot statisticians, nor data analysts, nor computer scientists, nor software engineers, nor\nbusiness analysts. They have some knowledge in each of these areas but also some outside\nof these areas.\u201d\nDhar (2013) \u201crequires an integrated skill set spanning mathematics, machine learning, artificial\nintelligence, statistics, databases, and optimization, along with a deep understanding of the\ncraft of problem formulation to engineer effective solutions.\u201d\nDavenport & Patil (2012) \u201cthe people who understand how to fish out answers to important business questions from\ntoday\u2019s tsunami of unstructured information.\u201d\nMohanty et al. (2013) \u201cthe practitioners of the analytics models solving business problems. They incorporate\nadvanced analytical approaches using sophisticated analytics and data visualization tools to\ndiscover patterns in data. In many cases, these practitioners work with well-established\nanalytics techniques such as logistic regression methods, clustering methods, and\nclassification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,\nexplore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 10\nProcess Warehouse Functionality\n\u201cA data warehouse that caters for the need of process analytics\u201d\nCollection and integration of historic and current data for predefinedprocess performance indicators\nTransformation, calculationand aggregationof process performance indicators\nProvisioning of toolsfor process-basedmultidimensional analysisand navigation\nDistributionand presentationof analysis results\nKueng et al. (2001), List et al. (2002), Becker et al. (2006)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 13\nProcess models in business informaticsProcess models specify the sequence in which certain activitiesshouldbe carried out or proceduresshouldbe used in order to successfully complete (IT) projects; this serves on the one hand to structuretasksand on the other hand to reduce complexity within these projects.Process models such as the KDD, SEMMA or CRISP-DM processstructure phases and tasks of the data mining processSources: Fil\u00df et al. (2005, p. 184; Gutzwiller (1994), p. 32;Jablonski (1997), p. 489f.; Mertens (2001), p. 498; Stahlknecht & Hasenkamp (2005), p. 215\nAdapted from Chapman et al. (2000), p. 13.",
            "Deep learning architectures for convolutional neural networks (CNNs) with convolutional\nlayers and downsampling layers began with the Neocognitron introduced by Kunihiko\nFukushima in 1979, though not trained by backpropagation.[45][46]\nBackpropagation  is  an  efficient  application  of  the  chain  rule  derived  by  Gottfried\nWilhelm  Leibniz  in  1673[47]  to  networks  of  differentiable  nodes.  The  terminology\n\"back-propagating  errors\"  was  actually  introduced  in  1962  by  Rosenblatt,[37]  but  he\ndid  not  know  how  to  implement  this,  although  Henry  J.  Kelley  had  a  continuous\nprecursor of backpropagation in 1960 in the context of control theory.[48] The modern\nform  of  backpropagation  was  first  published  in  Seppo  Linnainmaa's  master  thesis\n(1970).[49][50][31]  G.M.  Ostrovski  et  al.  republished  it  in  1971.[51][52]  Paul  Werbos\napplied backpropagation to neural networks in 1982[53] (his 1974 PhD thesis, reprinted\nin  a  1994  book,[54]  did  not  yet  describe  the  algorithm[52]).  In  1986,  David  E.\nRumelhart et al. popularised backpropagation but did not cite the original work.[55][56]\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply\nCNN  to  phoneme  recognition.  It  used  convolutions,  weight  sharing,  and\nbackpropagation.[57][58]  In 1988, Wei Zhang applied a backpropagation-trained CNN\nto alphabet recognition.[59] \nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP\ncodes on mail. Training required 3 days.[60] In 1990, Wei Zhang implemented a CNN on\noptical computing hardware.[61] In 1991, a CNN was applied to medical image object\nsegmentation[62] and breast cancer detection in mammograms.[63] LeNet-5 (1998), a",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 43\nTokens in a Normative Process Model\nHow many misplaced tokens in (a, b, i, j, k, l)?\nthe number of tokens that are correctly produced pthe number of tokens that are correctly consumed cthe number of tokens that are missing for executing mthe next activity in the log, andthe number of tokens remaining unconsumed rafter executing the final activity in the log\nproduced pconsumed cmissing mremaining r\nDumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 42\nNormative Process Model\nFor each trace in the workflow logreplay with tokensandrecordat each step whether an activity was allowedto be executed according to the rules of the model\nIs (a, b, g, j, i, k, l) valid?\nIs (a, b, i, j, k, l) valid, too? If not, what does it violate?\nDumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 44\nTokens in a Normative Process Model\nHow many misplaced tokens in (a, b, i, j, k, l)?\nthe number of tokens that are correctly produced pthe number of tokens that are correctly consumed cthe number of tokens that are missing for executing mthe next activity in the log, andthe number of tokens remaining unconsumed rafter executing the final activity in the log\nproduced pconsumed cmissing mremaining r\nDumas et al. (2018)\n1100\n1100 1100 1100\n1001\n1100\n1100 11001100\n1100\n1100\n0110",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 45\nTokens in a Normative Process Model\nHow many misplaced tokens in (a, b, i, j, k, l)?\nthe number of tokens that are correctly produced p (13)the number of tokens that are correctly consumed c (13)the number of tokens that are missing for executing m(1)the next activity in the log, andthe number of tokens remaining unconsumed r (1)after executing the final activity in the log\nproduced pconsumed cmissing mremaining r\nDumas et al. (2018)\n1100\n1100 1100 1100\n1001\n1100\n1100 11001100\n1100\n1100\n0110\n1100"
        ],
        "generated": "According to Cabena et al. (1997), data mining is defined as the process of extracting previously unknown, valid, and actionable information from large databases and then using the information to make crucial business decisions.",
        "ground_truth": "Data Mining is the process of extracting previously unknown, valid, and actionable information from large databases and then using the information to make crucial business decisions."
    },
    {
        "query": "What are the challenges of text mining?",
        "retrieved": [
            "Text mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 10\nText mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 10\nText mining challenges",
            "Text Mining in the Big Data EnvironmentThe amount of available texts increases extremely in Web 2.0 (keyword: user-generated content)Social networks, forums and blogs can be interesting sources for product improvements, marketing activities or opinion analysisText processing and analysis is very computationally intensive even for a few documentsBig Data technologies enable high-performance and scalable analysis systemsEx: Hadoop-based systemsDistributed File Systems (Hadoop Distributed File",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 3\nText Mining in the Big Data EnvironmentThe amount of available texts increases extremely in Web 2.0 (keyword: user-generated content)Social networks, forums and blogs can be interesting sources for product improvements, marketing activities or opinion analysisText processing and analysis is very computationally intensive even for a few documentsBig Data technologies enable high-performance and scalable analysis systemsEx: Hadoop-based systemsDistributed File Systems (Hadoop Distributed File System, HDFS).Distributed execution framework MapReduce Implementation e.g. in Apache Tika \nSource: http://cms.searchenginewatch.com/IMG/807/286807/social-media-stats-big-data.png?1397090150, retrieved on 11/22/2014.",
            "From a process perspective, text mining includes both the collection and preparation of texts and the exploitation of the results.Analysis techniques are used to evaluate and generate the text mining results.\nThe processing and analysis steps are integrated as functions in application systems.",
            "Text Mining\nProceduremodel: Text miningprocedure",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 7\nDefinition of Text MiningUnderstanding of terms in the context of the lecture\nSources: Schieber & Hilbert (2014c), p. 13\nThe term text mining refers to the analytical process for computer-assisted knowledge generation from text data.\nFrom a process perspective, text mining includes both the collection and preparation of texts and the exploitation of the results.Analysis techniques are used to evaluate and generate the text mining results.\nThe processing and analysis steps are integrated as functions in application systems.\nText data can be both internal and external to the company; in the context of data processing, one also speaks of unstructured data.The goal of text mining is to generate new knowledge to be translated into action.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 14\nProcedure model for text mining\nAccording to this understanding of the term and in connection with the definition of text mining, a procedure model for text mining thus considers the flow of the analytical process for the (partially) automated extraction of knowledge from unstructured data. The process model divides this process into several phases, in which, in turn, different activities must be carried out in order to convert the raw data into useful knowledge over several steps. To perform the activities, procedures, methods and techniques must be applied to achieve the desired results.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 80\nText mining methodsSegmentation method\nSegmentation methods group data sets without depending on a predefined category systemThe methods examine the data sets and calculate their similarity in terms of their attributesIn the context of text analysis, the main attributes available are the terms contained in the text Documents are therefore similar if they have many terms in commonMethods used in the literature:K-Means algorithmTopic Modeling",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 41\nVariety of Data Analysis TechniquesWhat is best practice?\nWhat are the most commonly usedtechniques/algorithms?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 58\n2. Data preparation \u2013 normalization\nLSTMs are sensitive to the scale of the data\u00e0 Scale input data to values between 0 and 1Remeber to reverse this normalization when you want to display predictions\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))normalized_closing_values = scaler.fit_transform(closing_values)[...]predictions = scaler.inverse_transform(normalized_predictions)",
            "The robot later practiced the task with the help of some coaching from the trainer, who\nprovided feedback such as \"good job\" and \"bad job\".[273]\nDeep learning has attracted both criticism and comment, in some cases from outside\nthe field of computer science.\nA main criticism concerns the lack of theory surrounding some methods.[274] Learning\nin the most common deep architectures is implemented using well-understood gradient\ndescent.  However,  the  theory  surrounding  other  algorithms,  such  as  contrastive\ndivergence is less clear.[citation needed] (e.g., Does it converge? If so, how fast? What\nis it approximating?) Deep learning methods are often looked at as a black box, with\nmost confirmations done empirically, rather than theoretically.[275]\nIn further reference to the idea that artistic sensitivity might be inherent in relatively\nlow levels of the cognitive hierarchy, a published series of graphic representations of\nthe internal states of deep (20-30 layers) neural networks attempting to discern within\nessentially  random  data  the  images  on  which  they  were  trained[276]  demonstrate  a\nvisual appeal: the original research notice received well over 1,000 comments, and was\nthe  subject  of  what  was  for  a  time  the  most  frequently  accessed  article  on  The\nGuardian's[277] website.\nSome  deep  learning  architectures  display  problematic  behaviors,[278]  such  as\nconfidently  classifying  unrecognizable  images  as  belonging  to  a  familiar  category  of",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 19\nDifferent Expectations\u2026\u2026 what people think I do \nWhat my friends think I \ndo\nWhat my mother thinks I \ndo\nWhat my boss thinks I do\nWhat I really doWhat I think I doWhat society thinks I do",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "The drawback of this method is that it is very computationally intensive, and systems\nfor  real-time  analysis  are  still  to  be  developed.  For  the  moment,  a  more  interesting\napproach  would  be  to  map  simple  primitive  objects  to  the  person's  most  important\nbody  parts  (for  example  cylinders  for  the  arms  and  neck,  sphere  for  the  head)  and\nanalyze the way these interact with each other. Furthermore, some abstract structures\nlike  super-quadrics  and   generalized  cylinders  maybe  even  more  suitable  for\napproximating the body parts.\nInstead  of  using  intensive  processing  of  the  3D  models  and  dealing  with  a  lot  of\nparameters, one can just use a simplified version of joint angle parameters along with\nsegment lengths. This is known as a skeletal representation of the body, where a virtual\nskeleton  of  the  person  is  computed  and  parts  of  the  body  are  mapped  to  certain\nsegments.  The  analysis  here  is  done  using  the  position  and  orientation  of  these\nsegments and the relation between each one of them( for example the angle between\nthe joints and the relative position or orientation)\nAdvantages of using skeletal models:\nAppearance-based models no longer use a spatial representation of the body, instead\nderiving  their  parameters  directly  from  the  images  or  videos  using  a  template\ndatabase. Some are based on the deformable 2D templates of the human parts of the\nbody, particularly the hands. Deformable templates are sets of points on the outline of\nan object, used as interpolation nodes for the object's outline approximation. One of the\nsimplest interpolation functions is linear, which performs an average shape from point",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail.",
            "predesignated criteria, while observations drawn from different clusters are dissimilar.\nDifferent clustering techniques make different assumptions on the structure of the data,\noften  defined  by  some  similarity  metric  and  evaluated,  for  example,  by  internal\ncompactness, or the similarity between members of the same cluster, and separation,\nthe  difference  between  clusters.  Other  methods  are  based  on  estimated  density  and\ngraph connectivity.\nA special type of unsupervised learning called, self-supervised learning involves training\na model by generating the supervisory signal from the data itself.[53][54]\nSemi-supervised  learning  falls  between  unsupervised  learning  (without  any  labeled\ntraining data) and supervised learning (with completely labeled training data). Some of\nthe  training  examples  are  missing  training  labels,  yet  many  machine-learning\nresearchers  have  found  that  unlabeled  data,  when  used  in  conjunction  with  a  small\namount of labeled data, can produce a considerable improvement in learning accuracy.\nIn  weakly  supervised  learning,  the  training  labels  are  noisy,  limited,  or  imprecise;\nhowever, these labels are often cheaper to obtain, resulting in larger effective training\nsets.[55]\nReinforcement  learning  is  an  area  of  machine  learning  concerned  with  how  software\nagents  ought  to  take  actions  in  an  environment  so  as  to  maximize  some  notion  of\ncumulative reward. Due to its generality, the field is studied in many other disciplines,"
        ],
        "generated": "The challenges of text mining include dealing with very large amounts of text data, high dimensionality, noise in the data, and the difficulty of understanding the results. Additionally, texts are usually not intended for computer-based processing, as they have a complex and little standardized structure, and language, morphology, syntax, and semantics strongly depend on the author and the target audience of the text.",
        "ground_truth": "Very large amounts of (text) data, High dimensionality, 'Noise' in the data, Understanding the results, Texts are usually not intended for computer-based processing."
    },
    {
        "query": "What is Diversive Clustering?",
        "retrieved": [
            "DiversiveClusteringAll objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained.\n\u2022Starting point is the class of all objects.\u2022Successive transition to finer decompositions\u2022Termination as soon as given criterion is fulfilled",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 6\nSubdivision ofclusterapproachesAgglomerativeand single-modal methods\nFurthermore, one still distinguishes: \u2015Agglomerativeand divisive methods. The former start from one-element classes and combine elements into classes step by step. Divisive methods,on the other hand, start from an initial decomposition which is refined (i.e., divided) step by step. \u2015Single-modal methods that group objects or features into classes, and dual-modalmethods that simultaneously classify objects and features of a data matrix.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 35\nClustering basedAdvantages",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 2\nRecap: Aims of the cluster analysis\nSegmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that\u2022between the elements of the same classes the greatest possible similarity,\u2022between the elements of different classes the greatest possible diversity is achieved",
            "Furthermore, one still distinguishes: \u2015Agglomerativeand divisive methods. The former start from one-element classes and combine elements into classes step by step. Divisive methods,on the other hand, start from an initial decomposition which is refined (i.e., divided) step by step. \u2015Single-modal methods that group objects or features into classes, and dual-modalmethods that simultaneously classify objects and features of a data matrix.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 3\nAimsoftheclusteranalysis\n\u2015Segmentationorcluster analysis is used to group objects and/or characteristics into classes or groups, so that-between the elements of thesame classes as similar as possible,-between the elements of different classes the greatest possible dissimilarityis achieved.\u2015The clusters are not known beforehand.\u2015So-calledunsupervised learning methods are used, for example.",
            "Clustering basedAdvantages\nClustering based techniques can operate in an unsupervised mode.Such techniques can often be adapted to other complex data types by simply plugging in a clustering algorithm that can handle the particular datatype.The testing phase for clustering basedtechniques is fast since the number of clusters against which every test instance needs to be compared is a small constant.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 35\nClustering basedAdvantages\nClustering based techniques can operate in an unsupervised mode.Such techniques can often be adapted to other complex data types by simply plugging in a clustering algorithm that can handle the particular datatype.The testing phase for clustering basedtechniques is fast since the number of clusters against which every test instance needs to be compared is a small constant.",
            "Aimsoftheclusteranalysis\n\u2015Segmentationorcluster analysis is used to group objects and/or characteristics into classes or groups, so that-between the elements of thesame classes as similar as possible,-between the elements of different classes the greatest possible dissimilarityis achieved.\u2015The clusters are not known beforehand.\u2015So-calledunsupervised learning methods are used, for example.",
            "Basics ofsegmentation\nCluster types",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 34\nClustering basedOverview",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 34\nClustering basedOverview\nIdea 1: Normal data instances belong to a cluster in the data, while anomalies do not belong to any cluster:Requires cluster method that does not put every data point into clustersE.g.: DBSCAN, ROCK, WaveCluster, FindOutIdea 2: Normal data instances lie close to their closest cluster centroid, while anomalies are far away from their closest cluster centroid:Commonused methods are SOM, K-means, Expectation MaximizationSemi-supervised approach can be used to improve resultsIdea 1 and 2 arenot working well when anomalies form clusters themselvesIdea 3: Normal data instances belong to large and dense clusters, while anomalies either belong to small or sparse clustersCommonly used: FindCBLOFCBLOF analogous to LOF captures cluster size as well as centroid distance based on clustering results",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 15\nMethodsOverview\nClassification basedNeighbor based\nClustering basedStatistical methods\nInformation Theory basedSpectral Theory based\nAnomaly Detection Methods*\n*For Information Theory based and Spectral Theory based see [Chandolaet al., 2009]",
            "classified  or  categorized.  Instead  of  responding  to  feedback,  unsupervised  learning\nalgorithms  identify  commonalities  in  the  data  and  react  based  on  the  presence  or\nabsence  of  such  commonalities  in  each  new  piece  of  data.  Central  applications  of\nunsupervised  machine  learning  include  clustering,  dimensionality  reduction,[7]  and\ndensity estimation.[52]\nCluster analysis is the assignment of a set of observations into subsets (called clusters)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "comes from the basic assumptions they work with: in machine learning, performance is\nusually evaluated with respect to the ability to reproduce known knowledge, while in\nknowledge discovery and data mining (KDD) the key task is the discovery of previously\nunknown  knowledge.  Evaluated  with  respect  to  known  knowledge,  an  uninformed\n(unsupervised) method will easily be outperformed by other supervised methods, while\nin a typical KDD task, supervised methods cannot be used due to the unavailability of\ntraining data.\nMachine  learning  also  has  intimate  ties  to  optimization:  Many  learning  problems  are\nformulated as minimization of some loss function on a training set of examples. Loss\nfunctions express the discrepancy between the predictions of the model being trained\nand the actual problem instances (for example, in classification, one wants to assign a\nlabel to instances, and models are trained to correctly predict the preassigned labels of\na set of examples).[35]\nCharacterizing  the  generalization  of  various  learning  algorithms  is  an  active  topic  of\ncurrent research, especially for deep learning algorithms.\nMachine  learning  and  statistics  are  closely  related  fields  in  terms  of  methods,  but\ndistinct  in  their  principal  goal:  statistics  draws  population  inferences  from  a  sample,\nwhile  machine  learning  finds  generalizable  predictive  patterns.[36]  According  to\nMichael  I.  Jordan,  the  ideas  of  machine  learning,  from  methodological  principles  to\ntheoretical  tools,  have  had  a  long  pre-history  in  statistics.[37]  He  also  suggested  the\nterm data science as a placeholder to call the overall field.[37]",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 49\nRis an open sourceprogramming language with focus on better user friendlydata analysis, statistics and graphical modelsR is an implementation of S programming languageCreated by Ross Ihaka and Robert Gentleman Released in 1995R has been used primarily in academicsand research,but it is rapidly expanding into the enterprise market\u201cThe closer you are to statistics, research and data science,the more you might prefer R.\u201dStandard IDE is R StudioMain advantage: graphical capabilities for data visualization\n(Source: https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis)",
            "meaning  that  even  the  coders  of  the  algorithm  cannot  audit  the  pattern  that  the\nmachine extracted out of the data.[123] The House of Lords Select Committee, which\nclaimed that such an \"intelligence system\" that could have a \"substantial impact on an\nindividual's  life\"  would  not  be  considered  acceptable  unless  it  provided  \"a  full  and\nsatisfactory explanation for the decisions\" it makes.[123]\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a\ncollision.[124]  Attempts  to  use  machine  learning  in  healthcare  with  the  IBM  Watson\nsystem  failed  to  deliver  even  after  years  of  time  and  billions  of  dollars\ninvested.[125][126] Microsoft's Bing Chat chatbot has been reported to produce hostile\nand offensive response against its users.[127]\nMachine  learning  has  been  used  as  a  strategy  to  update  the  evidence  related  to  a\nsystematic review and increased reviewer burden related to the growth of biomedical\nliterature. While it has improved with training sets, it has not yet developed sufficiently\nto reduce the workload burden without limiting the necessary sensitivity for the findings\nresearch themselves.[128]\nExplainable  AI  (XAI),  or  Interpretable  AI,  or  Explainable  Machine  Learning  (XML),  is\nartificial intelligence (AI) in which humans can understand the decisions or predictions\nmade  by  the  AI.[129]  It  contrasts  with  the  \"black  box\"  concept  in  machine  learning\nwhere even its designers cannot explain why an AI arrived at a specific decision.[130]\nBy  refining  the  mental  models  of  users  of  AI-powered  systems  and  dismantling  their\nmisconceptions,  XAI  promises  to  help  users  perform  more  effectively.  XAI  may  be  an",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail."
        ],
        "generated": "Diversive Clustering is a method where all objects initially belong to one cluster, which is then divided into sub-clusters. These sub-clusters are successively divided into their own sub-clusters until the desired cluster structure is obtained. The process continues until the desired cluster structure is achieved.",
        "ground_truth": "All objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained."
    },
    {
        "query": "What types of statistics are there?",
        "retrieved": [
            "Statistics= teaching in dealing with quantitative information (= data)\u2022Descriptiveor InductiveDescriptive StatisticsTask: Data should be prepared and graphically displayed.\u2022Concentration of the underlying extensive database on a few meaningful measures.\u2022In extreme cases, it is possible that a single number characterizes the entire data setInductive statisticsSummary of all methods needed for rational decision making under uncertainty or risk.Task: The properties of the population are derived",
            "Even when the statistical assumption can be reasonably justified, there are several hypothesis test statistics that can be applied to detect anomalies; choosing the right one often poses a problem.\nHistogram based techniques are relatively simple to implement, but a key shortcoming of such techniques for multivariate data is that they are not able to capture the interactions between different attributes.",
            "\u201cStatistics:\u2022The science of the collection, organization, and interpretation of data, including the design of surveys and experiments. \u2022Statistical techniques are often used to make judgments about what relationships between variables could have occurred by chance (the \u201cnull hypothesis\u201d), and what relationships between variables likely result from some kind of underlying causal relationship (i.e., that are \u201cstatistically significant\u201d).\u2022Statistical techniques are also used to reduce the",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 33\nStatisticsDescriptive or Inductive\nStatistics= teaching in dealing with quantitative information (= data)\u2022Descriptiveor InductiveDescriptive StatisticsTask: Data should be prepared and graphically displayed.\u2022Concentration of the underlying extensive database on a few meaningful measures.\u2022In extreme cases, it is possible that a single number characterizes the entire data setInductive statisticsSummary of all methods needed for rational decision making under uncertainty or risk.Task: The properties of the population are derived from the data of the sample.\u2022Basis of inductive statistics: probability theory\u2022Objective: The statistical methods of inductive statistics serve to make predictions (e.g., about risks).",
            "Different Types of AnalyticsTaking responsibilities for dedicated analytical tasks\nDescriptive AnalyticsQuestion: \u201cWhat is happening right now/ what happened in the past?\u201d Summarizingcollected data from various sources and providing aggregated measures and visualizationsIncluding traditional business intelligence tools: e.g.reports, dashboards, querying, online analytical processing (OLAP)",
            "means high chance of anomaly-Statistical tests are widely usedNon-parametric methods:-No probability distribution is assumed a-priori-Insteadthe distribution form is estimated based on the data",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 42\nStatistical methodsDisadvantages\nThe key disadvantage of statistical techniques is that they rely on the assumptionthat the data is generated from a particular distribution. This assumption often does not hold true, especially for high dimensional real data sets.\nEven when the statistical assumption can be reasonably justified, there are several hypothesis test statistics that can be applied to detect anomalies; choosing the right one often poses a problem.\nHistogram based techniques are relatively simple to implement, but a key shortcoming of such techniques for multivariate data is that they are not able to capture the interactions between different attributes.",
            "(i.e., that are \u201cstatistically significant\u201d).\u2022Statistical techniques are also used to reduce the likelihood of Type I errors (\u201cfalse positives\u201d) and Type II errors (\u201cfalse negatives\u201d).\u201d(Manyika et al., 2011)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 24\nDifferent Types of AnalyticsTaking responsibilities for dedicated analytical tasks\nDescriptive AnalyticsQuestion: \u201cWhat is happening right now/ what happened in the past?\u201d Summarizingcollected data from various sources and providing aggregated measures and visualizationsIncluding traditional business intelligence tools: e.g.reports, dashboards, querying, online analytical processing (OLAP)\nDiagnostic AnalyticsQuestion: \u201cWhy did/ does it happen?\u201dExplanatory empirical modeling based on statistical inference and causal hypotheses testing\nPredictive AnalyticsQuestion: \u201cWhat is likely to happen?\u201dDeveloping prediction models with high accuracy by using a large amount of historical data, detecting complexandnon-trivial relationshipsand providing predictions and equivalent probability scores on new unclassified observations\nPrescriptive AnalyticsQuestions: \u201cWhat should be done / why should it be done?\u201dMathematical techniques (e.g.optimization, simulation) that computationally determine a set of high-value alternative actions or decisions given a complex set of objectives, requirements and constraints",
            "Structuring the Field:3) Data Science Techniques",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 41\nStatistical methodsAdvantages\nIf the assumptionsregarding the underlying data distribution hold true, statistical techniques provide a statistically justifiable solution for anomaly detection.\nThe anomaly score provided by a statistical technique is associated with a confidence interval, which can be used as additional information while making a decisionregarding any test instance.\nIf the distribution estimation step is robustto anomalies in data, statistical techniques can operate in aunsupervised setting without any need for labeled training data.",
            "Structuring the Field:2) Data Science Concepts",
            "In particular, in the context of abuse and network intrusion detection, the interesting\nobjects are often not rare objects, but unexpected bursts of inactivity. This pattern does\nnot  adhere  to  the  common  statistical  definition  of  an  outlier  as  a  rare  object.  Many\noutlier detection methods (in particular, unsupervised algorithms) will fail on such data\nunless aggregated appropriately. Instead, a cluster analysis algorithm may be able to\ndetect the micro-clusters formed by these patterns.[74]\nThree  broad  categories  of  anomaly  detection  techniques  exist.[75]  Unsupervised\nanomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised\nanomaly detection techniques require a data set that has been labeled as \"normal\" and\n\"abnormal\"  and  involves  training  a  classifier  (the  key  difference  from  many  other\nstatistical  classification  problems  is  the  inherently  unbalanced  nature  of  outlier\ndetection).  Semi-supervised  anomaly  detection  techniques  construct  a  model\nrepresenting normal behavior from a given normal training data set and then test the\nlikelihood of a test instance to be generated by the model.\nRobot learning is inspired by a multitude of machine learning methods, starting from\nsupervised  learning,  reinforcement  learning,[76][77]  and  finally  meta-learning  (e.g.\nMAML).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 17\nClassification basedOne-class classification\nFrom Wikipedia, the free encyclopediaIn machine learning, one-class classification, also known as unary classification, tries to identifyobjects of a specific class amongst all objects, by learning from a training set containing only the objects of that class. This is different from and more difficult than the traditional classification problem, which tries to distinguish betweentwo or more classes with the training set containing objects from all the classes. An example is the classification of the operational status of a nuclear plant as 'normal':In this scenario, there are (fortunately) few or no examples of catastrophic system states, only the statistics of normal operation are known. The term one-class classification was coined by Moya & Hush (1996) and many applications can be found in scientific literature, for example outlier detection, anomaly detection, novelty detection. Aimportant component of one-class classification is that it uses only samples from the assigned class, so that a representative sampling is not strictly required for non-target classes.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "RFR compatible to be used in various application. [89][90]\nSupport-vector machines (SVMs), also known as support-vector networks, are a set of\nrelated supervised learning methods used for classification and regression. Given a set\nof  training  examples,  each  marked  as  belonging  to  one  of  two  categories,  an  SVM\ntraining algorithm builds a model that predicts whether a new example falls into one\ncategory.[91] An SVM training algorithm is a non-probabilistic, binary, linear classifier,\nalthough methods such as Platt scaling exist to use SVM in a probabilistic classification\nsetting.  In  addition  to  performing  linear  classification,  SVMs  can  efficiently  perform  a\nnon-linear  classification  using  what  is  called  the  kernel  trick,  implicitly  mapping  their\ninputs into high-dimensional feature spaces.\nRegression analysis encompasses a large variety of statistical methods to estimate the\nrelationship  between  input  variables  and  their  associated  features.  Its  most  common\nform  is  linear  regression,  where  a  single  line  is  drawn  to  best  fit  the  given  data\naccording to a mathematical criterion such as ordinary least squares. The latter is often\nextended  by  regularization  methods  to  mitigate  overfitting  and  bias,  as  in  ridge\nregression.  When  dealing  with  non-linear  problems,  go-to  models  include  polynomial\nregression  (for  example,  used  for  trendline  fitting  in  Microsoft  Excel[92]),  logistic\nregression  (often  used  in  statistical  classification)  or  even  kernel  regression,  which\nintroduces non-linearity by taking advantage of the kernel trick to implicitly map input\nvariables to higher-dimensional space.\nMultivariate  linear  regression  extends  the  concept  of  linear  regression  to  handle",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "modeling,  representation  of  objects  as  interconnections  of  smaller  structures,  optical\nflow, and motion estimation.[11]\nThe  next  decade  saw  studies  based  on  more  rigorous  mathematical  analysis  and\nquantitative aspects of computer vision. These include the concept of scale-space, the\ninference of shape from various cues such as shading, texture and focus, and contour\nmodels known as snakes. Researchers also realized that many of these mathematical\nconcepts  could  be  treated  within  the  same  optimization  framework  as  regularization\nand Markov random fields.[15]\nBy the 1990s, some of the previous research topics became more active than others.\nResearch  in  projective  3-D  reconstructions  led  to  better  understanding  of  camera\ncalibration.  With  the  advent  of  optimization  methods  for  camera  calibration,  it  was\nrealized that a lot of the ideas were already explored in bundle adjustment theory from\nthe  field  of  photogrammetry.  This  led  to  methods  for  sparse  3-D  reconstructions  of\nscenes from multiple images. Progress was made on the dense stereo correspondence\nproblem and further multi-view stereo techniques. At the same time, variations of graph\ncut  were  used  to  solve  image  segmentation.  This  decade  also  marked  the  first  time\nstatistical learning techniques were used in practice to recognize faces in images (see\nEigenface).  Toward  the  end  of  the  1990s,  a  significant  change  came  about  with  the\nincreased  interaction  between  the  fields  of  computer  graphics  and  computer  vision.\nThis  included  image-based  rendering,  image  morphing,  view  interpolation,  panoramic\nimage stitching and early light-field rendering.[11]\nRecent  work  has  seen  the  resurgence  of  feature-based  methods  used  in  conjunction\nwith machine learning techniques and complex optimization frameworks.[16][17]",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 43\nTokens in a Normative Process Model\nHow many misplaced tokens in (a, b, i, j, k, l)?\nthe number of tokens that are correctly produced pthe number of tokens that are correctly consumed cthe number of tokens that are missing for executing mthe next activity in the log, andthe number of tokens remaining unconsumed rafter executing the final activity in the log\nproduced pconsumed cmissing mremaining r\nDumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 31\nNeighbor basedRelative density: LOF Variations\nVariations:ODIN:simpler version of LOFMDEF:variation of LOF \u2013based on the standard deviation of the local densitiesCOF:variation with an incremental calculation of the k-neighborhoodOther variations to improve computation time and support for other data types (e.g.sequence data)LOF vs. COF neighborhood",
            "Deep  learning  consists  of  multiple  hidden  layers  in  an  artificial  neural  network.  This\napproach tries to model the way the human brain processes light and sound into vision\nand  hearing.  Some  successful  applications  of  deep  learning  are  computer  vision  and\nspeech recognition.[88]\nDecision  tree  learning  uses  a  decision  tree  as  a  predictive  model  to  go  from\nobservations  about  an  item  (represented  in  the  branches)  to  conclusions  about  the\nitem's  target  value  (represented  in  the  leaves).  It  is  one  of  the  predictive  modeling\napproaches used in statistics, data mining, and machine learning. Tree models where\nthe target variable can take a discrete set of values are called classification trees; in\nthese  tree  structures,  leaves  represent  class  labels,  and  branches  represent\nconjunctions of features that lead to those class labels. Decision trees where the target\nvariable can take continuous values (typically real numbers) are called regression trees.\nIn  decision  analysis,  a  decision  tree  can  be  used  to  visually  and  explicitly  represent\ndecisions and decision making. In data mining, a decision tree describes data, but the\nresulting classification tree can be an input for decision-making.\nRandom  forest  regression  (RFR)  falls  under  umbrella  of  decision  tree-based  models.\n\u00a0RFR is an ensemble learning method that builds multiple decision trees and averages\ntheir predictions to improve accuracy and to avoid overfitting. \u00a0To build decision trees,\nRFR uses bootstrapped sampling, for instance each decision tree is trained on random\ndata of from training set. This random selection of RFR for training enables model to\nreduce  bias  predictions  and  achieve  accuracy.  RFR  generates  independent  decision\ntrees, and it can work on single output data as well multiple regressor task. This makes",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 3\nArtificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in the input layer, you have as many nodes as input varibales + a constant (=bias)\u00a7Hidden units: Nodes in the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing the various outputs-Connection:\u00a7Each node is connected to the succeeding node (one direction only)\u00a7Each connection has a weight that need to be learned from the data\nIdothecalculations)",
            "The robot later practiced the task with the help of some coaching from the trainer, who\nprovided feedback such as \"good job\" and \"bad job\".[273]\nDeep learning has attracted both criticism and comment, in some cases from outside\nthe field of computer science.\nA main criticism concerns the lack of theory surrounding some methods.[274] Learning\nin the most common deep architectures is implemented using well-understood gradient\ndescent.  However,  the  theory  surrounding  other  algorithms,  such  as  contrastive\ndivergence is less clear.[citation needed] (e.g., Does it converge? If so, how fast? What\nis it approximating?) Deep learning methods are often looked at as a black box, with\nmost confirmations done empirically, rather than theoretically.[275]\nIn further reference to the idea that artistic sensitivity might be inherent in relatively\nlow levels of the cognitive hierarchy, a published series of graphic representations of\nthe internal states of deep (20-30 layers) neural networks attempting to discern within\nessentially  random  data  the  images  on  which  they  were  trained[276]  demonstrate  a\nvisual appeal: the original research notice received well over 1,000 comments, and was\nthe  subject  of  what  was  for  a  time  the  most  frequently  accessed  article  on  The\nGuardian's[277] website.\nSome  deep  learning  architectures  display  problematic  behaviors,[278]  such  as\nconfidently  classifying  unrecognizable  images  as  belonging  to  a  familiar  category  of",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail."
        ],
        "generated": "Based on the provided context, the types of statistics mentioned include parametric methods, non-parametric methods, regression-based methods, mixture distribution-based methods, and statistical learning techniques. These statistics are used in anomaly detection to detect anomalies in data sets.",
        "ground_truth": "Descriptive statistics, Inductive statistics"
    },
    {
        "query": "What is Agglomerative Clustering?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 10\nHierarchicalClustering Methods\nSegmentation methods that construct a sequence of partitions on the basis ofa set of objects N.\nAgglomerative ClusteringEach object initially represents a cluster of its own. Then clusters are successively merged until the desired cluster structure is obtained.\nDiversiveClusteringAll objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained.\n\u2022Starting point is the class of all objects.\u2022Successive transition to finer decompositions\u2022Termination as soon as given criterion is fulfilled\n\u2022Starting point are n = |N| one-element classes. \u2022Successive transition to coarser decompositions\u2022Termination as soon as given criterion is fulfilled\u2022Low computation times, good practical suitability> Kaufman, L. and Rousseeuw, P.J. (1990) PartitioningaroundMedoids(ProgramPAM). In: Kaufman, L. and Rousseeuw, P.J., Eds., FindingGroups in Data: An IntroductiontoCluster Analysis, John Wiley & Sons, Inc., Hoboken, 68-125.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 10\nHierarchicalClustering Methods\nSegmentation methods that construct a sequence of partitions on the basis ofa set of objects N.\nAgglomerative ClusteringEach object initially represents a cluster of its own. Then clusters are successively merged until the desired cluster structure is obtained.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 6\nSubdivision ofclusterapproachesAgglomerativeand single-modal methods\nFurthermore, one still distinguishes: \u2015Agglomerativeand divisive methods. The former start from one-element classes and combine elements into classes step by step. Divisive methods,on the other hand, start from an initial decomposition which is refined (i.e., divided) step by step. \u2015Single-modal methods that group objects or features into classes, and dual-modalmethods that simultaneously classify objects and features of a data matrix.",
            "Furthermore, one still distinguishes: \u2015Agglomerativeand divisive methods. The former start from one-element classes and combine elements into classes step by step. Divisive methods,on the other hand, start from an initial decomposition which is refined (i.e., divided) step by step. \u2015Single-modal methods that group objects or features into classes, and dual-modalmethods that simultaneously classify objects and features of a data matrix.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 3\nClustering Methods\nPartitionalClustering K-Means& K-MedoidsFor n objects or data tuples, a partitioning method constructs k partitions of the data, where each partition represents a cluster k <= n.\nHierarchicalClustering Agglomerative, DivisiveGroupingdata objects into a tree (dendrogram) of clusters\nDensity-BasedClustering DBSCANGroupingdatatuplesalongdensity-connectedpoints.\nGrid-BasedClustering STING, WaveCluster& CLIQUEMethoduses a multi-resolution grid data structure. E.g.spatial area is divided into rectangular cells (STING)\nOthersModel-BasedClustering, Fuzzy, Evolutionary, SimulatedAnnealing",
            "HierarchicalClustering Methods\nforSegmentation",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 6\nSubdivision ofclusterapproachesAgglomerativeand single-modal methods",
            "Several clustering algorithms force every instance to be assigned to some cluster.Several clustering based techniques are effective only when the anomalies do not form significant clusters among themselves.\nThe computational complexity for clustering the data is often a bottleneck.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 34\nClustering basedOverview\nIdea 1: Normal data instances belong to a cluster in the data, while anomalies do not belong to any cluster:Requires cluster method that does not put every data point into clustersE.g.: DBSCAN, ROCK, WaveCluster, FindOutIdea 2: Normal data instances lie close to their closest cluster centroid, while anomalies are far away from their closest cluster centroid:Commonused methods are SOM, K-means, Expectation MaximizationSemi-supervised approach can be used to improve resultsIdea 1 and 2 arenot working well when anomalies form clusters themselvesIdea 3: Normal data instances belong to large and dense clusters, while anomalies either belong to small or sparse clustersCommonly used: FindCBLOFCBLOF analogous to LOF captures cluster size as well as centroid distance based on clustering results",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 35\nClustering basedAdvantages\nClustering based techniques can operate in an unsupervised mode.Such techniques can often be adapted to other complex data types by simply plugging in a clustering algorithm that can handle the particular datatype.The testing phase for clustering basedtechniques is fast since the number of clusters against which every test instance needs to be compared is a small constant.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 15\nMethodsOverview\nClassification basedNeighbor based\nClustering basedStatistical methods\nInformation Theory basedSpectral Theory based\nAnomaly Detection Methods*\n*For Information Theory based and Spectral Theory based see [Chandolaet al., 2009]",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "comes from the basic assumptions they work with: in machine learning, performance is\nusually evaluated with respect to the ability to reproduce known knowledge, while in\nknowledge discovery and data mining (KDD) the key task is the discovery of previously\nunknown  knowledge.  Evaluated  with  respect  to  known  knowledge,  an  uninformed\n(unsupervised) method will easily be outperformed by other supervised methods, while\nin a typical KDD task, supervised methods cannot be used due to the unavailability of\ntraining data.\nMachine  learning  also  has  intimate  ties  to  optimization:  Many  learning  problems  are\nformulated as minimization of some loss function on a training set of examples. Loss\nfunctions express the discrepancy between the predictions of the model being trained\nand the actual problem instances (for example, in classification, one wants to assign a\nlabel to instances, and models are trained to correctly predict the preassigned labels of\na set of examples).[35]\nCharacterizing  the  generalization  of  various  learning  algorithms  is  an  active  topic  of\ncurrent research, especially for deep learning algorithms.\nMachine  learning  and  statistics  are  closely  related  fields  in  terms  of  methods,  but\ndistinct  in  their  principal  goal:  statistics  draws  population  inferences  from  a  sample,\nwhile  machine  learning  finds  generalizable  predictive  patterns.[36]  According  to\nMichael  I.  Jordan,  the  ideas  of  machine  learning,  from  methodological  principles  to\ntheoretical  tools,  have  had  a  long  pre-history  in  statistics.[37]  He  also  suggested  the\nterm data science as a placeholder to call the overall field.[37]",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 49\nRis an open sourceprogramming language with focus on better user friendlydata analysis, statistics and graphical modelsR is an implementation of S programming languageCreated by Ross Ihaka and Robert Gentleman Released in 1995R has been used primarily in academicsand research,but it is rapidly expanding into the enterprise market\u201cThe closer you are to statistics, research and data science,the more you might prefer R.\u201dStandard IDE is R StudioMain advantage: graphical capabilities for data visualization\n(Source: https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis)",
            "meaning  that  even  the  coders  of  the  algorithm  cannot  audit  the  pattern  that  the\nmachine extracted out of the data.[123] The House of Lords Select Committee, which\nclaimed that such an \"intelligence system\" that could have a \"substantial impact on an\nindividual's  life\"  would  not  be  considered  acceptable  unless  it  provided  \"a  full  and\nsatisfactory explanation for the decisions\" it makes.[123]\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a\ncollision.[124]  Attempts  to  use  machine  learning  in  healthcare  with  the  IBM  Watson\nsystem  failed  to  deliver  even  after  years  of  time  and  billions  of  dollars\ninvested.[125][126] Microsoft's Bing Chat chatbot has been reported to produce hostile\nand offensive response against its users.[127]\nMachine  learning  has  been  used  as  a  strategy  to  update  the  evidence  related  to  a\nsystematic review and increased reviewer burden related to the growth of biomedical\nliterature. While it has improved with training sets, it has not yet developed sufficiently\nto reduce the workload burden without limiting the necessary sensitivity for the findings\nresearch themselves.[128]\nExplainable  AI  (XAI),  or  Interpretable  AI,  or  Explainable  Machine  Learning  (XML),  is\nartificial intelligence (AI) in which humans can understand the decisions or predictions\nmade  by  the  AI.[129]  It  contrasts  with  the  \"black  box\"  concept  in  machine  learning\nwhere even its designers cannot explain why an AI arrived at a specific decision.[130]\nBy  refining  the  mental  models  of  users  of  AI-powered  systems  and  dismantling  their\nmisconceptions,  XAI  promises  to  help  users  perform  more  effectively.  XAI  may  be  an",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail."
        ],
        "generated": "Agglomerative Clustering is a segmentation method that starts with each object representing its own cluster and then merges clusters successively until the desired cluster structure is obtained.",
        "ground_truth": "Each object initially represents a cluster of its own. Then clusters are successively merged until the desired cluster structure is obtained."
    },
    {
        "query": "What are the four quality criteria?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "Basics ofsegmentation\nEvaluation criteria",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 25\nThe problemofqualityindices\n\u2015In general, the quality index falls as the number of classes increases. \u2015A conflict of objectives arises between\u2022as small a number of classes as possible and\u2022quality index as small as possible.Decision support: elbow criterionWith the help of this so-called criterion, the \"optimal\" choice of the number of classes can be made. The decision is made in favor of the number of classes s* with the quality b*, which is the same with \u2022a reduction in the number of classes sleads to a sharp increase in b \u2022an increase in the number of classes sleads only to a slight improvement in b.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 20\nEvaluation criteria\nIf one has two different segmentations K1und K2, the question arises,which is more suitable.Criteria for the evaluation of segmentations\nA distinction is made between measures for evaluating the\u2015Heterogeneity of a class (intra-class dissimilarity) -heterogeneity indices\u2015Difference of two classes (interclass difference) -dissimilarity indices\u2015Quality of a segmentation (quality index) -quality indices",
            "In this step, it is checked whether the initial question could be answered by the text mining process. Here are assessthe results from the upstream step of applying the analytical methods using quality criteria appropriate to the method, andMatch the results from the upstream step of applying the analysis procedures with the problem definitionIf the check is positive, the next process step is executed.If the test is negative, it must first be analyzed where improvements are needed (preparation,",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 103\nOutcome evaluation \nIn this step, it is checked whether the initial question could be answered by the text mining process. Here are assessthe results from the upstream step of applying the analytical methods using quality criteria appropriate to the method, andMatch the results from the upstream step of applying the analysis procedures with the problem definitionIf the check is positive, the next process step is executed.If the test is negative, it must first be analyzed where improvements are needed (preparation, data analysis,...)and then the process must jump back to this point to be executed again with changed parameters or other procedures",
            "Structuring the Field:4) Data Science Technologies",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 39\nStatistical methodsParametric methods: other methods\nRegression based:(1) Regression is estimated(2) for each data object the residual score resembles the anomaly scoreSome criteria used to detect anomalies in a regressions setting:\u2014AIC: anomalies influence regression results\u2014Robust regression: should be used to avoid anomaly influences \u00f0residuals for anomalies are considerably larger in this setting\u2014ARIMA/ARMA: detection of anomalies in a time series settingMixture distribution based: Two approaches -Different distributions for normal data and anomalies or mixed distribution for only the normal class",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 18\nProblematicpropertiesoftheLpdistance\n\u2015If two features k1 and k2 are highly correlated, then both features provide approximately the same information regarding the similarity of the objects. The same information is considered \"multiple\".\u2015Characteristics with large dispersion (i.e. variance) have a higher weight in aggregation\n\u2015The general remedy here is the Mahalanobis distance\nclushhas centroida distanceto -\nandroiddescribeif theyare similiarto\nthewholeduster",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 29\nAssociationAnalysis Remarks& applicationrecommendations\u2013Teil I\nProvided that frequent item sets with n elements exist, the A priori algorithm requires n iterations ( 1 MB shopping cart analyzable in seconds).Algorithm discovers thousands of rules.Visualizationor browsingis necessary:-Rules with very high support or confidence values are mostly already known.-The so called \"medium\" rulesare mainly interesting.\u00e0Thus, additional statistical key figures are necessary for the evaluation.Many external influencing factorsremain unconsidered, since transaction data do not include the following:-socio-economic status of buyers-time (time of day, day of week)-Advertising campaigns",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "issues with the viability of the technology for general usage. For example, an algorithm\ncalibrated  for  one  camera  may  not  work  for  a  different  camera.   The  amount  of\nbackground  noise  also  causes  tracking  and  recognition  difficulties,  especially  when\nocclusions (partial and full) occur.  Furthermore, the distance from the camera, and the\ncamera's resolution and quality, also cause variations in recognition accuracy.\nIn order to capture human gestures by visual sensors robust computer vision methods\nare  also  required,  for  example  for  hand  tracking  and  hand  posture\nrecognition[32][33][34][35][36][37][38][39][40]  or  for  capturing  movements  of  the\nhead, facial expressions or gaze direction.\nOne  significant  challenge  to  the  adoption  of  gesture  interfaces  on  consumer  mobile\ndevices  such  as  smartphones  and  smartwatches  stems  from  the  social  acceptability\nimplications of gestural input. While gestures can facilitate fast and accurate input on\nmany novel form-factor computers, their adoption and usefulness are often limited by\nsocial  factors  rather  than  technical  ones.  To  this  end,  designers  of  gesture  input\nmethods  may  seek  to  balance  both  technical  considerations  and  user  willingness  to\nperform gestures in different social contexts.[41] In addition, different device hardware\nand sensing mechanisms support different kinds of recognizable gestures.\nGesture interfaces on mobile and small form-factor devices are often supported by the\npresence  of  motion  sensors  such  as  inertial  measurement  units  (IMUs).  On  these\ndevices, gesture sensing relies on users performing movement-based gestures capable\nof  being  recognized  by  these  motion  sensors.  This  can  potentially  make  capturing",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 41\nStatistical methodsAdvantages\nIf the assumptionsregarding the underlying data distribution hold true, statistical techniques provide a statistically justifiable solution for anomaly detection.\nThe anomaly score provided by a statistical technique is associated with a confidence interval, which can be used as additional information while making a decisionregarding any test instance.\nIf the distribution estimation step is robustto anomalies in data, statistical techniques can operate in aunsupervised setting without any need for labeled training data.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 21\nAssociationAnalysisComments on thesubjectoftransactions\nThe following applies to transactions in general:Transactions consist of item quantity and transaction time. Often, information on behavior over time is available in addition to the transactions.  -Market Basket analysis: Payment by credit card or customer card; -Delivery Providers: collection of customer information e.g. based on orders received.However, this information is not usedin classical association analysis, although the inclusion of this additional information can significantly increase the meaningfulness of the rules (\u00e0sequence analysis).",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 5\nPartionalClustering Methods\nPartitioning methods are segmentation methods which divide the set of objects N on the basis of a fixed number of classes s in such a way that the computed segmentation or partition Kminimizes a given quality index b(K):\n{ }\ns\n1s i i j(( N ) ) i1\nmin b( ) : K , ,K ,    K N,    K K\u00ce\u00c3 \u00c3 =\n\u00ec\u00fc == \u00c7 = \u00c6\u00ed\u00fd\u00ee\u00fe\nK UK",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 24\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n2.1 Introduction to Segmentation\n2.2 Cluster types\n2.3 Distance measures\n2.4 Evaluation criteria \n2.5 Start heuristics",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 7\nSubdivision ofclusterapproachesHierarchicaland sharp methods\n\u2015Hierarchicalsegmentation methods are characterized by the fact that a cluster located at a higher fusion level completely contains the corresponding clusters located at a lower level. \u2015Non-hierarchical methods arebased on optimization methods that estimate class membership or attempt to iteratively improve classification quality by swapping elements between classes. \u2015Furthermore, a distinction is made between sharpand fuzzy segmentations. In the sharp approach, each object -if assigned to at least one class -is uniquely assigned to the corresponding class. In the fuzzy approach, there is no clear assignment to a class. Instead, share values are assigned that determine the degree to which an object belongs to a class.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 70\nDocument preparationCustomize data structure\nMany text mining techniques have their origins in data mining, and often classical data mining techniques can also be applied to text data, provided that the data is available in a suitable structure.In the literature, the vector space model according to Salton et al. (1975) is mostly used for this purpose, whereby the text data areavailable in a structured tabular form:Terms and documents are transformed into a matrixThe lines list the termsIn the columns the documents are listedThe intersections show whether a term occurs in a document or not\nTerme \nindexieren und \ngewichten\nDatenstruktur \nanpassen\nVorbereitende \nAnalysen \ndurchf\u00fchren\nTerme \nreduzieren\nD1D2D3T11 0 1T20 0 1T31 1 0",
            "One  of  the  most  prominent  application  fields  is  medical  computer  vision,  or  medical\nimage  processing,  characterized  by  the  extraction  of  information  from  image  data  to\ndiagnose a patient. An example of this is the detection of tumours, arteriosclerosis or\nother  malign  changes,  and  a  variety  of  dental  pathologies;  measurements  of  organ\ndimensions, blood flow, etc. are another example. It also supports medical research by\nproviding  new  information:  e.g.,  about  the  structure  of  the  brain  or  the  quality  of\nmedical  treatments.  Applications  of  computer  vision  in  the  medical  area  also  include\nenhancement of images interpreted by humans\u2014ultrasonic images or X-ray images, for\nexample\u2014to reduce the influence of noise.\nA second application area in computer vision is in industry, sometimes called machine\nvision,  where  information  is  extracted  for  the  purpose  of  supporting  a  production\nprocess.  One  example  is  quality  control  where  details  or  final  products  are  being\nautomatically  inspected  in  order  to  find  defects.  One  of  the  most  prevalent  fields  for\nsuch  inspection  is  the  Wafer  industry  in  which  every  single  Wafer  is  being  measured\nand inspected for inaccuracies or defects to prevent a computer chip from coming to\nmarket in an unusable manner. Another example is a measurement of the position and\norientation  of  details  to  be  picked  up  by  a  robot  arm.  Machine  vision  is  also  heavily\nused in the agricultural processes to remove undesirable foodstuff from bulk material, a\nprocess called optical sorting.[32]\nMilitary applications are probably one of the largest areas of computer vision[citation\nneeded].  The  obvious  examples  are  the  detection  of  enemy  soldiers  or  vehicles  and\nmissile guidance. More advanced systems for missile guidance send the missile to an\narea  rather  than  a  specific  target,  and  target  selection  is  made  when  the  missile",
            "represented  in  a  3D  coordinate  system.  Based  on  the  relative  motion  of  these,  the\ngesture can be detected with high accuracy, depending on the quality of the input and\nthe algorithm's approach.[30]\nIn  order  to  interpret  movements  of  the  body,  one  has  to  classify  them  according  to\ncommon  properties  and  the  message  the  movements  may  express.  For  example,  in\nsign language, each gesture represents a word or phrase.\nSome  literature  differentiates  2  different  approaches  in  gesture  recognition:  a  3D\nmodel-based  and  an  appearance-based.[31]  The  foremost  method  makes  use  of  3D\ninformation  on  key  elements  of  the  body  parts  in  order  to  obtain  several  important\nparameters, like palm position or joint angles. Approaches derived from it such as the\nvolumetric models have proven to be very intensive in terms of computational power\nand  require  further  technological  developments  in  order  to  be  implemented  for\nreal-time  analysis.  Alternately,  appearance-based  systems  use  images  or  videos  for\ndirect interpretation. Such models are easier to process, but usually lack the generality\nrequired for human-computer interaction.\nThe 3D model approach can use volumetric or skeletal models or even a combination of\nthe  two.  Volumetric  approaches  have  been  heavily  used  in  the  computer  animation\nindustry  and  for  computer  vision  purposes.  The  models  are  generally  created  from\ncomplicated 3D surfaces, like NURBS or polygon meshes.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "predesignated criteria, while observations drawn from different clusters are dissimilar.\nDifferent clustering techniques make different assumptions on the structure of the data,\noften  defined  by  some  similarity  metric  and  evaluated,  for  example,  by  internal\ncompactness, or the similarity between members of the same cluster, and separation,\nthe  difference  between  clusters.  Other  methods  are  based  on  estimated  density  and\ngraph connectivity.\nA special type of unsupervised learning called, self-supervised learning involves training\na model by generating the supervisory signal from the data itself.[53][54]\nSemi-supervised  learning  falls  between  unsupervised  learning  (without  any  labeled\ntraining data) and supervised learning (with completely labeled training data). Some of\nthe  training  examples  are  missing  training  labels,  yet  many  machine-learning\nresearchers  have  found  that  unlabeled  data,  when  used  in  conjunction  with  a  small\namount of labeled data, can produce a considerable improvement in learning accuracy.\nIn  weakly  supervised  learning,  the  training  labels  are  noisy,  limited,  or  imprecise;\nhowever, these labels are often cheaper to obtain, resulting in larger effective training\nsets.[55]\nReinforcement  learning  is  an  area  of  machine  learning  concerned  with  how  software\nagents  ought  to  take  actions  in  an  environment  so  as  to  maximize  some  notion  of\ncumulative reward. Due to its generality, the field is studied in many other disciplines,",
            "computed  by  looking  like  the  observed  points  and  the  covariances  between  those\npoints and the new, unobserved point.\nGaussian processes are popular surrogate models in Bayesian optimization used to do\nhyperparameter optimization.\nA genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the\nprocess of natural selection, using methods such as mutation and crossover to generate\nnew  genotypes  in  the  hope  of  finding  good  solutions  to  a  given  problem.  In  machine\nlearning,  genetic  algorithms  were  used  in  the  1980s  and  1990s.[95][96]  Conversely,\nmachine  learning  techniques  have  been  used  to  improve  the  performance  of  genetic\nand evolutionary algorithms.[97]\nThe theory of belief functions, also referred to as evidence theory or Dempster\u2013Shafer\ntheory,  is  a  general  framework  for  reasoning  with  uncertainty,  with  understood\nconnections  to  other  frameworks  such  as  probability,  possibility  and   imprecise\nprobability  theories.  These  theoretical  frameworks  can  be  thought  of  as  a  kind  of\nlearner  and  have  some  analogous  properties  of  how  evidence  is  combined  (e.g.,  \nDempster's  rule  of  combination),  just  like  how  in  a  pmf-based  Bayesian\napproach[clarification needed] would combine probabilities. However, there are many\ncaveats to these beliefs functions when compared to Bayesian approaches in order to\nincorporate ignorance and uncertainty quantification. These belief function approaches\nthat are implemented within the machine learning domain typically leverage a fusion\napproach  of  various  ensemble  methods  to  better  handle  the  learner's  decision",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 58\n2. Data preparation \u2013 normalization\nLSTMs are sensitive to the scale of the data\u00e0 Scale input data to values between 0 and 1Remeber to reverse this normalization when you want to display predictions\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))normalized_closing_values = scaler.fit_transform(closing_values)[...]predictions = scaler.inverse_transform(normalized_predictions)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 38\nLSTM-Concepts: Gates\nLSTM heavily uses gates in its architecureA gate is used to modify values in a vector to only let specific values or adapted values through.Sigmoid Gate: When using the Sigmoid activation function, the result is a vector of numbers between 0 and 1. When multiplying this vector pointwise with another vector, we can remove or deminish values in the other vector. 543\t\u00d700.251=013\t\nThese gates are used to \u201efilter\u201c values in vectors.LSTMs use 3 different gate layers to modify the internal state (following slides)\nSigmoid outputModified VectorInput"
        ],
        "generated": "The four quality criteria mentioned in the context are:\n1. Fitness - ability to replay\n2. Simplicity (Occam's razor) - simplest model to explain behavior is the best model\n3. Precision - degree of behavior allowed by the model, but not in the logs (do not underfit)\n4. Generalization - work with incomplete behavior, do not overfit",
        "ground_truth": "Fitness, Simplicity, Precision, Generalization."
    },
    {
        "query": "What is the definition of Deep Learning by Najafabadi et al. (2016)?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 29\nMachine Learning & Deep LearningDeep Learning as a new disruptive technology\nA special class of Machine Learning algorithms is Deep Learning.\u201cThe main concept in deep leaning algorithms is automating the extraction of representations(abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representation.\u201d(Najafabadi et al., 2016)\u201cThese algorithms are largely motivated by the field of artificial intelligence, which has the general goal of emulating the human brain\u2019s abilityto observe, analyze, learn, and make decisions, especially for extremely complex problems.\u201d (Najafabadi et al., 2016)\nhttps://blogs.nvidia.com",
            "A special class of Machine Learning algorithms is Deep Learning.\u201cThe main concept in deep leaning algorithms is automating the extraction of representations(abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representation.\u201d(Najafabadi et al., 2016)\u201cThese algorithms are largely motivated by the field of artificial intelligence, which has the general goal of emulating the human brain\u2019s abilityto observe, analyze, learn,",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 30\nDeep LearningDeep neural network architectures\n\u201cDeep learning is a relatively new term, although it has existed prior to the recent dramatic uptick in online searches. Enjoying a surge in research and industry, due mainly to its incredible successes in a number ofdifferent areas, deep learning is the process of applying deep neural network technologies -that is, neural network architectures with multiple hidden layers of neurons-to solve problems.\u201d(KDnuggets, 2016)\n(Source: Chen & Lin, 2014)\n(Source: Chen & Lin, 2014)",
            "Deep Learning\nDeep learning is a subset of machine learning that focuses on utilizing neural networks\nto  perform  tasks  such  as  classification,  regression,  and  representation  learning.  The\nfield  takes  inspiration  from  biological  neuroscience  and  is  centered  around  stacking\nartificial neurons into layers and \"training\" them to process data. The adjective \"deep\"\nrefers  to  the  use  of  multiple  layers  (ranging  from  three  to  several  hundred  or\nthousands) in the network. Methods used can be either supervised, semi-supervised or\nunsupervised.[2]\nSome common deep learning network architectures include fully connected networks,\ndeep  belief  networks,  recurrent  neural  networks,  convolutional  neural  networks,\ngenerative  adversarial  networks,  transformers,  and  neural  radiance  fields.  These\narchitectures have been applied to fields including computer vision, speech recognition,\nnatural language processing, machine translation, bioinformatics, drug design, medical\nimage analysis, climate science, material inspection and board game programs, where\nthey have produced results comparable to and in some cases surpassing human expert\nperformance.[3][4][5]\nEarly forms of neural networks were inspired by information processing and distributed\ncommunication  nodes  in  biological  systems,  particularly  the  human  brain.  However,\ncurrent neural networks do not intend to model the brain function of organisms, and are\ngenerally seen as low-quality models for that purpose.[6]",
            "Deep Learning\nConvolutional Neural Networks",
            "belief networks.[8][12]\nThe  term  Deep  Learning  was  introduced  to  the  machine  learning  community  by  Rina\nDechter in 1986,[13] and to artificial neural networks by Igor Aizenberg and colleagues",
            "which has the general goal of emulating the human brain\u2019s abilityto observe, analyze, learn, and make decisions, especially for extremely complex problems.\u201d (Najafabadi et al., 2016)",
            "Most modern deep learning models are based on multi-layered neural networks such as\nconvolutional  neural  networks  and  transformers,  although  they  can  also  include\npropositional  formulas  or  latent  variables  organized  layer-wise  in  deep  generative\nmodels such as the nodes in deep belief networks and deep Boltzmann machines.[7]\nFundamentally, deep learning refers to a class of machine learning algorithms in which\na hierarchy of layers is used to transform input data into a progressively more abstract\nand  composite  representation.  For  example,  in  an  image  recognition  model,  the  raw\ninput may be an image (represented as a tensor of pixels). The first representational\nlayer may attempt to identify basic shapes such as lines and circles, the second layer\nmay compose and encode arrangements of edges, the third layer may encode a nose\nand eyes, and the fourth layer may recognize that the image contains a face.\nImportantly,  a  deep  learning  process  can  learn  which  features  to  optimally  place  at\nwhich  level  on  its  own.  Prior  to  deep  learning,  machine  learning  techniques  often\ninvolved  hand-crafted  feature  engineering  to  transform  the  data  into  a  more  suitable\nrepresentation  for  a  classification  algorithm  to  operate  on.  In  the  deep  learning\napproach,  features  are  not  hand-crafted  and  the  model  discovers  useful  feature\nrepresentations  from  the  data  automatically.  This  does  not  eliminate  the  need  for\nhand-tuning;  for  example,  varying  numbers  of  layers  and  layer  sizes  can  provide\ndifferent degrees of abstraction.[8][2]\nThe word \"deep\" in \"deep learning\" refers to the number of layers through which the\ndata  is  transformed.  More  precisely,  deep  learning  systems  have  a  substantial  credit",
            "deep  learning  algorithms.  Deep  learning  processors  include  neural  processing  units\n(NPUs)  in  Huawei  cellphones[172]  and  cloud  computing  servers  such  as  tensor\nprocessing units (TPU) in the Google Cloud Platform.[173] Cerebras Systems has also\nbuilt a dedicated system to handle large deep learning models, the CS-2, based on the\nlargest  processor  in  the  industry,  the  second-generation  Wafer  Scale  Engine\n(WSE-2).[174][175]\nAtomically  thin  semiconductors  are  considered  promising  for  energy-efficient  deep\nlearning  hardware  where  the  same  basic  device  structure  is  used  for  both  logic\noperations and data storage.\nIn 2020, Marega et al. published experiments with a large-area active channel material\nfor developing logic-in-memory devices and circuits based on floating-gate field-effect\ntransistors (FGFETs).[176]\nIn 2021, J. Feldmann et al. proposed an integrated photonic hardware accelerator for\nparallel  convolutional  processing.[177]  The  authors  identify  two  key  advantages  of\nintegrated  photonics  over  its  electronic  counterparts:  (1)  massively  parallel  data\ntransfer through wavelength division multiplexing in conjunction with frequency combs,\nand (2) extremely high data modulation speeds.[177] Their system can execute trillions\nof  multiply-accumulate  operations  per  second,  indicating  the  potential  of  integrated\nphotonics in data-heavy AI applications.[177]\nLarge-scale  automatic  speech  recognition  is  the  first  and  most  convincing  successful\ncase of deep learning. LSTM RNNs can learn \"Very Deep Learning\" tasks[9] that involve",
            "A variety of approaches have been used to investigate the plausibility of deep learning\nmodels  from  a  neurobiological  perspective.  On  the  one  hand,  several  variants  of  the\nbackpropagation  algorithm  have  been  proposed  in  order  to  increase  its  processing\nrealism.[257][258]  Other  researchers  have  argued  that  unsupervised  forms  of  deep\nlearning,  such  as  those  based  on  hierarchical  generative  models  and  deep  belief",
            "in the most common deep architectures is implemented using well-understood gradient\ndescent.  However,  the  theory  surrounding  other  algorithms,  such  as  contrastive\ndivergence is less clear.[citation needed] (e.g., Does it converge? If so, how fast? What\nis it approximating?) Deep learning methods are often looked at as a black box, with\nmost confirmations done empirically, rather than theoretically.[275]",
            "Deep learning architectures for convolutional neural networks (CNNs) with convolutional\nlayers and downsampling layers began with the Neocognitron introduced by Kunihiko\nFukushima in 1979, though not trained by backpropagation.[45][46]\nBackpropagation  is  an  efficient  application  of  the  chain  rule  derived  by  Gottfried\nWilhelm  Leibniz  in  1673[47]  to  networks  of  differentiable  nodes.  The  terminology\n\"back-propagating  errors\"  was  actually  introduced  in  1962  by  Rosenblatt,[37]  but  he\ndid  not  know  how  to  implement  this,  although  Henry  J.  Kelley  had  a  continuous\nprecursor of backpropagation in 1960 in the context of control theory.[48] The modern\nform  of  backpropagation  was  first  published  in  Seppo  Linnainmaa's  master  thesis\n(1970).[49][50][31]  G.M.  Ostrovski  et  al.  republished  it  in  1971.[51][52]  Paul  Werbos\napplied backpropagation to neural networks in 1982[53] (his 1974 PhD thesis, reprinted\nin  a  1994  book,[54]  did  not  yet  describe  the  algorithm[52]).  In  1986,  David  E.\nRumelhart et al. popularised backpropagation but did not cite the original work.[55][56]\nThe time delay neural network (TDNN) was introduced in 1987 by Alex Waibel to apply\nCNN  to  phoneme  recognition.  It  used  convolutions,  weight  sharing,  and\nbackpropagation.[57][58]  In 1988, Wei Zhang applied a backpropagation-trained CNN\nto alphabet recognition.[59] \nIn 1989, Yann LeCun et al. created a CNN called LeNet for recognizing handwritten ZIP\ncodes on mail. Training required 3 days.[60] In 1990, Wei Zhang implemented a CNN on\noptical computing hardware.[61] In 1991, a CNN was applied to medical image object\nsegmentation[62] and breast cancer detection in mammograms.[63] LeNet-5 (1998), a",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 21\nData MiningDefinition and context\n\u201eData Mining is the process of extracting previously unknown, valid, and actionable informationfrom large databases and then using the information to make crucial business decisions.\u201c(Cabena et al. 1997)\n\u201eData Mining, as we use the term, is the exploration and analysis, by automatic or semiautomatic means, of large quantities of data in order to discover meaningful patterns and rules.\u201c(Berry et al. 1997)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 22\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 6\nDefinition of Text MiningUnderstanding of the term in the literature\nSources: Schieber & Hilbert (2014c), p. 13\nInformation extraction\n\u2022Extraction of passages from texts\u2022Annotation of these passages with attributes\u2022Ex: \u2022Recognition of companies and people\u2022Assignment of functions of a person in the company\u2022Source: Hotho et al. (2005), p. 45ff.\nAnalysis method\n\u2022Methods for computer-aided text analysis \u2022(semi-)automatic structuring of texts\u2022Ex:\u2022Text Clustering\u2022Text Categorization \u2022Sources: He (2013), p. 501; Heyer et al. (2006), p. 3.\nKnowledge generation process\n\u2022Analogous to the KDD process for data mining according to Fayyad (1996), p. 9.\u2022Knowledge Discovery in Textual Databases (KDT)\u2022Process includes, among other things, phases for the selection, preparation and analysis of text data\u2022Sources: Feldman & Dagan (1995), p. 112; Hippner & Rentzmann (2006), p. 287.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 25\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n3.1 Partitioned Cluster Methods\n3.2 Hierarchical Cluster Methods",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 29\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n7.1 Anomaly Detection Introduction\n7.2 Methods",
            "In particular, in the context of abuse and network intrusion detection, the interesting\nobjects are often not rare objects, but unexpected bursts of inactivity. This pattern does\nnot  adhere  to  the  common  statistical  definition  of  an  outlier  as  a  rare  object.  Many\noutlier detection methods (in particular, unsupervised algorithms) will fail on such data\nunless aggregated appropriately. Instead, a cluster analysis algorithm may be able to\ndetect the micro-clusters formed by these patterns.[74]\nThree  broad  categories  of  anomaly  detection  techniques  exist.[75]  Unsupervised\nanomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised\nanomaly detection techniques require a data set that has been labeled as \"normal\" and\n\"abnormal\"  and  involves  training  a  classifier  (the  key  difference  from  many  other\nstatistical  classification  problems  is  the  inherently  unbalanced  nature  of  outlier\ndetection).  Semi-supervised  anomaly  detection  techniques  construct  a  model\nrepresenting normal behavior from a given normal training data set and then test the\nlikelihood of a test instance to be generated by the model.\nRobot learning is inspired by a multitude of machine learning methods, starting from\nsupervised  learning,  reinforcement  learning,[76][77]  and  finally  meta-learning  (e.g.\nMAML).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 22\n\u03b1-Algorithm Order Relations\nBasic(a > b)Task a is directly followed by bBasis for the definition of the other three order relations\nCausality(a \u2192b)a > b and that b \u226fa\nParallelism(a \u01c1b)a > b and b > a\nNon-succession(a#b)a \u226fb and b \u226fa Dumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 7\nProcess Mining Challenges\nCorrelation challenge-Identify the case an event belongs toTimestamps challenge-Logging is often delayed until the system has idle time: sequential events with the same timestamp, logs from different Business Process Management Software (BPMS)Longevity challenge-Long running processes might be too slow for snapshot windowScoping challenge-IS does not directly produce event logs. Logs are synthesizedGranularity challenge-Abstraction of model might be different from logDumas et al. (2013, 2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 40\nConformance Checking\n\u201cDoes the execution of a process followspredefined rules or constraints or does it violatethem?\u201d\nViolations relate to one of the three process perspectives-Control flowExplicit constraintsNormative process model-Data-Resourcesin isolation or in combination\nDumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 42\nNormative Process Model\nFor each trace in the workflow logreplay with tokensandrecordat each step whether an activity was allowedto be executed according to the rules of the model\nIs (a, b, g, j, i, k, l) valid?\nIs (a, b, i, j, k, l) valid, too? If not, what does it violate?\nDumas et al. (2018)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem)."
        ],
        "generated": "The definition of Deep Learning by Najafabadi et al. (2016) is: \"The main concept in deep learning algorithms is automating the extraction of representations (abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representation.\"",
        "ground_truth": "The main concept in deep learning algorithms is automating the extraction of representations (abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representations."
    },
    {
        "query": "What is segmentation or cluster analysis used for?",
        "retrieved": [
            "Aimsoftheclusteranalysis\n\u2015Segmentationorcluster analysis is used to group objects and/or characteristics into classes or groups, so that-between the elements of thesame classes as similar as possible,-between the elements of different classes the greatest possible dissimilarityis achieved.\u2015The clusters are not known beforehand.\u2015So-calledunsupervised learning methods are used, for example.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 2\nRecap: Aims of the cluster analysis\nSegmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that\u2022between the elements of the same classes the greatest possible similarity,\u2022between the elements of different classes the greatest possible diversity is achieved",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 3\nAimsoftheclusteranalysis\n\u2015Segmentationorcluster analysis is used to group objects and/or characteristics into classes or groups, so that-between the elements of thesame classes as similar as possible,-between the elements of different classes the greatest possible dissimilarityis achieved.\u2015The clusters are not known beforehand.\u2015So-calledunsupervised learning methods are used, for example.",
            "Basics ofsegmentation\nCluster types",
            "beneficial in image and signal processing, k-means clustering aids in data reduction by\nreplacing  groups  of  data  points  with  their  centroids,  thereby  preserving  the  core\ninformation  of  the  original  data  while  significantly  decreasing  the  required  storage\nspace.[32]\nMachine  learning  and  data  mining  often  employ  the  same  methods  and  overlap\nsignificantly,  but  while  machine  learning  focuses  on  prediction,  based  on  known",
            "In unsupervised machine learning, k-means clustering can be utilized to compress data\nby  grouping  similar  data  points  into  clusters.  This  technique  simplifies  handling\nextensive datasets that lack predefined labels and finds widespread use in fields such\nas image compression.[31]\nData  compression  aims  to  reduce  the  size  of  data  files,  enhancing  storage  efficiency\nand  speeding  up  data  transmission.  K-means  clustering,  an  unsupervised  machine\nlearning  algorithm,  is  employed  to  partition  a  dataset  into  a  specified  number  of\nclusters,  k,  each  represented  by  the  centroid  of  its  points.  This  process  condenses\nextensive  datasets  into  a  more  compact  set  of  representative  points.  Particularly\nbeneficial in image and signal processing, k-means clustering aids in data reduction by\nreplacing  groups  of  data  points  with  their  centroids,  thereby  preserving  the  core\ninformation  of  the  original  data  while  significantly  decreasing  the  required  storage\nspace.[32]\nMachine  learning  and  data  mining  often  employ  the  same  methods  and  overlap\nsignificantly,  but  while  machine  learning  focuses  on  prediction,  based  on  known\nproperties  learned  from  the  training  data,  data  mining  focuses  on  the  discovery  of\n(previously)  unknown  properties  in  the  data  (this  is  the  analysis  step  of  knowledge\ndiscovery in databases). Data mining uses many machine learning methods, but with\ndifferent goals; on the other hand, machine learning also employs data mining methods\nas  \"unsupervised  learning\"  or  as  a  preprocessing  step  to  improve  learner  accuracy.\nMuch of the confusion between these two research communities (which do often have\nseparate  conferences  and  separate  journals,  ECML  PKDD  being  a  major  exception)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 10\nHierarchicalClustering Methods\nSegmentation methods that construct a sequence of partitions on the basis ofa set of objects N.\nAgglomerative ClusteringEach object initially represents a cluster of its own. Then clusters are successively merged until the desired cluster structure is obtained.\nDiversiveClusteringAll objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained.\n\u2022Starting point is the class of all objects.\u2022Successive transition to finer decompositions\u2022Termination as soon as given criterion is fulfilled\n\u2022Starting point are n = |N| one-element classes. \u2022Successive transition to coarser decompositions\u2022Termination as soon as given criterion is fulfilled\u2022Low computation times, good practical suitability> Kaufman, L. and Rousseeuw, P.J. (1990) PartitioningaroundMedoids(ProgramPAM). In: Kaufman, L. and Rousseeuw, P.J., Eds., FindingGroups in Data: An IntroductiontoCluster Analysis, John Wiley & Sons, Inc., Hoboken, 68-125.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 5\nPartionalClustering Methods\nPartitioning methods are segmentation methods which divide the set of objects N on the basis of a fixed number of classes s in such a way that the computed segmentation or partition Kminimizes a given quality index b(K):\n{ }\ns\n1s i i j(( N ) ) i1\nmin b( ) : K , ,K ,    K N,    K K\u00ce\u00c3 \u00c3 =\n\u00ec\u00fc == \u00c7 = \u00c6\u00ed\u00fd\u00ee\u00fe\nK UK",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 34\nClustering basedOverview\nIdea 1: Normal data instances belong to a cluster in the data, while anomalies do not belong to any cluster:Requires cluster method that does not put every data point into clustersE.g.: DBSCAN, ROCK, WaveCluster, FindOutIdea 2: Normal data instances lie close to their closest cluster centroid, while anomalies are far away from their closest cluster centroid:Commonused methods are SOM, K-means, Expectation MaximizationSemi-supervised approach can be used to improve resultsIdea 1 and 2 arenot working well when anomalies form clusters themselvesIdea 3: Normal data instances belong to large and dense clusters, while anomalies either belong to small or sparse clustersCommonly used: FindCBLOFCBLOF analogous to LOF captures cluster size as well as centroid distance based on clustering results",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 39\nVariety of Data Analysis TechniquesWhich one to choose?\nHow do we know which technique/algorithm to choose?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 81\nText mining methodsDependency analyses\nDependency analyses map dependencies between termsIn contrast to classification and segmentation methods, these dependencies are calculated over the entire data setThis means that these results apply to all documents in the datasetBy determining term dependencies and linking these terms to term networks, ontologies can be created automatically\nMethods used in the literature:Association analysisCoocurrence analysis",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "In particular, in the context of abuse and network intrusion detection, the interesting\nobjects are often not rare objects, but unexpected bursts of inactivity. This pattern does\nnot  adhere  to  the  common  statistical  definition  of  an  outlier  as  a  rare  object.  Many\noutlier detection methods (in particular, unsupervised algorithms) will fail on such data\nunless aggregated appropriately. Instead, a cluster analysis algorithm may be able to\ndetect the micro-clusters formed by these patterns.[74]\nThree  broad  categories  of  anomaly  detection  techniques  exist.[75]  Unsupervised\nanomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised\nanomaly detection techniques require a data set that has been labeled as \"normal\" and\n\"abnormal\"  and  involves  training  a  classifier  (the  key  difference  from  many  other\nstatistical  classification  problems  is  the  inherently  unbalanced  nature  of  outlier\ndetection).  Semi-supervised  anomaly  detection  techniques  construct  a  model\nrepresenting normal behavior from a given normal training data set and then test the\nlikelihood of a test instance to be generated by the model.\nRobot learning is inspired by a multitude of machine learning methods, starting from\nsupervised  learning,  reinforcement  learning,[76][77]  and  finally  meta-learning  (e.g.\nMAML).",
            "Types  of  supervised-learning  algorithms  include  active  learning,  classification  and\nregression.[50] Classification algorithms are used when the outputs are restricted to a\nlimited set of values, and regression algorithms are used when the outputs may have\nany numerical value within a range. As an example, for a classification algorithm that\nfilters emails, the input would be an incoming email, and the output would be the name\nof the folder in which to file the email. Examples of regression would be predicting the\nheight of a person, or the future temperature.[51]\nSimilarity  learning  is  an  area  of  supervised  machine  learning  closely  related  to\nregression and classification, but the goal is to learn from examples using a similarity\nfunction  that  measures  how  similar  or  related  two  objects  are.  It  has  applications  in\nranking,  recommendation  systems,  visual  identity  tracking,  face  verification,  and\nspeaker verification.\nUnsupervised  learning  algorithms  find  structures  in  data  that  has  not  been  labeled,\nclassified  or  categorized.  Instead  of  responding  to  feedback,  unsupervised  learning\nalgorithms  identify  commonalities  in  the  data  and  react  based  on  the  presence  or\nabsence  of  such  commonalities  in  each  new  piece  of  data.  Central  applications  of\nunsupervised  machine  learning  include  clustering,  dimensionality  reduction,[7]  and\ndensity estimation.[52]\nCluster analysis is the assignment of a set of observations into subsets (called clusters)\nso  that  observations  within  the  same  cluster  are  similar  according  to  one  or  more",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 8\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nCritical consideration on the application in questionExample questions:Does the pattern lead to better decisions than some reasonable alternative?How well would one have done by chance? How well would one do with a smart \u2018\u2018default\u2019\u2019 alternative?\n\u201cEvaluatingdata-science results requires careful consideration of the context in which they will be used.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 110\nFeedback loops\n5.From phaseText Mining Procedureto phaseDocumentProcessing: To improve the analysis results, the documents must be reprocessed, e.g. because the requirements of the procedure were not yet known at the time of reprocessing. 6.From phaseResultInterpretation to phaseBusiness Understanding: In case of invalid results,the entire process must be repeated; the reason for this is misinterpretation of the task or poor execution of the process. 7.From phaseResultInterpretation to phaseText Mining Procedure: To improve the results, the text analysis must be performed again, e.g. with new procedures or new parameters. The model takes these situations into account and also provides further feedback options after all core phases, so that phases can be repeated recursively if required.",
            "and providing high-level information about the environment and the robot\nBesides the above-mentioned views on computer vision, many of the related research\ntopics  can  also  be  studied  from  a  purely  mathematical  point  of  view.  For  example,\nmany  methods  in  computer  vision  are  based  on  statistics,  optimization  or  geometry.\nFinally,  a  significant  part  of  the  field  is  devoted  to  the  implementation  aspect  of\ncomputer  vision;  how  existing  methods  can  be  realized  in  various  combinations  of\nsoftware  and  hardware,  or  how  these  methods  can  be  modified  in  order  to  gain\nprocessing speed without losing too much performance. Computer vision is also used in\nfashion eCommerce, inventory management, patent search, furniture, and the beauty\nindustry.[23]\nThe fields most closely related to computer vision are image processing, image analysis\nand  machine  vision.  There  is  a  significant  overlap  in  the  range  of  techniques  and\napplications that these cover. This implies that the basic techniques that are used and\ndeveloped in these fields are similar, something which can be interpreted as there is\nonly one field with different names. On the other hand, it appears to be necessary for\nresearch groups, scientific journals, conferences, and companies to present or market\nthemselves  as  belonging  specifically  to  one  of  these  fields  and,  hence,  various\ncharacterizations  which  distinguish  each  of  the  fields  from  the  others  have  been\npresented. In image processing, the input is an image and the output is an image as\nwell,  whereas  in  computer  vision,  an  image  or  a  video  is  taken  as  an  input  and  the\noutput could be an enhanced image, an understanding of the content of an image or\neven behavior of a computer system based on such understanding.",
            "1970s  by  Kunihiko  Fukushima,  is  an  early  example  of  computer  vision  taking  direct\ninspiration from neurobiology, specifically the primary visual cortex.\nSome strands of computer vision research are closely related to the study of biological\nvision\u2014indeed, just as many strands of AI research are closely tied with research into\nhuman intelligence and the use of stored knowledge to interpret, integrate, and utilize\nvisual  information.  The  field  of  biological  vision  studies  and  models  the  physiological\nprocesses behind visual perception in humans and other animals. Computer vision, on\nthe  other  hand,  develops  and  describes  the  algorithms  implemented  in  software  and\nhardware  behind  artificial  vision  systems.  An  interdisciplinary  exchange  between\nbiological and computer vision has proven fruitful for both fields.[21]\nYet  another  field  related  to  computer  vision  is  signal  processing.  Many  methods  for\nprocessing one-variable signals, typically temporal signals, can be extended in a natural\nway  to  the  processing  of  two-variable  signals  or  multi-variable  signals  in  computer\nvision.  However,  because  of  the  specific  nature  of  images,  there  are  many  methods\ndeveloped  within  computer  vision  that  have  no  counterpart  in  the  processing  of\none-variable signals. Together with the multi-dimensionality of the signal, this defines a\nsubfield in signal processing as a part of computer vision.\nRobot navigation sometimes deals with autonomous path planning or deliberation for\nrobotic systems to navigate through an environment.[22] A detailed understanding of\nthese  environments  is  required  to  navigate  through  them.  Information  about  the\nenvironment could be provided by a computer vision system, acting as a vision sensor"
        ],
        "generated": "Segmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that between the elements of the same classes the greatest possible similarity is achieved, and between the elements of different classes the greatest possible dissimilarity is achieved. The clusters are not known beforehand, and unsupervised learning methods are used for this purpose.",
        "ground_truth": "Segmentation or cluster analysis is used to group objects and/or characteristics into classes or groups, so that - between the elements of the same classes as similar as possible, - between the elements of different classes the greatest possible dissimilarity is achieved."
    },
    {
        "query": "What is the \u03b1-algorithm?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 18\n\u03b1-algorithm\nThe \u03b1-algorithmis a basicalgorithm for discovering process models from event logsIt is less complex than other advanced algorithmsIt will not be sufficient for practical application\nIdea is to identify the relations between all pairs of tasks from the workflow log to construct a process model\nDumas et al. (2018), van der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 31\nProblems with the \u03b1-Algorithm\nShort loopsa\u2192b, b\u2192ais not always (a \u01c1b) Incompleteness andnoiseFor 10 concurrent tasks, we need 10! = 3,628,800 casesMissing tasks\n Dumas et al. (2018)",
            "A-priori AlgorithmIdea\nThe A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database.The algorithm searches for all rules that have a high confidencevalue. It must now be taken into account that the important confidence of a rule is also expressed by its support values. Thus applies: Let X be an item set from the population of all items I and X\u2018 \u00ccX, then:",
            "-A-priori Algorithm-A-priori-Tid algorithm-A-priori-Hybrid Algorithm-AIS algorithmThe procedures have in common that they are often used as starting procedures in the data mining, since no assumptions are necessary to the connections of the data, which things could correlate e.g. (undirected data mining).\nNote: 100 itemsresultin generally(100 overk) item combinations.-2-itemsets: 4,950 combinations-3-itemsets: 161,700 combinations-5-itemsets: 75.287.520 combinations",
            "\u03b1-Algorithm Steps (3)\n7.Construct the flow arcs in the following way1.Pattern (a): For each a\u2192b, draw an arc a to b2.Pattern (b): For each a \u2192(b#c), draw an arc from a to an XOR-split, and from there to b and c3.Pattern (c): For each (b#c)\u2192d, draw an arc from b and c to an XOR-join, and from there to d4.Pattern (d) and (e): If a task in the so constructed process model has multiple incoming or multiple outgoing arcs, bundle these arcs with an AND-splitor AND-join, respectively",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 41\nVariety of Data Analysis TechniquesWhat is best practice?\nWhat are the most commonly usedtechniques/algorithms?",
            "meaning  that  even  the  coders  of  the  algorithm  cannot  audit  the  pattern  that  the\nmachine extracted out of the data.[123] The House of Lords Select Committee, which\nclaimed that such an \"intelligence system\" that could have a \"substantial impact on an\nindividual's  life\"  would  not  be  considered  acceptable  unless  it  provided  \"a  full  and\nsatisfactory explanation for the decisions\" it makes.[123]\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a\ncollision.[124]  Attempts  to  use  machine  learning  in  healthcare  with  the  IBM  Watson\nsystem  failed  to  deliver  even  after  years  of  time  and  billions  of  dollars\ninvested.[125][126] Microsoft's Bing Chat chatbot has been reported to produce hostile\nand offensive response against its users.[127]\nMachine  learning  has  been  used  as  a  strategy  to  update  the  evidence  related  to  a\nsystematic review and increased reviewer burden related to the growth of biomedical\nliterature. While it has improved with training sets, it has not yet developed sufficiently\nto reduce the workload burden without limiting the necessary sensitivity for the findings\nresearch themselves.[128]\nExplainable  AI  (XAI),  or  Interpretable  AI,  or  Explainable  Machine  Learning  (XML),  is\nartificial intelligence (AI) in which humans can understand the decisions or predictions\nmade  by  the  AI.[129]  It  contrasts  with  the  \"black  box\"  concept  in  machine  learning\nwhere even its designers cannot explain why an AI arrived at a specific decision.[130]\nBy  refining  the  mental  models  of  users  of  AI-powered  systems  and  dismantling  their\nmisconceptions,  XAI  promises  to  help  users  perform  more  effectively.  XAI  may  be  an",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 3\nArtificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in the input layer, you have as many nodes as input varibales + a constant (=bias)\u00a7Hidden units: Nodes in the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing the various outputs-Connection:\u00a7Each node is connected to the succeeding node (one direction only)\u00a7Each connection has a weight that need to be learned from the data\nIdothecalculations)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 13\nExample to explain layers\nWe will take a look at the following imageQuestion: Is this an X or a 0?\nThe computer can only see the numbers representing the colorNote: This example only has one color channel (black or white) to keep it simple\nImages from: ROHRER, BRANDON: How Convolutional Neural Networks work. https://www.youtube.com/watch?v=FmpDIaiMIeA",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 43\nTokens in a Normative Process Model\nHow many misplaced tokens in (a, b, i, j, k, l)?\nthe number of tokens that are correctly produced pthe number of tokens that are correctly consumed cthe number of tokens that are missing for executing mthe next activity in the log, andthe number of tokens remaining unconsumed rafter executing the final activity in the log\nproduced pconsumed cmissing mremaining r\nDumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 5\nIntroductionDefinition and Data Mining context\nOne possible definition:\nIn the context of data mining:-A portion of the observed data is generated by an unknown, anomalous process-This process differs from the standard processUntil now: -Assumption of one process that generates the data-Data Mining models reflecting that processNow: Interesting new observations that indicate differing mechanism behind data\n\u201cAn Outlier is an observation which deviates so much from the otherobservations as to arouse suspicions that it was generated by a differentmechanism\u201d (Hawkins, 1980)Source: Hawkins D. 1980. Identification of Outliers. Chapman and Hall.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 49\nRis an open sourceprogramming language with focus on better user friendlydata analysis, statistics and graphical modelsR is an implementation of S programming languageCreated by Ross Ihaka and Robert Gentleman Released in 1995R has been used primarily in academicsand research,but it is rapidly expanding into the enterprise market\u201cThe closer you are to statistics, research and data science,the more you might prefer R.\u201dStandard IDE is R StudioMain advantage: graphical capabilities for data visualization\n(Source: https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 24\nTask definitionUse case: Text mining in customer support\nText mining to categorize customer queriesManufacturers receive very many support requests by mailText mining to channel and distribute the flood of requestsSupport requests bymail orticketGoal: Automatic presorting ofmailsorticketsExamination of the content, what words are included, what topics do they indicateAssignment of mails to support topicsForwarding of the mails to the appropriate processor",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail.",
            "to gain high-level understanding from digital images or videos. From the perspective of\nengineering, it seeks to automate tasks that the human visual system can do.[5][6][7]\n\"Computer  vision  is  concerned  with  the  automatic  extraction,  analysis,  and\nunderstanding  of  useful  information  from  a  single  image  or  a  sequence  of  images.  It\ninvolves the development of a theoretical and algorithmic basis to achieve automatic\nvisual  understanding.\"[8]  As  a  scientific  discipline,  computer  vision  is  concerned  with\nthe  theory  behind  artificial  systems  that  extract  information  from  images.  The  image\ndata can take many forms, such as video sequences, views from multiple cameras, or\nmulti-dimensional  data  from  a  medical  scanner.[9]  As  a  technological  discipline,\ncomputer vision seeks to apply its theories and models for the construction of computer\nvision systems. Machine vision refers to a systems engineering discipline, especially in\nthe context of factory automation. In more recent times, the terms computer vision and\nmachine vision have converged to a greater degree.[10]:\u200a13\u200a\nIn the late 1960s, computer vision began at universities that were pioneering artificial\nintelligence.  It  was  meant  to  mimic  the  human  visual  system  as  a  stepping  stone  to\nendowing robots with intelligent behavior.[11] In 1966, it was believed that this could\nbe achieved through an undergraduate summer project,[12] by attaching a camera to a\ncomputer and having it \"describe what it saw\".[13][14]\nWhat distinguished computer vision from the prevalent field of digital image processing\nat that time was a desire to extract three-dimensional structure from images with the\ngoal  of  achieving  full  scene  understanding.  Studies  in  the  1970s  formed  the  early\nfoundations  for  many  of  the  computer  vision  algorithms  that  exist  today,  including\nextraction  of  edges  from  images,  labeling  of  lines,  non-polyhedral  and  polyhedral"
        ],
        "generated": "The \u03b1-algorithm is a basic algorithm for discovering process models from event logs. It is less complex than other advanced algorithms but may not be sufficient for practical application. The idea behind the \u03b1-algorithm is to identify the relations between all pairs of tasks from the workflow log to construct a process model.",
        "ground_truth": "The \u03b1-algorithm is a basic algorithm for discovering process models from event logs."
    },
    {
        "query": "What type of layers are in ANN?",
        "retrieved": [
            "Artificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 3\nArtificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in the input layer, you have as many nodes as input varibales + a constant (=bias)\u00a7Hidden units: Nodes in the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing the various outputs-Connection:\u00a7Each node is connected to the succeeding node (one direction only)\u00a7Each connection has a weight that need to be learned from the data\nIdothecalculations)",
            "Artificial Neural Networks (ANN)Recap: Example Network descriptionStructure:\u00a7An input layer with 3 input units\u00a7A hidden layer with 4 hidden units\u00a7An output layer with 2 output unitsConnections and weights:\u00a7Every unit of a layer is connected to every unit of the following layer\u00a7Those connections are not all of the same strength, instead they are weighted\u00a7Those weights are the parameter of an ANN model and need to be learnedFeed forward run:\u00a7Once the weights are learned, a new input vector can be",
            "surveys such as the one by Bishop.[27]\nThere  are  two  types  of  artificial  neural  network  (ANN):  feedforward  neural  network\n(FNN) or multilayer perceptron (MLP) and recurrent neural networks (RNN). RNNs have\ncycles in their connectivity structure, FNNs don't. In the 1920s, Wilhelm Lenz and Ernst\nIsing  created  the  Ising  model[28][29]  which  is  essentially  a  non-learning  RNN\narchitecture  consisting  of  neuron-like  threshold  elements.  In  1972,  Shun'ichi  Amari",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 5\nArtificial Neural Networks (ANN)Recap: Example Network descriptionStructure:\u00a7An input layer with 3 input units\u00a7A hidden layer with 4 hidden units\u00a7An output layer with 2 output unitsConnections and weights:\u00a7Every unit of a layer is connected to every unit of the following layer\u00a7Those connections are not all of the same strength, instead they are weighted\u00a7Those weights are the parameter of an ANN model and need to be learnedFeed forward run:\u00a7Once the weights are learned, a new input vector can be fed into the ANN and will be propagated through the net until an output is generated\u00a7Every unit (except the input units) are calculated by applying a function (mostly sigmoid or tanh) to the weighted linear combination of all units from the previous layer\u00a7See the picture in the previous slide for an example calculation\u00a7Play with ANN architectures (highly encouraged!!): http://playground.tensorflow.org/",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 4\nExample ANN 1 hidden layer, 3 input nodes, 4 hidden nodes, 2 output nodes\nArtificial Neural Networks (ANN)Recap: Classic ANN architecture and example calculation",
            "systems  \"learn\"  to  perform  tasks  by  considering  examples,  generally  without  being\nprogrammed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"artificial\nneurons\", which loosely model the neurons in a biological brain. Each connection, like\nthe  synapses  in  a  biological  brain,  can  transmit  information,  a  \"signal\",  from  one\nartificial neuron to another. An artificial neuron that receives a signal can process it and\nthen  signal  additional  artificial  neurons  connected  to  it.  In  common  ANN\nimplementations, the signal at a connection between artificial neurons is a real number,\nand the output of each artificial neuron is computed by some non-linear function of the\nsum  of  its  inputs.  The  connections  between  artificial  neurons  are  called  \"edges\".\nArtificial neurons and edges typically have a weight that adjusts as learning proceeds.\nThe weight increases or decreases the strength of the signal at a connection. Artificial\nneurons may have a threshold such that the signal is only sent if the aggregate signal\ncrosses that threshold. Typically, artificial neurons are aggregated into layers. Different\nlayers  may  perform  different  kinds  of  transformations  on  their  inputs.  Signals  travel\nfrom the first layer (the input layer) to the last layer (the output layer), possibly after\ntraversing the layers multiple times.\nThe original goal of the ANN approach was to solve problems in the same way that a\nhuman brain would. However, over time, attention moved to performing specific tasks,\nleading  to  deviations  from  biology.  Artificial  neural  networks  have  been  used  on  a\nvariety  of  tasks,  including  computer  vision,  speech  recognition,  machine  translation,\nsocial network filtering, playing board and video games and medical diagnosis.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 12\nConvolutional Neural Network: Overview\nStack layers to build a complete CNNOne type of layer is the previously mentioned \u201econvolutional layer\u201cIn total there are 4 types of layers:\u00a7Convolutional Layer (Extract features)\u00a7Pooling Layer (Reduce size)\u00a7ReLU Layer (Remove negative values \u00e0 disregard information about missing features)\u00a7Fully Connected Layer (Classify features)\nLECUN, YANN; BENGIO, YOSHUA: Convolutional Networks for Images, Speech, and Time-Series. In M. A. Arbib(Ed.),The handbook of brain theory and neural networksMIT Press (1995).\nConvolution\nReLU\nPooling\u2026\nFully-ConnectedThis is a face",
            "DNNs  can  model  complex  non-linear  relationships.  DNN  architectures  generate\ncompositional  models  where  the  object  is  expressed  as  a  layered  composition  of\nprimitives.[147]  The  extra  layers  enable  composition  of  features  from  lower  layers,\npotentially modeling complex data with fewer units than a similarly performing shallow\nnetwork.[7]  For  instance,  it  was  proved  that  sparse  multivariate  polynomials  are\nexponentially easier to approximate with DNNs than with shallow networks.[148]\nDeep architectures include many variants of a few basic approaches. Each architecture\nhas  found  success  in  specific  domains.  It  is  not  always  possible  to  compare  the\nperformance of multiple architectures, unless they have been evaluated on the same\ndata sets.[146]\nDNNs are typically feedforward networks in which data flows from the input layer to the\noutput layer without looping back. At first, the DNN creates a map of virtual neurons\nand assigns random numerical values, or \"weights\", to connections between them. The\nweights and inputs are multiplied and return an output between 0 and 1. If the network\ndid  not  accurately  recognize  a  particular  pattern,  an  algorithm  would  adjust  the\nweights.[149]  That  way  the  algorithm  can  make  certain  parameters  more  influential,\nuntil it determines the correct mathematical manipulation to fully process the data.\nRecurrent  neural  networks,  in  which  data  can  flow  in  any  direction,  are  used  for\napplications  such  as  language  modeling.[150][151][152][153][154]  Long  short-term",
            "Neural  networks  have  been  used  on  a  variety  of  tasks,  including  computer  vision,\nspeech  recognition,  machine  translation,  social  network  filtering,  playing  board  and\nvideo games and medical diagnosis.\nAs of 2017, neural networks typically have a few thousand to a few million units and\nmillions of connections. Despite this number being several order of magnitude less than\nthe number of neurons on a human brain, these networks can perform many tasks at a\nlevel beyond that of humans (e.g., recognizing faces, or playing \"Go\"[144]).\nA  deep  neural  network  (DNN)  is  an  artificial  neural  network  with  multiple  layers\nbetween the input and output layers.[7][9] There are different types of neural networks\nbut they always consist of the same components: neurons, synapses, weights, biases,\nand  functions.[145]  These  components  as  a  whole  function  in  a  way  that  mimics\nfunctions of the human brain, and can be trained like any other ML algorithm.[citation\nneeded]\nFor  example,  a  DNN  that  is  trained  to  recognize  dog  breeds  will  go  over  the  given\nimage and calculate the probability that the dog in the image is a certain breed. The\nuser can review the results and select which probabilities the network should display\n(above  a  certain  threshold,  etc.)  and  return  the  proposed  label.  Each  mathematical\nmanipulation as such is considered a layer, [146] and complex DNN have many layers,\nhence the name \"deep\" networks.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 19\nClassification basedAlgorithms\nNeural Networks: Multi-Class:Network is trained on normal data,test data is either accepted or rejected One-Class:Using Replicator Neural Networks, the input data is replicated by a number ofhidden layers (usually three). The reconstruction error resembles the anomaly scoreDecision Tree: Builds rules based on normal behavior; if test object does not follow any rulesit is declared anomalousAnomaly Score is inverse value of the leaf confidence of the best rule for each test point (= the fraction of correctly classified values)Support Vector Machine:Learns complex regions; If a point is outside the regionit is declared an anomalySpecial Case:One Class SVM",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 38\nLSTM-Concepts: Gates\nLSTM heavily uses gates in its architecureA gate is used to modify values in a vector to only let specific values or adapted values through.Sigmoid Gate: When using the Sigmoid activation function, the result is a vector of numbers between 0 and 1. When multiplying this vector pointwise with another vector, we can remove or deminish values in the other vector. 543\t\u00d700.251=013\t\nThese gates are used to \u201efilter\u201c values in vectors.LSTMs use 3 different gate layers to modify the internal state (following slides)\nSigmoid outputModified VectorInput",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 43\nAnomaly DetectionSummary\nEven though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation, etc. that are used in another context.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 41\nExplicit Constraints\nMandatoriness-Tasks that are required from a control perspective-Violationscan be found by searching for traces without them-e.g., review tasksExclusiveness-Tasks that relate to a decision-Violationscan be found by searching for traces with both/all of them-e.g., accept vs. reject taskOrdering-Tasks that have tobe in a specific succession-Violations can be found by searching for traces with the activities appearing in the wrong order-e.g., pay -> deliver Dumas et al. (2018)"
        ],
        "generated": "The types of layers in an Artificial Neural Network (ANN) are Input Layer, Hidden Layer(s), and Output Layer.",
        "ground_truth": "Input Layer, Hidden Layer, Output Layer."
    },
    {
        "query": "What are process mining challenges?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 7\nProcess Mining Challenges",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 34\nChallenges in Process Mining\ntarget model\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 35\nChallenges in Process Mining\nnon-fitting model\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 36\nChallenges in Process Mining\nUnderfitting Model\nvan der Aalst (2017)",
            "\u201cProcess mining adds the process perspective to machine learning and data mining\u201d\n\u201cProcess mining brings together traditional model-based process analysis and data-centric analysis techniques\u201d\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 2\nProcess Analytics and Process Mining\n\u201cProcess mining aims to exploit event data in a meaningful way\u201d\n\u201cProcess mining techniques use event data to discoverprocesses, check compliance, analyze bottlenecks, compare process variants, and suggest improvements\u201d\n\u201cProcess mining adds the process perspective to machine learning and data mining\u201d\n\u201cProcess mining brings together traditional model-based process analysis and data-centric analysis techniques\u201d\nvan der Aalst (2017)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 10\nText mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 21\nThe text mining process at a glance\nProcess activityDescriptionDefinetask The goal of the text mining project and the task must be clearly defined and described. This has an impact on the concrete design of the process as well as the choice of procedures. Select documents Source systems and target data are determined and extracted for analysis. Prepare documentsThe extracteddataisprocessed; a distinctionismadebetweenlinguisticand technicalprocessing. This phaseisparticularlydifferent fromdataminingprocessesand hasa strong influenceon theachievableresults. Apply text mining techniquesText mining methods are applied to the processed data; for example, documents are classified or grouped. Evaluate and interpret results The results are reviewed and evaluated; specific, statistical key figures can be evaluated for this purpose, depending on the procedure. Deriveand applymeasuresIftheresultsaresatisfactory, measurescanbederivedin linewiththetermsofreference.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 58\n2. Data preparation \u2013 normalization\nLSTMs are sensitive to the scale of the data\u00e0 Scale input data to values between 0 and 1Remeber to reverse this normalization when you want to display predictions\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))normalized_closing_values = scaler.fit_transform(closing_values)[...]predictions = scaler.inverse_transform(normalized_predictions)",
            "memory is particularly effective for this use.[155][156]\nConvolutional  neural  networks  (CNNs)  are  used  in  computer  vision.[157]  CNNs  also\nhave been applied to acoustic modeling for automatic speech recognition (ASR).[158]\nAs with ANNs, many issues can arise with naively trained DNNs. Two common issues\nare overfitting and computation time.\nDNNs are prone to overfitting because of the added layers of abstraction, which allow\nthem to model rare dependencies in the training data. Regularization methods such as\nIvakhnenko's unit pruning[41] or weight decay (\n\u2113\n2\n{\\displaystyle \\ell _{2}}",
            "Both  shallow  and  deep  learning  (e.g.,  recurrent  nets)  of  ANNs  for  speech  recognition\nhave  been  explored  for  many  years.[83][84][85]  These  methods  never  outperformed\nnon-uniform  internal-handcrafting  Gaussian  mixture  model/Hidden  Markov  model\n(GMM-HMM)  technology  based  on  generative  models  of  speech  trained\ndiscriminatively.[86]  Key  difficulties  have  been  analyzed,  including  gradient\ndiminishing[70]  and  weak  temporal  correlation  structure  in  neural  predictive\nmodels.[87][88]  Additional  difficulties  were  the  lack  of  training  data  and  limited\ncomputing power.\nMost  speech  recognition  researchers  moved  away  from  neural  nets  to  pursue\ngenerative modeling. An exception was at SRI International in the late 1990s. Funded\nby  the  US  government's  NSA  and  DARPA,  SRI  researched  in  speech  and  speaker\nrecognition.  The  speaker  recognition  team  led  by  Larry  Heck  reported  significant\nsuccess  with  deep  neural  networks  in  speech  processing  in  the  1998  NIST  Speaker\nRecognition  benchmark.[89][90]  It  was  deployed  in  the  Nuance  Verifier,  representing\nthe first major industrial application of deep learning.[91]\nThe  principle  of  elevating  \"raw\"  features  over  hand-crafted  optimization  was  first\nexplored successfully in the architecture of deep autoencoder on the \"raw\" spectrogram\nor  linear  filter-bank  features  in  the  late  1990s,[90]  showing  its  superiority  over  the\nMel-Cepstral  features  that  contain  stages  of  fixed  transformation  from  spectrograms.\nThe  raw  features  of  speech,  waveforms,  later  produced  excellent  larger-scale\nresults.[92]",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail."
        ],
        "generated": "The process mining challenges mentioned in the provided context include:\n1. Target model challenges\n2. Non-fitting model challenges\n3. Frequent behavior and trace in the log challenges\n4. Underfitting model challenges",
        "ground_truth": "Correlation challenge, Timestamps challenge, longevity challenge, scoping challenge, granularity challenge."
    },
    {
        "query": "What are anomaly detection methods?",
        "retrieved": [
            "Anomaly Detection\nMethods",
            "Anomaly Detection\nIntroduction",
            "Data Science: Advanced Analytics\nAnomaly Detection",
            "Even though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 43\nAnomaly DetectionSummary\nEven though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation, etc. that are used in another context.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 4\nIntroductionOverview\nAnomalous patterns are often referred to as anomalies, outliers, discordant observations, exceptions, aberrations, surprises, peculiarities orcontaminants in different application domainsWe will use the term anomalyMain reference: Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A Survey. ACM Computing Surveys, 41(3), 1\u201358. \nDistinction:-Anomaly Detection deals with detecting interesting, non-normal patterns-In contrast noise removal deals with detection and removal of unwanted outliersthat are not of interest-Novelty detection deals with new patterns that in contrast to anomalies can also be part of the \u201enormal\u201c behavior-The methods used are fairly similar, however anomaly detection seems to offer the biggest range of methods",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 9\nMethodsCriteria for anomaly detection problem definition",
            "In particular, in the context of abuse and network intrusion detection, the interesting\nobjects are often not rare objects, but unexpected bursts of inactivity. This pattern does\nnot  adhere  to  the  common  statistical  definition  of  an  outlier  as  a  rare  object.  Many\noutlier detection methods (in particular, unsupervised algorithms) will fail on such data\nunless aggregated appropriately. Instead, a cluster analysis algorithm may be able to\ndetect the micro-clusters formed by these patterns.[74]\nThree  broad  categories  of  anomaly  detection  techniques  exist.[75]  Unsupervised\nanomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised\nanomaly detection techniques require a data set that has been labeled as \"normal\" and\n\"abnormal\"  and  involves  training  a  classifier  (the  key  difference  from  many  other\nstatistical  classification  problems  is  the  inherently  unbalanced  nature  of  outlier\ndetection).  Semi-supervised  anomaly  detection  techniques  construct  a  model\nrepresenting normal behavior from a given normal training data set and then test the\nlikelihood of a test instance to be generated by the model.\nRobot learning is inspired by a multitude of machine learning methods, starting from\nsupervised  learning,  reinforcement  learning,[76][77]  and  finally  meta-learning  (e.g.\nMAML).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 9\nMethodsCriteria for anomaly detection problem definition\nThere is NO general approach that works for all application domainsDifferent problem definitionsdepending on some basic criteria:-Nature of data-Labels-Anomaly Type-OutputAnomaly Detection methods can be found in many research fields:-Machine Learning (Data Mining)-Statistics-Information Theory-Spectral Theory-\u2026",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 41\nStatistical methodsAdvantages\nIf the assumptionsregarding the underlying data distribution hold true, statistical techniques provide a statistically justifiable solution for anomaly detection.\nThe anomaly score provided by a statistical technique is associated with a confidence interval, which can be used as additional information while making a decisionregarding any test instance.\nIf the distribution estimation step is robustto anomalies in data, statistical techniques can operate in aunsupervised setting without any need for labeled training data.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 39\nStatistical methodsParametric methods: other methods\nRegression based:(1) Regression is estimated(2) for each data object the residual score resembles the anomaly scoreSome criteria used to detect anomalies in a regressions setting:\u2014AIC: anomalies influence regression results\u2014Robust regression: should be used to avoid anomaly influences \u00f0residuals for anomalies are considerably larger in this setting\u2014ARIMA/ARMA: detection of anomalies in a time series settingMixture distribution based: Two approaches -Different distributions for normal data and anomalies or mixed distribution for only the normal class",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 34\nClustering basedOverview\nIdea 1: Normal data instances belong to a cluster in the data, while anomalies do not belong to any cluster:Requires cluster method that does not put every data point into clustersE.g.: DBSCAN, ROCK, WaveCluster, FindOutIdea 2: Normal data instances lie close to their closest cluster centroid, while anomalies are far away from their closest cluster centroid:Commonused methods are SOM, K-means, Expectation MaximizationSemi-supervised approach can be used to improve resultsIdea 1 and 2 arenot working well when anomalies form clusters themselvesIdea 3: Normal data instances belong to large and dense clusters, while anomalies either belong to small or sparse clustersCommonly used: FindCBLOFCBLOF analogous to LOF captures cluster size as well as centroid distance based on clustering results",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 22\nNeighbor basedOverview\nIdea: Normal data instances occur in dense neighborhoods, while anomalies occur far from their closest neighbors.We need to measure the distance between data object to construct the neighborhood.We can use distance measures introduced in the cluster lectures.Remember: Distance measures should be chosen according to the scale levels of variables.Two main approaches in anomaly detection:Approaches that use k-nearest neighbor distancesApproaches that calculate relative density scores for each object with regard tothe neighborhood",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 7\nIntroductionChallenges\nDefining anormal region which encompasses every possible normal behavior is very difficult. When anomalies are the result of malicious actions, the malicious adversaries often adapt themselves to make the anomalous observations appear like normal.In many domains normal behavior keeps evolving and a current notion of normal behavior might not be sufficiently representative in the future.The exact notion of an anomaly is different for different application domains.\nAvailability of labeled data for training/validation of models used by anomaly detection techniques is usually a major issue.\nOften the data contains noise which tends to be similar tothe actual anomalies and hence is difficult to distinguish and remove.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 36\nClustering basedDisadvantages\nPerformance of clustering basedtechniques is highly dependent on the effectiveness of clustering algorithm in capturing the cluster structure of normal instances.\nMany techniques detect anomalies as a by-product of clustering, and hence are not optimized for anomaly detection.\nSeveral clustering algorithms force every instance to be assigned to some cluster.Several clustering based techniques are effective only when the anomalies do not form significant clusters among themselves.\nThe computational complexity for clustering the data is often a bottleneck.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 39\nVariety of Data Analysis TechniquesWhich one to choose?\nHow do we know which technique/algorithm to choose?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 41\nVariety of Data Analysis TechniquesWhat is best practice?\nWhat are the most commonly usedtechniques/algorithms?",
            "that the conditions for the universal approximation theorem holds. It is shown that this\nmethod  provides  a  strongly  consistent  estimator  and  outperforms  other  methods  in\ncase of large alphabet sizes.[229]\nDeep  learning  has  been  shown  to  produce  competitive  results  in  medical  application\nsuch  as  cancer  cell  classification,  lesion  detection,  organ  segmentation  and  image\nenhancement.[230][231] Modern deep learning tools demonstrate the high accuracy of\ndetecting various diseases and the helpfulness of their use by specialists to improve the\ndiagnosis efficiency.[232][233]\nFinding the appropriate mobile audience for mobile advertising is always challenging,\nsince many data points must be considered and analyzed before a target segment can\nbe created and used in ad serving by any ad server.[234] Deep learning has been used\nto  interpret  large,  many-dimensioned  advertising  datasets.  Many  data  points  are\ncollected during the request/serve/click internet advertising cycle. This information can\nform the basis of machine learning to improve ad selection.\nDeep  learning  has  been  successfully  applied  to  inverse  problems  such  as  denoising,\nsuper-resolution,  inpainting,  and  film  colorization.[235]  These  applications  include\nlearning methods such as \"Shrinkage Fields for Effective Image Restoration\"[236] which\ntrains  on  an  image  dataset,  and  Deep  Image  Prior,  which  trains  on  the  image  that\nneeds restoration.",
            "reaches the area based on locally acquired image data. Modern military concepts, such\nas \"battlefield awareness\", imply that various sensors, including image sensors, provide\na rich set of information about a combat scene that can be used to support strategic\ndecisions. In this case, automatic processing of the data is used to reduce complexity\nand to fuse information from multiple sensors to increase reliability.\nOne  of  the  newer  application  areas  is  autonomous  vehicles,  which  include\nsubmersibles,  land-based  vehicles  (small  robots  with  wheels,  cars,  or  trucks),  aerial\nvehicles, and unmanned aerial vehicles (UAV). The level of autonomy ranges from fully\nautonomous  (unmanned)  vehicles  to  vehicles  where  computer-vision-based  systems\nsupport a driver or a pilot in various situations. Fully autonomous vehicles typically use\ncomputer  vision  for  navigation,  e.g.,  for  knowing  where  they  are  or  mapping  their\nenvironment (SLAM), for detecting obstacles. It can also be used for detecting certain\ntask-specific  events,  e.g.,  a  UAV  looking  for  forest  fires.  Examples  of  supporting\nsystems are obstacle warning systems in cars, cameras and LiDAR sensors in vehicles,\nand  systems  for  autonomous  landing  of  aircraft.  Several  car  manufacturers  have\ndemonstrated  systems  for  autonomous  driving  of  cars.  There  are  ample  examples  of\nmilitary  autonomous  vehicles  ranging  from  advanced  missiles  to  UAVs  for  recon\nmissions  or  missile  guidance.  Space  exploration  is  already  being  made  with\nautonomous vehicles using computer vision, e.g., NASA's Curiosity and CNSA's Yutu-2\nrover.\nMaterials  such  as  rubber  and  silicon  are  being  used  to  create  sensors  that  allow  for\napplications such as detecting microundulations and calibrating robotic hands. Rubber\ncan be used in order to create a mold that can be placed over a finger, inside of this",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 22\nC) AnalyticsIs it just about analyzing data?\nhttp://www.digitalvidya.com",
            "computed  by  looking  like  the  observed  points  and  the  covariances  between  those\npoints and the new, unobserved point.\nGaussian processes are popular surrogate models in Bayesian optimization used to do\nhyperparameter optimization.\nA genetic algorithm (GA) is a search algorithm and heuristic technique that mimics the\nprocess of natural selection, using methods such as mutation and crossover to generate\nnew  genotypes  in  the  hope  of  finding  good  solutions  to  a  given  problem.  In  machine\nlearning,  genetic  algorithms  were  used  in  the  1980s  and  1990s.[95][96]  Conversely,\nmachine  learning  techniques  have  been  used  to  improve  the  performance  of  genetic\nand evolutionary algorithms.[97]\nThe theory of belief functions, also referred to as evidence theory or Dempster\u2013Shafer\ntheory,  is  a  general  framework  for  reasoning  with  uncertainty,  with  understood\nconnections  to  other  frameworks  such  as  probability,  possibility  and   imprecise\nprobability  theories.  These  theoretical  frameworks  can  be  thought  of  as  a  kind  of\nlearner  and  have  some  analogous  properties  of  how  evidence  is  combined  (e.g.,  \nDempster's  rule  of  combination),  just  like  how  in  a  pmf-based  Bayesian\napproach[clarification needed] would combine probabilities. However, there are many\ncaveats to these beliefs functions when compared to Bayesian approaches in order to\nincorporate ignorance and uncertainty quantification. These belief function approaches\nthat are implemented within the machine learning domain typically leverage a fusion\napproach  of  various  ensemble  methods  to  better  handle  the  learner's  decision",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 8\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nCritical consideration on the application in questionExample questions:Does the pattern lead to better decisions than some reasonable alternative?How well would one have done by chance? How well would one do with a smart \u2018\u2018default\u2019\u2019 alternative?\n\u201cEvaluatingdata-science results requires careful consideration of the context in which they will be used.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 19\nDifferent Expectations\u2026\u2026 what people think I do \nWhat my friends think I \ndo\nWhat my mother thinks I \ndo\nWhat my boss thinks I do\nWhat I really doWhat I think I doWhat society thinks I do"
        ],
        "generated": "Anomaly detection methods are techniques used to identify anomalies or outliers in data. These methods typically assume that anomalies are rare compared to normal instances and have unique strengths and weaknesses based on the specific situation or application. Commonly known anomaly detection methods include SVM, clustering, kernel density estimation, and others that are used in various contexts.",
        "ground_truth": "Classification based, neighbor based, clustering based, statistical methods, information theory based, spectral theory based."
    },
    {
        "query": "What are items regarding Association Analysis?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 4\nAssociationAnalysisBasic Terms\nItemsare uninterpretable, discrete things or entities. The set of all items is denoted by I.An association rule A \u00e0B consists of a set of items A in the rule bodyand a set of items B in the rule head, where A and B must be disjoint.Each transaction tconsists of a set of items. The transactions considered in the association analysis are combined into a database D.A transaction t satisfies a rule A \u00e0B if (A\u00c8B) \u00cdt, i.e., if all items contained in the rule also occur in the transaction.\n/Acan'tbepartof BS",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 21\nAssociationAnalysisComments on thesubjectoftransactions\nThe following applies to transactions in general:Transactions consist of item quantity and transaction time. Often, information on behavior over time is available in addition to the transactions.  -Market Basket analysis: Payment by credit card or customer card; -Delivery Providers: collection of customer information e.g. based on orders received.However, this information is not usedin classical association analysis, although the inclusion of this additional information can significantly increase the meaningfulness of the rules (\u00e0sequence analysis).",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 3\nAssociationAnalysisIdeaand Examples\nThe ideacan be described as follows:-So-called association rules should be found that describe the correlation between items that occur together. -Thus, the identification of items A that imply the occurrence of other items B within a transaction should succeed. -A discovered relationshipbetween two or more items can then be represented as a rule of the form \"If item(set) A, then item(set) B\"or A \u00e0B, respectively. Examplesinclude the following:-Point-of-sale transactions-Financialand banking services (current account, share deposit, credit card, building loan, etc.)-Conclusion of various insurances (especially: sequence analyses)-Combinations of insurance claims-Interactions when taking different medicationsat the same time",
            "Itemsare uninterpretable, discrete things or entities. The set of all items is denoted by I.An association rule A \u00e0B consists of a set of items A in the rule bodyand a set of items B in the rule head, where A and B must be disjoint.Each transaction tconsists of a set of items. The transactions considered in the association analysis are combined into a database D.A transaction t satisfies a rule A \u00e0B if (A\u00c8B) \u00cdt, i.e., if all items contained in the rule also occur in the transaction.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 29\nAssociationAnalysis Remarks& applicationrecommendations\u2013Teil I\nProvided that frequent item sets with n elements exist, the A priori algorithm requires n iterations ( 1 MB shopping cart analyzable in seconds).Algorithm discovers thousands of rules.Visualizationor browsingis necessary:-Rules with very high support or confidence values are mostly already known.-The so called \"medium\" rulesare mainly interesting.\u00e0Thus, additional statistical key figures are necessary for the evaluation.Many external influencing factorsremain unconsidered, since transaction data do not include the following:-socio-economic status of buyers-time (time of day, day of week)-Advertising campaigns",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 8\nAssociationAnalysisAlgorithmoverview\nSince the data sets are typically very large, efficient algorithms are required.The algorithms themselves generally search for all association rules that meet predefined minimum confidence and minimum support.Depending on how this is done, different procedures are known. The best known methods are from Agrarwal:\n-A-priori Algorithm-A-priori-Tid algorithm-A-priori-Hybrid Algorithm-AIS algorithmThe procedures have in common that they are often used as starting procedures in the data mining, since no assumptions are necessary to the connections of the data, which things could correlate e.g. (undirected data mining).\nNote: 100 itemsresultin generally(100 overk) item combinations.-2-itemsets: 4,950 combinations-3-itemsets: 161,700 combinations-5-itemsets: 75.287.520 combinations",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 9\nA-priori AlgorithmIdea\nThe A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database.The algorithm searches for all rules that have a high confidencevalue. It must now be taken into account that the important confidence of a rule is also expressed by its support values. Thus applies: Let X be an item set from the population of all items I and X\u2018 \u00ccX, then: \nSupport values, in turn, represent frequencies of item sets in the population.\nsup( X )conf( (X X) X) sup( X X ')\n\u00a2\u00a2-\u00ae = -",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 27\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n5.1 Introduction to Text Mining\n5.2 Overview procedure model\n5.3 Components of procedure model\n5.4 Application Examples",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 24\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n2.1 Introduction to Segmentation\n2.2 Cluster types\n2.3 Distance measures\n2.4 Evaluation criteria \n2.5 Start heuristics",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 25\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n3.1 Partitioned Cluster Methods\n3.2 Hierarchical Cluster Methods",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 30\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n8.1 Introduction \n8.2 Process Warehouse\n8.3 Process Discovery\n8.4 Conformance Checking",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 29\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n7.1 Anomaly Detection Introduction\n7.2 Methods",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 22\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail."
        ],
        "generated": "Items in the context of Association Analysis are uninterpretable, discrete things or entities. The set of all items is denoted by I. An association rule A \u00e0 B consists of a set of items A in the rule body and a set of items B in the rule head, where A and B must be disjoint. Each transaction t consists of a set of items. The transactions considered in the association analysis are combined into a database D. A transaction t satisfies a rule A \u00e0 B if (A\u00c8B) \u00cd t, i.e., if all items contained in the rule also occur in the transaction.",
        "ground_truth": "Items are uninterpretable, discrete things or entities."
    },
    {
        "query": "What is the definition of a data scientist from Davenport & Patil (2012)?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 20\nSome Definitions\u2026 \u2026 collected by Chatfield et al. (2014)\nSource Definition: Data scientists are \u2026\nGranville (2014) \u201cnot statisticians, nor data analysts, nor computer scientists, nor software engineers, nor\nbusiness analysts. They have some knowledge in each of these areas but also some outside\nof these areas.\u201d\nDhar (2013) \u201crequires an integrated skill set spanning mathematics, machine learning, artificial\nintelligence, statistics, databases, and optimization, along with a deep understanding of the\ncraft of problem formulation to engineer effective solutions.\u201d\nDavenport & Patil (2012) \u201cthe people who understand how to fish out answers to important business questions from\ntoday\u2019s tsunami of unstructured information.\u201d\nMohanty et al. (2013) \u201cthe practitioners of the analytics models solving business problems. They incorporate\nadvanced analytical approaches using sophisticated analytics and data visualization tools to\ndiscover patterns in data. In many cases, these practitioners work with well-established\nanalytics techniques such as logistic regression methods, clustering methods, and\nclassification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,\nexplore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 20\nSome Definitions\u2026 \u2026 collected by Chatfield et al. (2014)\nSource Definition: Data scientists are \u2026\nGranville (2014) \u201cnot statisticians, nor data analysts, nor computer scientists, nor software engineers, nor\nbusiness analysts. They have some knowledge in each of these areas but also some outside\nof these areas.\u201d",
            "of these areas.\u201d\nDhar (2013) \u201crequires an integrated skill set spanning mathematics, machine learning, artificial\nintelligence, statistics, databases, and optimization, along with a deep understanding of the\ncraft of problem formulation to engineer effective solutions.\u201d\nDavenport & Patil (2012) \u201cthe people who understand how to fish out answers to important business questions from\ntoday\u2019s tsunami of unstructured information.\u201d",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 5\nA Definition of Data Scienceby Provost & Fawcett (2013)\nTo understand Data Science, it requires to understand the 1) principles, 2) concepts, 3) techniques, 4) technologies and5) processes behind it!",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 5\nA Definition of Data Scienceby Provost & Fawcett (2013)\nTo understand Data Science, it requires to understand the 1) principles, 2) concepts, 3) techniques, 4) technologies and5) processes behind it!\nAtahighlevel,datascienceisasetoffundamentalprinciplesthatsupportandguidetheprincipledextractionofinformationandknowledgefromdata.Possiblythemostcloselyrelatedconcepttodatascienceisdatamining-theactualextractionofknowledgefromdataviatechnologiesthatincorporatetheseprinciples.Therearehundredsofdifferentdataminingalgorithms,andagreatdealofdetailtothemethodsofthefield.Wearguethatunderlyingallthesemanydetailsisamuchsmallerandmoreconcisesetoffundamentalprinciples.\nDatascienceinvolvesprinciples,processes,andtechniquesforunderstandingphenomenaviathe(automated)analysisofdata.(\u2026)theultimategoalofdatascienceisimprovingdecisionmaking,asthisgenerallyisofparamountinteresttobusiness.(\u2026)Data-drivendecisionmakingreferstothepracticeofbasingdecisionsontheanalysisofdataratherthanpurelyonintuition.\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Data Science: Advanced Analytics\nIntroduction",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 7\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\n1.Structured approach towards analytical problem2.Careful analysis of the problemExamples of common process/ procedure models:Knowledge Discovery in Databases (KDD)Sample, Explore, Modify, Model, Asess (SEMMA)More details later\u2026\n\u201cExtracting useful knowledge from data to solve business problems can be treated systematicallyby following a  process with reasonably well-defined stages.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "explore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 8\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nCritical consideration on the application in questionExample questions:Does the pattern lead to better decisions than some reasonable alternative?How well would one have done by chance? How well would one do with a smart \u2018\u2018default\u2019\u2019 alternative?\n\u201cEvaluatingdata-science results requires careful consideration of the context in which they will be used.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 10\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nSimilarity is one of the most important measures in Data ScienceMany ways and specifications to quantify similarity\nProblem of representation, also called \u201eoverfitting\u201c\n\u201cEntities that are similar with respect to known featuresor attributes often are similar with respect to unknown featuresor attributes.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)\n\u201cIf you look too hard at a set of data, you will find something -but it might not generalize beyond the datayou\u2019re observing.\u201d",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 5\nIntroductionDefinition and Data Mining context\nOne possible definition:\nIn the context of data mining:-A portion of the observed data is generated by an unknown, anomalous process-This process differs from the standard processUntil now: -Assumption of one process that generates the data-Data Mining models reflecting that processNow: Interesting new observations that indicate differing mechanism behind data\n\u201cAn Outlier is an observation which deviates so much from the otherobservations as to arouse suspicions that it was generated by a differentmechanism\u201d (Hawkins, 1980)Source: Hawkins D. 1980. Identification of Outliers. Chapman and Hall.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 39\nVariety of Data Analysis TechniquesWhich one to choose?\nHow do we know which technique/algorithm to choose?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 4\nRelevance of text mining...in scienceHandling unstructured dataNeed for evaluations based on unstructured data Integration of unstructured data in the context of decision supportPotentials through the expansion of business understandingResearch branch Social Business Intelligence deals with the evaluation of social media\n...in practice\u2022Importance of unstructured data for companies increases\u2013Internal documents\u2013External documents\u2022Structuring information for knowledge management\u2022Analysis of large amounts of text provides implications for the further development of products and services\nSources: Baars & Kemper (2008), p. 132ff.; Dinter & Lorenz (2012), p. 1ff.; Gluchowski et al. (2008), p. 326ff.; Kruse et al. (2013), p. 1ff.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 22\nReferences & WebLinks\n\u00a7GOODFELLOW, I.; BENGIO, Y.; COURVILLE, A.:Deep Learning (2016), P.330ff.\u00a7LECUN, YANN; BENGIO, YOSHUA: Convolutional Networks for Images, Speech, and Time-Series. In M. A. Arbib(Ed.),The handbook of brain theory and neural networksMIT Press (1995).\u00a7ROHRER, BRANDON: How Convolutional Neural Networks work. https://www.youtube.com/watch?v=FmpDIaiMIeA\u00a7STANFORDCS231NCLASSNOTES: Convolutional Neural Networks for Visual Recognition: http://cs231n.github.io/convolutional-networks/",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 6\nDefinition of Text MiningUnderstanding of the term in the literature\nSources: Schieber & Hilbert (2014c), p. 13\nInformation extraction\n\u2022Extraction of passages from texts\u2022Annotation of these passages with attributes\u2022Ex: \u2022Recognition of companies and people\u2022Assignment of functions of a person in the company\u2022Source: Hotho et al. (2005), p. 45ff.\nAnalysis method\n\u2022Methods for computer-aided text analysis \u2022(semi-)automatic structuring of texts\u2022Ex:\u2022Text Clustering\u2022Text Categorization \u2022Sources: He (2013), p. 501; Heyer et al. (2006), p. 3.\nKnowledge generation process\n\u2022Analogous to the KDD process for data mining according to Fayyad (1996), p. 9.\u2022Knowledge Discovery in Textual Databases (KDT)\u2022Process includes, among other things, phases for the selection, preparation and analysis of text data\u2022Sources: Feldman & Dagan (1995), p. 112; Hippner & Rentzmann (2006), p. 287.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 3\nAimsoftheclusteranalysis\n\u2015Segmentationorcluster analysis is used to group objects and/or characteristics into classes or groups, so that-between the elements of thesame classes as similar as possible,-between the elements of different classes the greatest possible dissimilarityis achieved.\u2015The clusters are not known beforehand.\u2015So-calledunsupervised learning methods are used, for example.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 7\nDefinition of Text MiningUnderstanding of terms in the context of the lecture\nSources: Schieber & Hilbert (2014c), p. 13\nThe term text mining refers to the analytical process for computer-assisted knowledge generation from text data.\nFrom a process perspective, text mining includes both the collection and preparation of texts and the exploitation of the results.Analysis techniques are used to evaluate and generate the text mining results.\nThe processing and analysis steps are integrated as functions in application systems.\nText data can be both internal and external to the company; in the context of data processing, one also speaks of unstructured data.The goal of text mining is to generate new knowledge to be translated into action.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 19\nProcedure model according to Schieber & Hilbert\nProcess models such as the KDD, SEMMA or CRISP-DM process structure phases and tasks of the data mining processAnalogously, the procedure model according to Schieber & Hilbert structures the phases and tasks of the text mining processSources: Kurgan & Musilek (2006), p. 9ff.; Schieber & Hilbert (2014a), p. 45\nAufgaben \ndefinieren\nDokumente \nselektieren und \nuntersuchen\nDokumente \naufbereiten\nText-Mining-\nVerfahren \nanwenden\nErgebnisse \nevaluieren und \ninterpretieren\nMa\u00dfnahmen \nableiten und \nErgebnisse \nanwenden\nProblemstellung\nQuellsysteme Ergebnisse\nZus\u00e4tzliche \nHilfsmittel\nMa\u00dfnahmenArbeitsbereich",
            "to gain high-level understanding from digital images or videos. From the perspective of\nengineering, it seeks to automate tasks that the human visual system can do.[5][6][7]\n\"Computer  vision  is  concerned  with  the  automatic  extraction,  analysis,  and\nunderstanding  of  useful  information  from  a  single  image  or  a  sequence  of  images.  It\ninvolves the development of a theoretical and algorithmic basis to achieve automatic\nvisual  understanding.\"[8]  As  a  scientific  discipline,  computer  vision  is  concerned  with\nthe  theory  behind  artificial  systems  that  extract  information  from  images.  The  image\ndata can take many forms, such as video sequences, views from multiple cameras, or\nmulti-dimensional  data  from  a  medical  scanner.[9]  As  a  technological  discipline,\ncomputer vision seeks to apply its theories and models for the construction of computer\nvision systems. Machine vision refers to a systems engineering discipline, especially in\nthe context of factory automation. In more recent times, the terms computer vision and\nmachine vision have converged to a greater degree.[10]:\u200a13\u200a\nIn the late 1960s, computer vision began at universities that were pioneering artificial\nintelligence.  It  was  meant  to  mimic  the  human  visual  system  as  a  stepping  stone  to\nendowing robots with intelligent behavior.[11] In 1966, it was believed that this could\nbe achieved through an undergraduate summer project,[12] by attaching a camera to a\ncomputer and having it \"describe what it saw\".[13][14]\nWhat distinguished computer vision from the prevalent field of digital image processing\nat that time was a desire to extract three-dimensional structure from images with the\ngoal  of  achieving  full  scene  understanding.  Studies  in  the  1970s  formed  the  early\nfoundations  for  many  of  the  computer  vision  algorithms  that  exist  today,  including\nextraction  of  edges  from  images,  labeling  of  lines,  non-polyhedral  and  polyhedral",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 3\nArtificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in the input layer, you have as many nodes as input varibales + a constant (=bias)\u00a7Hidden units: Nodes in the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing the various outputs-Connection:\u00a7Each node is connected to the succeeding node (one direction only)\u00a7Each connection has a weight that need to be learned from the data\nIdothecalculations)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 19\nDifferent Expectations\u2026\u2026 what people think I do \nWhat my friends think I \ndo\nWhat my mother thinks I \ndo\nWhat my boss thinks I do\nWhat I really doWhat I think I doWhat society thinks I do",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "Deep  learning  consists  of  multiple  hidden  layers  in  an  artificial  neural  network.  This\napproach tries to model the way the human brain processes light and sound into vision\nand  hearing.  Some  successful  applications  of  deep  learning  are  computer  vision  and\nspeech recognition.[88]\nDecision  tree  learning  uses  a  decision  tree  as  a  predictive  model  to  go  from\nobservations  about  an  item  (represented  in  the  branches)  to  conclusions  about  the\nitem's  target  value  (represented  in  the  leaves).  It  is  one  of  the  predictive  modeling\napproaches used in statistics, data mining, and machine learning. Tree models where\nthe target variable can take a discrete set of values are called classification trees; in\nthese  tree  structures,  leaves  represent  class  labels,  and  branches  represent\nconjunctions of features that lead to those class labels. Decision trees where the target\nvariable can take continuous values (typically real numbers) are called regression trees.\nIn  decision  analysis,  a  decision  tree  can  be  used  to  visually  and  explicitly  represent\ndecisions and decision making. In data mining, a decision tree describes data, but the\nresulting classification tree can be an input for decision-making.\nRandom  forest  regression  (RFR)  falls  under  umbrella  of  decision  tree-based  models.\n\u00a0RFR is an ensemble learning method that builds multiple decision trees and averages\ntheir predictions to improve accuracy and to avoid overfitting. \u00a0To build decision trees,\nRFR uses bootstrapped sampling, for instance each decision tree is trained on random\ndata of from training set. This random selection of RFR for training enables model to\nreduce  bias  predictions  and  achieve  accuracy.  RFR  generates  independent  decision\ntrees, and it can work on single output data as well multiple regressor task. This makes"
        ],
        "generated": "According to Davenport & Patil (2012), data scientists are \"the people who understand how to fish out answers to important business questions from today\u2019s tsunami of unstructured information.\"",
        "ground_truth": "Data scientists are the people who understand how to fish out answers to important business questions from today\u2019s tsunami of unstructured information."
    },
    {
        "query": "How many credits does this course give?",
        "retrieved": [
            "Credit points: \n5\nAssessment:\n120min exam (ONYX-Exam \u2013 further information during the semester) \nAll information: in OPAL - https://bildungsportal.sachsen.de/opal/auth/RepositoryEntry/16864575517",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 12\nCourse Information \u2013\nextracts of the module guide \u201cDiplom Wirtschaftsinformatik\u201d\nCreditability:  \nMA-WW-WINF-0416b D-WW-WINF-0416b \nMaster: BWL, VWL, Wing, Winfo, Wip\u00e4d\nDiploma: Wing, Winfo\nCredit points: \n5\nAssessment:\n120min exam (ONYX-Exam \u2013 further information during the semester)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 13\nCourse structure\nLecture:\n\u2022 Will be provided on a weekly basis as video \nlectures on video campus Sachsen\n\u2022 first upload date: 19.04.2023\nExercises:\n\u2022 3 Virtual Exercises as MS Teams Call\n\u2022 free Python courses on DataCamp\nTrial exam: 30 min online (OPAL)\nExam:\n\u2022 120 min online (hybrid PC-Pool via OPAL)\u200b\n\u2022 Thrusday, August the 3-th.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 12\nCourse Information \u2013\nextracts of the module guide \u201cDiplom Wirtschaftsinformatik\u201d\nCreditability:  \nMA-WW-WINF-0416b D-WW-WINF-0416b \nMaster: BWL, VWL, Wing, Winfo, Wip\u00e4d\nDiploma: Wing, Winfo\nCredit points: \n5\nAssessment:\n120min exam (ONYX-Exam \u2013 further information during the semester) \nAll information: in OPAL - https://bildungsportal.sachsen.de/opal/auth/RepositoryEntry/16864575517",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 39\nVariety of Data Analysis TechniquesWhich one to choose?\nHow do we know which technique/algorithm to choose?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 21\nAssociationAnalysisComments on thesubjectoftransactions\nThe following applies to transactions in general:Transactions consist of item quantity and transaction time. Often, information on behavior over time is available in addition to the transactions.  -Market Basket analysis: Payment by credit card or customer card; -Delivery Providers: collection of customer information e.g. based on orders received.However, this information is not usedin classical association analysis, although the inclusion of this additional information can significantly increase the meaningfulness of the rules (\u00e0sequence analysis).",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 13\nExample to explain layers\nWe will take a look at the following imageQuestion: Is this an X or a 0?\nThe computer can only see the numbers representing the colorNote: This example only has one color channel (black or white) to keep it simple\nImages from: ROHRER, BRANDON: How Convolutional Neural Networks work. https://www.youtube.com/watch?v=FmpDIaiMIeA",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 32\nChallenge: Sequence related problems\nThink about the following questions:-What will the stock price of Nike be tomorrow?\u00a7You need information from the past: Where was it yesterday? Where was it before that?-What is the letter after M?\u00a7In your head you will probably think: \u201eH, I, J, K, L, M, N\u2026 It\u2018s N!\u201c\u00a7You can see, that your brain works with sequences of data.-How will this sentence end:\u00a7\u201eI was in France. It was very nice there! I even learned to speak\u2026\u201c\u00a7As a human, you can remember that we were talking about France at the beginning of the sentence, so the language will probably be french.All these questions are about a sequence of elements, sometimes time related.How can these sequences be incorporated into an ANN?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 62\n5. Test the model\nFirst, make predicted outputs for the test data and the training dataDenormalize this dataTest it by:-Plotting it-Calculating the lossimport mathfrom sklearn.metricsimport mean_squared_errortrain_predictions= scaler.inverse_transform(normalized_train_predictions)test_predictions= scaler.inverse_transform(normalized_test_predictions)plt.plot(closing_values)plt.plot(train_predictions)plt.plot(range(len(X_train), len(X_train) + len(X_test)), test_predictions)test_score= math.sqrt(mean_squared_error(y_test[:,0], test_predictions[:,0]))",
            "1970s  by  Kunihiko  Fukushima,  is  an  early  example  of  computer  vision  taking  direct\ninspiration from neurobiology, specifically the primary visual cortex.\nSome strands of computer vision research are closely related to the study of biological\nvision\u2014indeed, just as many strands of AI research are closely tied with research into\nhuman intelligence and the use of stored knowledge to interpret, integrate, and utilize\nvisual  information.  The  field  of  biological  vision  studies  and  models  the  physiological\nprocesses behind visual perception in humans and other animals. Computer vision, on\nthe  other  hand,  develops  and  describes  the  algorithms  implemented  in  software  and\nhardware  behind  artificial  vision  systems.  An  interdisciplinary  exchange  between\nbiological and computer vision has proven fruitful for both fields.[21]\nYet  another  field  related  to  computer  vision  is  signal  processing.  Many  methods  for\nprocessing one-variable signals, typically temporal signals, can be extended in a natural\nway  to  the  processing  of  two-variable  signals  or  multi-variable  signals  in  computer\nvision.  However,  because  of  the  specific  nature  of  images,  there  are  many  methods\ndeveloped  within  computer  vision  that  have  no  counterpart  in  the  processing  of\none-variable signals. Together with the multi-dimensionality of the signal, this defines a\nsubfield in signal processing as a part of computer vision.\nRobot navigation sometimes deals with autonomous path planning or deliberation for\nrobotic systems to navigate through an environment.[22] A detailed understanding of\nthese  environments  is  required  to  navigate  through  them.  Information  about  the\nenvironment could be provided by a computer vision system, acting as a vision sensor",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 13\nSimilaritymeasuresoftheobjects\n\u2015Since cluster analysis is used to group objects and/or features into classes or groups according to their similarity, one needs a measure that quantifies the similarity of two objects described by any features.\u2022Similarity measure AM: The larger a value, the more similar two objects are.\u2022Consequence: What does a value AM = 0 mean? or How great is the similarity of two identical objects?\n\u00deTransition to a difference measure or distance measure\n!The main problem of this measure is not the determination of the dissimilarity of two objects on the basis of one characteristic, but the dissimilarity in the presence of several characteristics (aggregation problem).",
            "low).Aggregation and ranking of ratingsInvestigation of particularly critically evaluated product properties",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 18\nProblematicpropertiesoftheLpdistance\n\u2015If two features k1 and k2 are highly correlated, then both features provide approximately the same information regarding the similarity of the objects. The same information is considered \"multiple\".\u2015Characteristics with large dispersion (i.e. variance) have a higher weight in aggregation\n\u2015The general remedy here is the Mahalanobis distance\nclushhas centroida distanceto -\nandroiddescribeif theyare similiarto\nthewholeduster",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 3\nAssociationAnalysisIdeaand Examples\nThe ideacan be described as follows:-So-called association rules should be found that describe the correlation between items that occur together. -Thus, the identification of items A that imply the occurrence of other items B within a transaction should succeed. -A discovered relationshipbetween two or more items can then be represented as a rule of the form \"If item(set) A, then item(set) B\"or A \u00e0B, respectively. Examplesinclude the following:-Point-of-sale transactions-Financialand banking services (current account, share deposit, credit card, building loan, etc.)-Conclusion of various insurances (especially: sequence analyses)-Combinations of insurance claims-Interactions when taking different medicationsat the same time",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 58\n2. Data preparation \u2013 normalization\nLSTMs are sensitive to the scale of the data\u00e0 Scale input data to values between 0 and 1Remeber to reverse this normalization when you want to display predictions\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))normalized_closing_values = scaler.fit_transform(closing_values)[...]predictions = scaler.inverse_transform(normalized_predictions)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 41\nStatistical methodsAdvantages\nIf the assumptionsregarding the underlying data distribution hold true, statistical techniques provide a statistically justifiable solution for anomaly detection.\nThe anomaly score provided by a statistical technique is associated with a confidence interval, which can be used as additional information while making a decisionregarding any test instance.\nIf the distribution estimation step is robustto anomalies in data, statistical techniques can operate in aunsupervised setting without any need for labeled training data.",
            "reaches the area based on locally acquired image data. Modern military concepts, such\nas \"battlefield awareness\", imply that various sensors, including image sensors, provide\na rich set of information about a combat scene that can be used to support strategic\ndecisions. In this case, automatic processing of the data is used to reduce complexity\nand to fuse information from multiple sensors to increase reliability.\nOne  of  the  newer  application  areas  is  autonomous  vehicles,  which  include\nsubmersibles,  land-based  vehicles  (small  robots  with  wheels,  cars,  or  trucks),  aerial\nvehicles, and unmanned aerial vehicles (UAV). The level of autonomy ranges from fully\nautonomous  (unmanned)  vehicles  to  vehicles  where  computer-vision-based  systems\nsupport a driver or a pilot in various situations. Fully autonomous vehicles typically use\ncomputer  vision  for  navigation,  e.g.,  for  knowing  where  they  are  or  mapping  their\nenvironment (SLAM), for detecting obstacles. It can also be used for detecting certain\ntask-specific  events,  e.g.,  a  UAV  looking  for  forest  fires.  Examples  of  supporting\nsystems are obstacle warning systems in cars, cameras and LiDAR sensors in vehicles,\nand  systems  for  autonomous  landing  of  aircraft.  Several  car  manufacturers  have\ndemonstrated  systems  for  autonomous  driving  of  cars.  There  are  ample  examples  of\nmilitary  autonomous  vehicles  ranging  from  advanced  missiles  to  UAVs  for  recon\nmissions  or  missile  guidance.  Space  exploration  is  already  being  made  with\nautonomous vehicles using computer vision, e.g., NASA's Curiosity and CNSA's Yutu-2\nrover.\nMaterials  such  as  rubber  and  silicon  are  being  used  to  create  sensors  that  allow  for\napplications such as detecting microundulations and calibrating robotic hands. Rubber\ncan be used in order to create a mold that can be placed over a finger, inside of this"
        ],
        "generated": "This course gives 5 credits.",
        "ground_truth": "5"
    },
    {
        "query": "What is text mining?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 7\nDefinition of Text MiningUnderstanding of terms in the context of the lecture\nSources: Schieber & Hilbert (2014c), p. 13\nThe term text mining refers to the analytical process for computer-assisted knowledge generation from text data.\nFrom a process perspective, text mining includes both the collection and preparation of texts and the exploitation of the results.Analysis techniques are used to evaluate and generate the text mining results.\nThe processing and analysis steps are integrated as functions in application systems.\nText data can be both internal and external to the company; in the context of data processing, one also speaks of unstructured data.The goal of text mining is to generate new knowledge to be translated into action.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 7\nDefinition of Text MiningUnderstanding of terms in the context of the lecture\nSources: Schieber & Hilbert (2014c), p. 13\nThe term text mining refers to the analytical process for computer-assisted knowledge generation from text data.",
            "From a process perspective, text mining includes both the collection and preparation of texts and the exploitation of the results.Analysis techniques are used to evaluate and generate the text mining results.\nThe processing and analysis steps are integrated as functions in application systems.",
            "Text Mining\nProceduremodel: Text miningprocedure",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 6\nDefinition of Text MiningUnderstanding of the term in the literature\nSources: Schieber & Hilbert (2014c), p. 13\nInformation extraction\n\u2022Extraction of passages from texts\u2022Annotation of these passages with attributes\u2022Ex: \u2022Recognition of companies and people\u2022Assignment of functions of a person in the company\u2022Source: Hotho et al. (2005), p. 45ff.\nAnalysis method",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 6\nDefinition of Text MiningUnderstanding of the term in the literature\nSources: Schieber & Hilbert (2014c), p. 13\nInformation extraction\n\u2022Extraction of passages from texts\u2022Annotation of these passages with attributes\u2022Ex: \u2022Recognition of companies and people\u2022Assignment of functions of a person in the company\u2022Source: Hotho et al. (2005), p. 45ff.\nAnalysis method\n\u2022Methods for computer-aided text analysis \u2022(semi-)automatic structuring of texts\u2022Ex:\u2022Text Clustering\u2022Text Categorization \u2022Sources: He (2013), p. 501; Heyer et al. (2006), p. 3.\nKnowledge generation process\n\u2022Analogous to the KDD process for data mining according to Fayyad (1996), p. 9.\u2022Knowledge Discovery in Textual Databases (KDT)\u2022Process includes, among other things, phases for the selection, preparation and analysis of text data\u2022Sources: Feldman & Dagan (1995), p. 112; Hippner & Rentzmann (2006), p. 287.",
            "The processing and analysis steps are integrated as functions in application systems.\nText data can be both internal and external to the company; in the context of data processing, one also speaks of unstructured data.The goal of text mining is to generate new knowledge to be translated into action.",
            "Many text mining techniques have their origins in data mining, and often classical data mining techniques can also be applied to text data, provided that the data is available in a suitable structure.In the literature, the vector space model according to Salton et al. (1975) is mostly used for this purpose, whereby the text data areavailable in a structured tabular form:Terms and documents are transformed into a matrixThe lines list the termsIn the columns the documents are listedThe",
            "Text Mining in the Big Data EnvironmentThe amount of available texts increases extremely in Web 2.0 (keyword: user-generated content)Social networks, forums and blogs can be interesting sources for product improvements, marketing activities or opinion analysisText processing and analysis is very computationally intensive even for a few documentsBig Data technologies enable high-performance and scalable analysis systemsEx: Hadoop-based systemsDistributed File Systems (Hadoop Distributed File",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 21\nThe text mining process at a glance\nProcess activityDescriptionDefinetask The goal of the text mining project and the task must be clearly defined and described. This has an impact on the concrete design of the process as well as the choice of procedures. Select documents Source systems and target data are determined and extracted for analysis. Prepare documentsThe extracteddataisprocessed; a distinctionismadebetweenlinguisticand technicalprocessing. This phaseisparticularlydifferent fromdataminingprocessesand hasa strong influenceon theachievableresults. Apply text mining techniquesText mining methods are applied to the processed data; for example, documents are classified or grouped. Evaluate and interpret results The results are reviewed and evaluated; specific, statistical key figures can be evaluated for this purpose, depending on the procedure. Deriveand applymeasuresIftheresultsaresatisfactory, measurescanbederivedin linewiththetermsofreference.",
            "Text mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 10\nText mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 70\nDocument preparationCustomize data structure\nMany text mining techniques have their origins in data mining, and often classical data mining techniques can also be applied to text data, provided that the data is available in a suitable structure.In the literature, the vector space model according to Salton et al. (1975) is mostly used for this purpose, whereby the text data areavailable in a structured tabular form:Terms and documents are transformed into a matrixThe lines list the termsIn the columns the documents are listedThe intersections show whether a term occurs in a document or not\nTerme \nindexieren und \ngewichten\nDatenstruktur \nanpassen\nVorbereitende \nAnalysen \ndurchf\u00fchren\nTerme \nreduzieren\nD1D2D3T11 0 1T20 0 1T31 1 0",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 14\nProcedure model for text mining\nAccording to this understanding of the term and in connection with the definition of text mining, a procedure model for text mining thus considers the flow of the analytical process for the (partially) automated extraction of knowledge from unstructured data. The process model divides this process into several phases, in which, in turn, different activities must be carried out in order to convert the raw data into useful knowledge over several steps. To perform the activities, procedures, methods and techniques must be applied to achieve the desired results.",
            "deep  learning  architecture  that  transforms  an  atomic  word  into  a  positional\nrepresentation  of  the  word  relative  to  other  words  in  the  dataset;  the  position  is\nrepresented as a point in a vector space. Using word embedding as an RNN input layer\nallows  the  network  to  parse  sentences  and  phrases  using  an  effective  compositional\nvector  grammar.  A  compositional  vector  grammar  can  be  thought  of  as  probabilistic\ncontext free grammar (PCFG) implemented by an RNN.[192] Recursive auto-encoders\nbuilt  atop  word  embeddings  can  assess  sentence  similarity  and  detect\nparaphrasing.[192] Deep neural architectures provide the best results for constituency\nparsing,[193]  sentiment  analysis,[194]  information  retrieval,[195][196]  spoken\nlanguage  understanding,[197]  machine  translation,[151][198]  contextual  entity\nlinking,[198]  writing  style  recognition,[199]  named-entity  recognition  (token\nclassification),[200] text classification, and others.[201]\nRecent developments generalize word embedding to sentence embedding.\nGoogle  Translate  (GT)  uses  a  large  end-to-end  long  short-term  memory  (LSTM)\nnetwork.[202][203][204][205]  Google  Neural  Machine  Translation  (GNMT)  uses  an\nexample-based machine translation method in which the system \"learns from millions\nof examples\".[203] It translates \"whole sentences at a time, rather than pieces\". Google\nTranslate  supports  over  one  hundred  languages.[203]  The  network  encodes  the\n\"semantics  of  the  sentence  rather  than  simply  memorizing  phrase-to-phrase\ntranslations\".[203][206]  GT  uses  English  as  an  intermediate  between  most  language\npairs.[206]",
            "meaning  that  even  the  coders  of  the  algorithm  cannot  audit  the  pattern  that  the\nmachine extracted out of the data.[123] The House of Lords Select Committee, which\nclaimed that such an \"intelligence system\" that could have a \"substantial impact on an\nindividual's  life\"  would  not  be  considered  acceptable  unless  it  provided  \"a  full  and\nsatisfactory explanation for the decisions\" it makes.[123]\nIn 2018, a self-driving car from Uber failed to detect a pedestrian, who was killed after a\ncollision.[124]  Attempts  to  use  machine  learning  in  healthcare  with  the  IBM  Watson\nsystem  failed  to  deliver  even  after  years  of  time  and  billions  of  dollars\ninvested.[125][126] Microsoft's Bing Chat chatbot has been reported to produce hostile\nand offensive response against its users.[127]\nMachine  learning  has  been  used  as  a  strategy  to  update  the  evidence  related  to  a\nsystematic review and increased reviewer burden related to the growth of biomedical\nliterature. While it has improved with training sets, it has not yet developed sufficiently\nto reduce the workload burden without limiting the necessary sensitivity for the findings\nresearch themselves.[128]\nExplainable  AI  (XAI),  or  Interpretable  AI,  or  Explainable  Machine  Learning  (XML),  is\nartificial intelligence (AI) in which humans can understand the decisions or predictions\nmade  by  the  AI.[129]  It  contrasts  with  the  \"black  box\"  concept  in  machine  learning\nwhere even its designers cannot explain why an AI arrived at a specific decision.[130]\nBy  refining  the  mental  models  of  users  of  AI-powered  systems  and  dismantling  their\nmisconceptions,  XAI  promises  to  help  users  perform  more  effectively.  XAI  may  be  an",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 8\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nCritical consideration on the application in questionExample questions:Does the pattern lead to better decisions than some reasonable alternative?How well would one have done by chance? How well would one do with a smart \u2018\u2018default\u2019\u2019 alternative?\n\u201cEvaluatingdata-science results requires careful consideration of the context in which they will be used.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 26\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n4.1 Introduction to Association Analysis\n4.2 Algorithm overview\n4.3 Measure of interest\n4.4 Taxonomies",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 58\n2. Data preparation \u2013 normalization\nLSTMs are sensitive to the scale of the data\u00e0 Scale input data to values between 0 and 1Remeber to reverse this normalization when you want to display predictions\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0, 1))normalized_closing_values = scaler.fit_transform(closing_values)[...]predictions = scaler.inverse_transform(normalized_predictions)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 49\nRis an open sourceprogramming language with focus on better user friendlydata analysis, statistics and graphical modelsR is an implementation of S programming languageCreated by Ross Ihaka and Robert Gentleman Released in 1995R has been used primarily in academicsand research,but it is rapidly expanding into the enterprise market\u201cThe closer you are to statistics, research and data science,the more you might prefer R.\u201dStandard IDE is R StudioMain advantage: graphical capabilities for data visualization\n(Source: https://www.datacamp.com/community/tutorials/r-or-python-for-data-analysis)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Thank you for your attention",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 14\nDataCamp\nAccess (upon next week):\nYou will receive an invitation under \nfirstname.lastname@mailbox.tu-dresden.de\nAccount: \nFollow the link in the mail to create an account.\nIf you already worked with DataCamp in prior courses, you could \nalso sign in with your existent account.\nEither way make sure to use the @mailbox.tu-dresden.de \nemail."
        ],
        "generated": "Text mining refers to the analytical process for computer-assisted knowledge generation from text data. It involves the collection and preparation of texts, the exploitation of results, and the use of analysis techniques to evaluate and generate text mining results. The goal of text mining is to generate new knowledge that can be translated into action.",
        "ground_truth": "The term text mining refers to the analytical process for computer-assisted knowledge generation from text data."
    },
    {
        "query": "What are types of anomalies?",
        "retrieved": [
            "Anomaly Detection\nMethods",
            "IntroductionOverview\nAnomalous patterns are often referred to as anomalies, outliers, discordant observations, exceptions, aberrations, surprises, peculiarities orcontaminants in different application domainsWe will use the term anomalyMain reference: Chandola, V., Banerjee, A., & Kumar, V. (2009). Anomaly detection: A Survey. ACM Computing Surveys, 41(3), 1\u201358.",
            "Anomaly Detection\nIntroduction",
            "MethodsCriteria: Type of anomaly\nPoint Anomalies: -A single data object is considered to benot \u201enormal\u201c in relation to the rest of the data -Example: \u201eAmount spend\u201c in credit fraud is very high compared to usual behaviorContextual Anomalies:-A single data point is only anomalous in a certain context-The context in form of context variables sets the neighborhood and defines normal behavior-E.g.observed temperature is normal during winter but are anomalous in JuneContextual Anomaly",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 39\nStatistical methodsParametric methods: other methods\nRegression based:(1) Regression is estimated(2) for each data object the residual score resembles the anomaly scoreSome criteria used to detect anomalies in a regressions setting:\u2014AIC: anomalies influence regression results\u2014Robust regression: should be used to avoid anomaly influences \u00f0residuals for anomalies are considerably larger in this setting\u2014ARIMA/ARMA: detection of anomalies in a time series settingMixture distribution based: Two approaches -Different distributions for normal data and anomalies or mixed distribution for only the normal class",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 34\nClustering basedOverview\nIdea 1: Normal data instances belong to a cluster in the data, while anomalies do not belong to any cluster:Requires cluster method that does not put every data point into clustersE.g.: DBSCAN, ROCK, WaveCluster, FindOutIdea 2: Normal data instances lie close to their closest cluster centroid, while anomalies are far away from their closest cluster centroid:Commonused methods are SOM, K-means, Expectation MaximizationSemi-supervised approach can be used to improve resultsIdea 1 and 2 arenot working well when anomalies form clusters themselvesIdea 3: Normal data instances belong to large and dense clusters, while anomalies either belong to small or sparse clustersCommonly used: FindCBLOFCBLOF analogous to LOF captures cluster size as well as centroid distance based on clustering results",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 41\nStatistical methodsAdvantages\nIf the assumptionsregarding the underlying data distribution hold true, statistical techniques provide a statistically justifiable solution for anomaly detection.\nThe anomaly score provided by a statistical technique is associated with a confidence interval, which can be used as additional information while making a decisionregarding any test instance.\nIf the distribution estimation step is robustto anomalies in data, statistical techniques can operate in aunsupervised setting without any need for labeled training data.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 10\nMethodsCriteria: Nature of Input Data\nRecall that input data are attributes (variables) measured for data instances(or data objects), e.g.measuring weight and blood pressure (attributes) of several patients (data objects) in a hospital \nScale: Attributes can be measured on different scale levels (nominal, ordinal, interval, ratio) \u00f0different techniques for different scale levels\nRelationship between data instances: data objects can have different types of relationship to each other-Sequential-Spatial-Graph data\u00f0Those relationships can be useful to determine anomalies",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 17\nClassification basedOne-class classification\nFrom Wikipedia, the free encyclopediaIn machine learning, one-class classification, also known as unary classification, tries to identifyobjects of a specific class amongst all objects, by learning from a training set containing only the objects of that class. This is different from and more difficult than the traditional classification problem, which tries to distinguish betweentwo or more classes with the training set containing objects from all the classes. An example is the classification of the operational status of a nuclear plant as 'normal':In this scenario, there are (fortunately) few or no examples of catastrophic system states, only the statistics of normal operation are known. The term one-class classification was coined by Moya & Hush (1996) and many applications can be found in scientific literature, for example outlier detection, anomaly detection, novelty detection. Aimportant component of one-class classification is that it uses only samples from the assigned class, so that a representative sampling is not strictly required for non-target classes.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 24\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics\n2.1 Introduction to Segmentation\n2.2 Cluster types\n2.3 Distance measures\n2.4 Evaluation criteria \n2.5 Start heuristics",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 10\nSomeExamplesofData Science PrinciplesbyProvost & Fawcett (2013)\nSimilarity is one of the most important measures in Data ScienceMany ways and specifications to quantify similarity\nProblem of representation, also called \u201eoverfitting\u201c\n\u201cEntities that are similar with respect to known featuresor attributes often are similar with respect to unknown featuresor attributes.\u201d\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)\n\u201cIf you look too hard at a set of data, you will find something -but it might not generalize beyond the datayou\u2019re observing.\u201d",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 22\nAgenda\nContent structure:\n1. Introduction and Terms\n2. Basics of Segmentation \n3. Methods of Segmentation \n4. Association Analysis\n5. Text Mining \n6. Deep Learning \n7. Anomaly Detection\n8. Process Analytics",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 3\nAimsoftheclusteranalysis\n\u2015Segmentationorcluster analysis is used to group objects and/or characteristics into classes or groups, so that-between the elements of thesame classes as similar as possible,-between the elements of different classes the greatest possible dissimilarityis achieved.\u2015The clusters are not known beforehand.\u2015So-calledunsupervised learning methods are used, for example.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 20\nEvaluation criteria\nIf one has two different segmentations K1und K2, the question arises,which is more suitable.Criteria for the evaluation of segmentations\nA distinction is made between measures for evaluating the\u2015Heterogeneity of a class (intra-class dissimilarity) -heterogeneity indices\u2015Difference of two classes (interclass difference) -dissimilarity indices\u2015Quality of a segmentation (quality index) -quality indices",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 2\nRecap: Aims of the cluster analysis\nSegmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that\u2022between the elements of the same classes the greatest possible similarity,\u2022between the elements of different classes the greatest possible diversity is achieved",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 3\nAnalyzing Processes\nKraftMixing Center\nDistribution\nCenter\nRetailer A\nDistribution \nCenter\nSupplier\nDSDDistributionCenter\nRetail Store ARetail Store B\nMfg Plant\nHow many processes go through distribution centers?\nIs direct delivery from Mfg Plant less prone to errors?\nWhich retail store has less lost opportunities?\nHow many processes start with the supplier (VMI)?\nHow many resources are idle?How many processes are stuck?\nSAP (2008)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 2\nAssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 19\nDifferent Expectations\u2026\u2026 what people think I do \nWhat my friends think I \ndo\nWhat my mother thinks I \ndo\nWhat my boss thinks I do\nWhat I really doWhat I think I doWhat society thinks I do",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 25\nThe problemofqualityindices\n\u2015In general, the quality index falls as the number of classes increases. \u2015A conflict of objectives arises between\u2022as small a number of classes as possible and\u2022quality index as small as possible.Decision support: elbow criterionWith the help of this so-called criterion, the \"optimal\" choice of the number of classes can be made. The decision is made in favor of the number of classes s* with the quality b*, which is the same with \u2022a reduction in the number of classes sleads to a sharp increase in b \u2022an increase in the number of classes sleads only to a slight improvement in b.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 35\nImportance of Visualization\nWhy is data visualization so important?\u201cBecause of the way the human brain processes information, using charts or graphs to visualize large amounts of complex data is easier than poring over spreadsheets or reports. Data visualization is a quick, easy way to convey concepts in a universal manner \u2013and you can experiment with different scenarios by making slight adjustments.\u201d (SAS, 2017)\nAnother Example: Anscombe\u2019s Quartet4 data sets of 11 elementssame descriptive statistics for all 4 data sets\u2014mean of x = 9\u2014variance of x = 11\u2014mean of y = 7.50\u2014variance of y = 4.125\u2014correlation = 0.816\u2014linear regression line: y = 3.00 + 0.500x\n (Source: Anscombe, 1973)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 38\nLSTM-Concepts: Gates\nLSTM heavily uses gates in its architecureA gate is used to modify values in a vector to only let specific values or adapted values through.Sigmoid Gate: When using the Sigmoid activation function, the result is a vector of numbers between 0 and 1. When multiplying this vector pointwise with another vector, we can remove or deminish values in the other vector. 543\t\u00d700.251=013\t\nThese gates are used to \u201efilter\u201c values in vectors.LSTMs use 3 different gate layers to modify the internal state (following slides)\nSigmoid outputModified VectorInput"
        ],
        "generated": "The types of anomalies mentioned in the context are Point Anomalies and Contextual Anomalies.",
        "ground_truth": "Point Anomalies, Contextual Anomalies, Collective Anomalies."
    }
]