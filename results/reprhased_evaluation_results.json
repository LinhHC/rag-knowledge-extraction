[
    {
        "query": "What are the application domains of anomaly detection?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 9\nMethodsCriteria for anomaly detection problem definition\nThere is NO general approach that works for all application domainsDifferent problem definitionsdepending on some basic criteria:-Nature of data-Labels-Anomaly Type-OutputAnomaly Detection methods can be found in many research fields:-Machine Learning (Data Mining)-Statistics-Information Theory-Spectral Theory-\u2026",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 3\nIntroductionOverview\nDescription: Detections of patterns that do not conform to \u201enormal\u201c behavior\nApplication domains:-Fraud Detection (e.g., credit card fraud, tax fraud, etc.)-Intrusion Detection in cyber security-Fault Detection in safety critical systems-Military surveillance of enemies-\u2026Importance of anomalies: Anomalies often are indicators for situations that require critical decisionsExample: An anomalous pattern in network traffic could indicate a hacker attack",
            "Even though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation,",
            "Data Science: Advanced Analytics\nAnomaly Detection",
            "Anomaly Detection\nMethods"
        ],
        "generated": "The application domains of anomaly detection include fraud detection (e.g., credit card fraud, tax fraud), intrusion detection in cybersecurity, fault detection in safety-critical systems, military surveillance of enemies, and more.",
        "ground_truth": "- Fraud Detection (e.g., credit card fraud, tax fraud, etc.) - Intrusion Detection in cyber security - Fault Detection in safety critical systems - Military surveillance of enemies."
    },
    {
        "query": "What is anomaly detection?",
        "retrieved": [
            "anomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised\nanomaly detection techniques require a data set that has been labeled as \"normal\" and\n\"abnormal\"  and  involves  training  a  classifier  (the  key  difference  from  many  other\nstatistical  classification  problems  is  the  inherently  unbalanced  nature  of  outlier\ndetection).  Semi-supervised  anomaly  detection  techniques  construct  a  model",
            "Even though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation,",
            "Anomaly Detection\nMethods",
            "Anomaly Detection\nIntroduction",
            "Data Science: Advanced Analytics\nAnomaly Detection"
        ],
        "generated": "Anomaly detection is the process of detecting anomalies or outliers in a dataset, where anomalies are data points that deviate significantly from the majority of the data points. There are various techniques for anomaly detection, including supervised, unsupervised, and semi-supervised methods.",
        "ground_truth": "Detections of patterns that do not conform to 'normal' behavior."
    },
    {
        "query": "How many credits does this course give?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 12\nCourse Information \u2013\nextracts of the module guide \u201cDiplom Wirtschaftsinformatik\u201d\nCreditability:  \nMA-WW-WINF-0416b D-WW-WINF-0416b \nMaster: BWL, VWL, Wing, Winfo, Wip\u00e4d\nDiploma: Wing, Winfo\nCredit points: \n5\nAssessment:\n120min exam (ONYX-Exam \u2013 further information during the semester) \nAll information: in OPAL - https://bildungsportal.sachsen.de/opal/auth/RepositoryEntry/16864575517",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 15\nDataCamp\nYou can explore further courses and programming languages in the catalog. \nThese are the main dashboards for the course. You can view your assignments, your\nprogress and the progress of your fellow students.\nAssignments:\nYou can filter all \nyour assignments\nfor this course.\nFully completed\ntasks will be\ndisplayed as\ncompleted.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 13\nCourse structure\nLecture:\n\u2022 Will be provided on a weekly basis as video \nlectures on video campus Sachsen\n\u2022 first upload date: 19.04.2023\nExercises:\n\u2022 3 Virtual Exercises as MS Teams Call\n\u2022 free Python courses on DataCamp\nTrial exam: 30 min online (OPAL)\nExam:\n\u2022 120 min online (hybrid PC-Pool via OPAL)\u200b\n\u2022 Thrusday, August the 3-th.",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 10\nConcept of this course -> Flipped Classroom\nTraditional classroom:\nFrontal teaching of main topics\nStudents expected to deepen understanding by \nexercises on their own\nFlipped classroom:\nshift the classic explanation phases from frontal \nteaching to self-study\nIn depth understanding by working through exercise \ntogether with teaching staff",
            "(Source: SoongsilUniversity, 2016)"
        ],
        "generated": "This course gives 5 credits.",
        "ground_truth": "This course provides 5 academic credits."
    },
    {
        "query": "What are the different types of analytics?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 24\nDifferent Types of AnalyticsTaking responsibilities for dedicated analytical tasks\nDescriptive AnalyticsQuestion: \u201cWhat is happening right now/ what happened in the past?\u201d Summarizingcollected data from various sources and providing aggregated measures and visualizationsIncluding traditional business intelligence tools: e.g.reports, dashboards, querying, online analytical processing (OLAP)\nDiagnostic AnalyticsQuestion: \u201cWhy did/ does it happen?\u201dExplanatory empirical modeling based on statistical inference and causal hypotheses testing",
            "analytics techniques such as logistic regression methods, clustering methods, and\nclassification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,\nexplore, visualise, share and discover. The people who help organisations do this are data",
            "Data Science: Advanced Analytics \nProcess Analytics",
            "Predictive AnalyticsQuestion: \u201cWhat is likely to happen?\u201dDeveloping prediction models with high accuracy by using a large amount of historical data, detecting complexandnon-trivial relationshipsand providing predictions and equivalent probability scores on new unclassified observations\nPrescriptive AnalyticsQuestions: \u201cWhat should be done / why should it be done?\u201dMathematical techniques (e.g.optimization, simulation) that computationally determine a set of high-value alternative actions or decisions given a complex set of objectives, requirements and constraints",
            "Data Science: Advanced Analytics\nIntroduction"
        ],
        "generated": "The different types of analytics mentioned in the context are Descriptive Analytics, Diagnostic Analytics, Predictive Analytics, and Prescriptive Analytics.",
        "ground_truth": "Descriptive Analytics, Diagnostic Analytics, Predictive Analytics, Prescriptive Analytics"
    },
    {
        "query": "What is the A-priori algorithm?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 9\nA-priori AlgorithmIdea\nThe A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database.The algorithm searches for all rules that have a high confidencevalue. It must now be taken into account that the important confidence of a rule is also expressed by its support values. Thus applies: Let X be an item set from the population of all items I and X\u2018 \u00ccX, then: \nSupport values, in turn, represent frequencies of item sets in the population.",
            "-A-priori Algorithm-A-priori-Tid algorithm-A-priori-Hybrid Algorithm-AIS algorithmThe procedures have in common that they are often used as starting procedures in the data mining, since no assumptions are necessary to the connections of the data, which things could correlate e.g. (undirected data mining).\nNote: 100 itemsresultin generally(100 overk) item combinations.-2-itemsets: 4,950 combinations-3-itemsets: 161,700 combinations-5-itemsets: 75.287.520 combinations",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 10\nA-priori AlgorithmProcesssteps\nThe following steps are to be completed during rule generation using the A-priori algorithm.must be completed:Step 1: Compute the (frequent) item sets whose support values are at least equal to the minimum support (\u00e0frequent item set X ).\nStep 2: For each subset X' of a frequent item set X holds:\nFormation of all rules whose Confidence is at least equal to the minimum Confidence.\nsup( X )conf( (X X) X) sup( X X ')\n\u00a2\u00a2-\u00ae = -",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 13\nA-priori AlgorithmExample\u2013Part I\nDetermination of association rulesfor transaction data of a supermarket\nKunde Artikel\n1 Wein, Lachs, Baguette\n2 Wein, Lachs, Sahne\n3 Wein, K\u00e4se, \n4 Lachs, Baguette, Wein\n5 Wein, Lachs, Baguette, Sahne\n6 K\u00e4se\nArtikel\nTransaktion, die \nArtikel umfasst\nSupport des \nArtikels\nWein 1,2,3,4,5 5/6 = 83,3 %\nLachs 1,2,4,5 4/6 = 66,6 %\nBaguette 1,4,5 3/6 = 50,0 %\nSahne 2,5 2/6 = 33,3 %\nK\u00e4se 3,6 2/6 = 33,3 %\nn H n I n\n1 {{Wein }, { Lachs }, { Baguette }, { Sahne }, { K\u00e4se }} {{Wein }, { Lachs }, { Baguette }}",
            "AssociationAnalysis Remarks& applicationrecommendations\u2013Teil I\nProvided that frequent item sets with n elements exist, the A priori algorithm requires n iterations ( 1 MB shopping cart analyzable in seconds).Algorithm discovers thousands of rules.Visualizationor browsingis necessary:-Rules with very high support or confidence values are mostly already known.-The so called \"medium\" rulesare mainly interesting.\u00e0Thus, additional statistical key figures are necessary for the evaluation.Many external influencing factorsremain unconsidered, since transaction data do not include the following:-socio-economic status of buyers-time (time of day, day of week)-Advertising campaigns"
        ],
        "generated": "The A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database. It searches for all rules that have a high confidence value and is often used as a starting procedure in data mining as no assumptions are necessary about the connections of the data.",
        "ground_truth": "The A-priori algorithm is a classical technique for discovering frequent patterns and association rules in large datasets."
    },
    {
        "query": "What are types of anomalies?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 11\nMethodsCriteria: Type of anomaly\nPoint Anomalies: -A single data object is considered to benot \u201enormal\u201c in relation to the rest of the data -Example: \u201eAmount spend\u201c in credit fraud is very high compared to usual behaviorContextual Anomalies:-A single data point is only anomalous in a certain context-The context in form of context variables sets the neighborhood and defines normal behavior-E.g.observed temperature is normal during winter but are anomalous in JuneContextual Anomaly",
            "such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies\nare referred to as outliers, novelties, noise, deviations and exceptions.[73]",
            "Even though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation,",
            "Relationship between data instances: data objects can have different types of relationship to each other-Sequential-Spatial-Graph data\u00f0Those relationships can be useful to determine anomalies",
            "MethodsCriteria: Data labels and Output\nTo classifya data instance as normal or anomalous one can use labels:Labeling data is costly and expensiveGetting labels for all kinds of anomalous behavior is nearly impossibleNormal class easier to labelDepending on the availability of labeled data there are three approaches:Supervised anomaly detection:assumes labels for both classesSemi-supervised: only assumes labels for the normal classUnsupervised: does not assume labelsThe outputsof an anomaly detection method can be:Scores: Scores how unusual the anomaly is compared to normal; ranking of the data objects possibleLabels: Labels the data instance either anomalous or normal"
        ],
        "generated": "Based on the provided context, the types of anomalies mentioned are Point Anomalies and Contextual Anomalies.",
        "ground_truth": "Point Anomalies, Contextual Anomalies, Collective Anomalies."
    },
    {
        "query": "What types of layers are in CNN?",
        "retrieved": [
            "Our CNN Architecture contains multiple layer types:\u00a7Conv2D: CNN Layer with 32 filters, shape 3x3 with ReLU Layer appended\u00a7MaxPooling2D: Pooling layer with shape 3x3\u00a7Dropout: Randomly drop 20% of neurons to prevent overfitting\u00a7Flatten: Prepare filter results for classification\u00a7Dense: Fully connected layers for classificationfrom keras.models import Sequentialfrom keras.layers import Dense, Flatten, Dropoutfrom keras.layers import Conv2D, MaxPooling2Dmodel = Sequential()model.add(Conv2D(32, (3, 3), input_shape=(x_train.shape[1:]), activation='relu'))model.add(MaxPooling2D(pool_size=(2, 2)))model.add(Conv2D(32, (3, 3), activation='relu'))model.add(MaxPooling2D(pool_size=(2,",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 12\nConvolutional Neural Network: Overview\nStack layers to build a complete CNNOne type of layer is the previously mentioned \u201econvolutional layer\u201cIn total there are 4 types of layers:\u00a7Convolutional Layer (Extract features)\u00a7Pooling Layer (Reduce size)\u00a7ReLU Layer (Remove negative values \u00e0 disregard information about missing features)\u00a7Fully Connected Layer (Classify features)\nLECUN, YANN; BENGIO, YOSHUA: Convolutional Networks for Images, Speech, and Time-Series. In M. A. Arbib(Ed.),The handbook of brain theory and neural networksMIT Press (1995).\nConvolution",
            "Most modern deep learning models are based on multi-layered neural networks such as\nconvolutional  neural  networks  and  transformers,  although  they  can  also  include\npropositional  formulas  or  latent  variables  organized  layer-wise  in  deep  generative\nmodels such as the nodes in deep belief networks and deep Boltzmann machines.[7]\nFundamentally, deep learning refers to a class of machine learning algorithms in which\na hierarchy of layers is used to transform input data into a progressively more abstract\nand  composite  representation.  For  example,  in  an  image  recognition  model,  the  raw\ninput may be an image (represented as a tensor of pixels). The first representational",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 13\nExample to explain layers\nWe will take a look at the following imageQuestion: Is this an X or a 0?\nThe computer can only see the numbers representing the colorNote: This example only has one color channel (black or white) to keep it simple\nImages from: ROHRER, BRANDON: How Convolutional Neural Networks work. https://www.youtube.com/watch?v=FmpDIaiMIeA",
            "the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing the various outputs-Connection:\u00a7Each node is connected to the succeeding node (one direction only)\u00a7Each connection has a weight that need to be learned from the data"
        ],
        "generated": "The types of layers in a Convolutional Neural Network (CNN) are:\n1. Convolutional Layer (Extract features)\n2. Pooling Layer (Reduce size)\n3. ReLU Layer (Remove negative values)\n4. Fully Connected Layer (Classify features)",
        "ground_truth": "Convolution Layer, Pooling Layer, ReLu Layer, Fully Connected Layer."
    },
    {
        "query": "What are the challenges of text mining?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 10\nText mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff.",
            "The processing and analysis steps are integrated as functions in application systems.\nText data can be both internal and external to the company; in the context of data processing, one also speaks of unstructured data.The goal of text mining is to generate new knowledge to be translated into action.",
            "Text Mining in the Big Data EnvironmentThe amount of available texts increases extremely in Web 2.0 (keyword: user-generated content)Social networks, forums and blogs can be interesting sources for product improvements, marketing activities or opinion analysisText processing and analysis is very computationally intensive even for a few documentsBig Data technologies enable high-performance and scalable analysis systemsEx: Hadoop-based systemsDistributed File Systems (Hadoop Distributed File System, HDFS).Distributed execution framework MapReduce Implementation e.g. in Apache Tika",
            "Text mining methodsOther analysis methods\nText summarizationThe proceduresselectessential sentencesofa documenton thebasisofstatisticalkeyfiguresThe usercangraspthecorecontentofa documentmorequicklyInformation ExtractionThe proceduressearchdefinedpatternsin documentsand cantherebyconverttermsintoinformationHowever, todo so, theproceduresrequiremanuallycreatedtoolssuch asdictionariesMethod forthevisualizationofinterrelationships(informationvisualization)The methodsrepresentdocumentsortheirkeywordsin hierarchies, graphsornetworksThis enablestheusertonavigatethroughthedocumentsand easilygraspcontentorcontexts",
            "Text Mining\nProceduremodel: taskdefinition"
        ],
        "generated": "The challenges of text mining include very large amounts of (text) data, high dimensionality, \"noise\" in the data, understanding the results, texts not being intended for computer-based processing, and the complex and little standardized structure of texts. Additionally, language, morphology, syntax, and semantics strongly depend on the author and the target audience of the text.",
        "ground_truth": "Very large amounts of (text) data, High dimensionality, 'Noise' in the data, Understanding the results, Texts are usually not intended for computer-based processing."
    },
    {
        "query": "What types of statistics are there?",
        "retrieved": [
            "Statistics= teaching in dealing with quantitative information (= data)\u2022Descriptiveor InductiveDescriptive StatisticsTask: Data should be prepared and graphically displayed.\u2022Concentration of the underlying extensive database on a few meaningful measures.\u2022In extreme cases, it is possible that a single number characterizes the entire data setInductive statisticsSummary of all methods needed for rational decision making under uncertainty or risk.Task: The properties of the population are derived from the data of the sample.\u2022Basis of inductive statistics: probability theory\u2022Objective: The statistical methods of inductive statistics serve to make predictions (e.g., about risks).",
            "Statistical methodsOverview\nIdea: Normal data instances occur in high probability regions of a stochastic model, while anomalies occur in the low probability regions of the stochastic model.Parametric approaches: -The normal data is assumed to be generated from a probability distribution -The inverse of the probability of an observation to be generated from such a distribution is considered as anomaly score \u00f0small probability means high chance of anomaly-Statistical tests are widely usedNon-parametric methods:-No probability distribution is assumed a-priori-Insteadthe distribution form is estimated based on the data",
            "Statistical methodsParametric methods: Gaussian model\nGaussian assumption:Assumes a normal distribution to fit the dataParameters of the distribution are estimated based on data using statistical inference (e.g.MLE)The distance of a data object to the estimated mean is the anomaly scoreDifferent tests:Simple M\u2212Nrule: Every point that lies beyond 3 standard deviations is considered an anomalyBox-Plot-Rule: \u2014Every point k* IQR above Q3 or k*IQR below Q1 is considered  an outlier\u2014The boxplot therefore gives left bound (Min)and right bound (Max) thresholds for anomaliesUnivariate tests: Grubbs test, t-testMultivariate tests: Hotellingt\u00b2-test, Slippage detection, Rosner test, Dixon test",
            "Statistical methodsParametric methods: other methods\nRegression based:(1) Regression is estimated(2) for each data object the residual score resembles the anomaly scoreSome criteria used to detect anomalies in a regressions setting:\u2014AIC: anomalies influence regression results\u2014Robust regression: should be used to avoid anomaly influences \u00f0residuals for anomalies are considerably larger in this setting\u2014ARIMA/ARMA: detection of anomalies in a time series settingMixture distribution based: Two approaches -Different distributions for normal data and anomalies or mixed distribution for only the normal class",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 24\nDifferent Types of AnalyticsTaking responsibilities for dedicated analytical tasks\nDescriptive AnalyticsQuestion: \u201cWhat is happening right now/ what happened in the past?\u201d Summarizingcollected data from various sources and providing aggregated measures and visualizationsIncluding traditional business intelligence tools: e.g.reports, dashboards, querying, online analytical processing (OLAP)\nDiagnostic AnalyticsQuestion: \u201cWhy did/ does it happen?\u201dExplanatory empirical modeling based on statistical inference and causal hypotheses testing"
        ],
        "generated": "Based on the provided context, the types of statistics mentioned are Descriptive Statistics and Inductive Statistics.",
        "ground_truth": "Statistics can be categorized into Descriptive Statistics and Inferential Statistics."
    },
    {
        "query": "What is the definition of Machine Learning by Samuel (1959)?",
        "retrieved": [
            "\u201cMachine Learning: Field of study that gives computers the ability to learn without being explicitly programmed.\u201d (Samuel, 1959)\u201cA subspecialty of computer science (within a field historically called \u201cartificial intelligence\u201d) concerned with the design and development of algorithms that allow computers to evolve behaviors based on empirical data. A major focus of machine learning research is to automatically learn to recognize complex patterns and make intelligent decisions based on data.\u201d (Manyikaet al., 2011)Machine Learning explores the study and construction of algorithms that can learn from and make predictions on data. Such algorithms overcome following strictly static program",
            "framework for describing machine learning.\nThe term machine learning was coined in 1959 by Arthur Samuel, an IBM employee and\npioneer in the field of computer gaming and artificial intelligence.[8][9] The synonym\nself-teaching computers was also used in this time period.[10][11]",
            "Machine Learning\nMachine  learning  (ML)  is  a  field  of  study  in  artificial  intelligence  concerned  with  the\ndevelopment and study of statistical algorithms that can learn from data and generalize\nto  unseen  data,  and  thus  perform  tasks  without  explicit  instructions.[1]  Within  a\nsubdiscipline in machine learning, advances in the field of deep learning have allowed\nneural  networks,  a  class  of  statistical  algorithms,  to  surpass  many  previous  machine\nlearning approaches in performance.[2]\nML  finds  application  in  many  fields,  including  natural  language  processing,  computer",
            "Tom  M.  Mitchell  provided  a  widely  quoted,  more  formal  definition  of  the  algorithms\nstudied  in  the  machine  learning  field:  \"A  computer  program  is  said  to  learn  from\nexperience E with respect to some class of tasks T and performance measure P if its\nperformance at tasks in T, as measured by P,  improves with experience E.\"[18] This\ndefinition of the tasks in which machine learning is concerned offers a fundamentally\noperational definition rather than defining the field in cognitive terms. This follows Alan\nTuring's  proposal  in  his  paper  \"Computing  Machinery  and  Intelligence\",  in  which  the",
            "Although the earliest machine learning model was introduced in the 1950s when Arthur\nSamuel  invented  a  program  that  calculated  the  winning  chance  in  checkers  for  each\nside, the history of machine learning roots back to decades of human desire and effort\nto study human cognitive processes.[12] In 1949, Canadian psychologist Donald Hebb\npublished the book The Organization of Behavior, in which he introduced a theoretical\nneural structure formed by certain interactions among nerve cells.[13] Hebb's model of\nneurons  interacting  with  one  another  set  a  groundwork  for  how  AIs  and  machine"
        ],
        "generated": "The definition of Machine Learning by Samuel (1959) is: \"Field of study that gives computers the ability to learn without being explicitly programmed.\"",
        "ground_truth": "Machine learning is a field of AI that enables computers to learn and improve from experience without explicit programming."
    },
    {
        "query": "What are items regarding Association Analysis?",
        "retrieved": [
            "AssociationAnalysisComments on thesubjectoftransactions\nThe following applies to transactions in general:Transactions consist of item quantity and transaction time. Often, information on behavior over time is available in addition to the transactions.  -Market Basket analysis: Payment by credit card or customer card; -Delivery Providers: collection of customer information e.g. based on orders received.However, this information is not usedin classical association analysis, although the inclusion of this additional information can significantly increase the meaningfulness of the rules (\u00e0sequence analysis).",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 4\nAssociationAnalysisBasic Terms\nItemsare uninterpretable, discrete things or entities. The set of all items is denoted by I.An association rule A \u00e0B consists of a set of items A in the rule bodyand a set of items B in the rule head, where A and B must be disjoint.Each transaction tconsists of a set of items. The transactions considered in the association analysis are combined into a database D.A transaction t satisfies a rule A \u00e0B if (A\u00c8B) \u00cdt, i.e., if all items contained in the rule also occur in the transaction.\n/Acan'tbepartof BS",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 19\nAssociationAnalysisTaxonomies\nThe integration of taxonomies, i.e. systems, classes or orders over the items, can increase the usefulness of association rules.\nBenefit: Associations between commodity groups and products and commodity groups are also found; Support and Confidence tend to be higher as a result of grouping.Simultaneous inclusion of multiple independent taxonomies in the analysis.\nFrischprodukte\nMilchprodukte ...\nButter ...\nBackzutaten\nBackpulver Vanillinzucker Rum-Aroma ...\n...\n...\n...",
            "AssociationAnalysisOverview\nAssociation rules were first introduced in the area of market basket analysis with the aim of finding out which products are purchased together.The resulting publications \"If you buy diapers on Friday night, you buy beer!\" then first drew the attention of the general public to the possibilities of data mining in the 1990s.In the meantime, association rules are also increasingly used in other fields. Because they do not perform disjoint data decomposition as decision trees do, more interesting associationscan be uncovered; however, a large number of uninteresting associations can also be uncovered.",
            "AssociationAnalysis Remarks& applicationrecommendations\u2013Teil I\nProvided that frequent item sets with n elements exist, the A priori algorithm requires n iterations ( 1 MB shopping cart analyzable in seconds).Algorithm discovers thousands of rules.Visualizationor browsingis necessary:-Rules with very high support or confidence values are mostly already known.-The so called \"medium\" rulesare mainly interesting.\u00e0Thus, additional statistical key figures are necessary for the evaluation.Many external influencing factorsremain unconsidered, since transaction data do not include the following:-socio-economic status of buyers-time (time of day, day of week)-Advertising campaigns"
        ],
        "generated": "Items regarding Association Analysis are uninterpretable, discrete things or entities. The set of all items is denoted by I.",
        "ground_truth": "Items are uninterpretable, discrete things or entities."
    },
    {
        "query": "What is the \u03b1-algorithm?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 18\n\u03b1-algorithm\nThe \u03b1-algorithmis a basicalgorithm for discovering process models from event logsIt is less complex than other advanced algorithmsIt will not be sufficient for practical application\nIdea is to identify the relations between all pairs of tasks from the workflow log to construct a process model\nDumas et al. (2018), van der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 31\nProblems with the \u03b1-Algorithm\nShort loopsa\u2192b, b\u2192ais not always (a \u01c1b) Incompleteness andnoiseFor 10 concurrent tasks, we need 10! = 3,628,800 casesMissing tasks\n Dumas et al. (2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 27\n\u03b1-Algorithm Steps (2)\n5.Construct the asubsetby1.Eliminating a\u2192band a\u2192cif there exists some a\u2192(b#c)2.Eliminating b\u2192cand b\u2192dif there exists some (b#c)\u2192d\n6.Connect start and end events1.If there are multiple first tasks, then draw a start event leading to a split (XOR or AND) which connects to all first tasks; otherwise, directly connect the start event with theonly first task2.For each last task, add an end event and draw an arc from the task to the end event\nDumas et al. (2018)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 03.05.2023 Folie 9\nA-priori AlgorithmIdea\nThe A-priori algorithm is considered a classical method for the formation of association rules or for the efficient determination of all relevant relationships in a database.The algorithm searches for all rules that have a high confidencevalue. It must now be taken into account that the important confidence of a rule is also expressed by its support values. Thus applies: Let X be an item set from the population of all items I and X\u2018 \u00ccX, then: \nSupport values, in turn, represent frequencies of item sets in the population.",
            "-A-priori Algorithm-A-priori-Tid algorithm-A-priori-Hybrid Algorithm-AIS algorithmThe procedures have in common that they are often used as starting procedures in the data mining, since no assumptions are necessary to the connections of the data, which things could correlate e.g. (undirected data mining).\nNote: 100 itemsresultin generally(100 overk) item combinations.-2-itemsets: 4,950 combinations-3-itemsets: 161,700 combinations-5-itemsets: 75.287.520 combinations"
        ],
        "generated": "The \u03b1-algorithm is a basic algorithm for discovering process models from event logs. It is less complex than other advanced algorithms but may not be sufficient for practical application. The idea behind the \u03b1-algorithm is to identify the relations between all pairs of tasks from the workflow log to construct a process model.",
        "ground_truth": "Process models define structured workflows, outlining the sequence of activities needed to complete an IT or business project efficiently."
    },
    {
        "query": "What are process models in business informatics?",
        "retrieved": [
            "Process models in business informaticsProcess models specify the sequence in which certain activitiesshouldbe carried out or proceduresshouldbe used in order to successfully complete (IT) projects; this serves on the one hand to structuretasksand on the other hand to reduce complexity within these projects.Process models such as the KDD, SEMMA or CRISP-DM processstructure phases and tasks of the data mining processSources: Fil\u00df et al. (2005, p. 184; Gutzwiller (1994), p. 32;Jablonski (1997), p. 489f.; Mertens (2001), p. 498; Stahlknecht & Hasenkamp (2005), p. 215\nAdapted from Chapman et al. (2000), p. 13.",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 15\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 49\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 8\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 38\nProcess Analytics Questions\nWhat is the performanceof the process?\nWhat isthe actual process model?\nTo which extent are the rulesof the process model followed?"
        ],
        "generated": "Process models in business informatics specify the sequence in which certain activities should be carried out or procedures should be used in order to successfully complete (IT) projects. They serve to structure tasks and reduce complexity within these projects. Examples of process models include KDD, SEMMA, and CRISP-DM.",
        "ground_truth": "Process models define structured workflows, outlining the sequence of activities needed to complete an IT or business project efficiently."
    },
    {
        "query": "In what categories can Machine Learning tasks be classified?",
        "retrieved": [
            "Machine Learning tasks can be classified into three broad categories of learning problems:Supervised Learning:The algorithm is given training data which contains examples of the input vectors along with their correspondingtarget vectors as the \u201ccorrect answer\u201d and the goal is to learn a general rule/ model that maps inputs to outputs.Examples: classification, regressionUnsupervised Learning: Principle: No labels (i.e.target values) are given to the algorithm, leaving it on its own to find structure in its input. Unsupervised learning can be a goal by itself (discovering hidden patterns) or a means towards a supervised approach (feature learning).Examples: cluster analysis, dimensionality",
            "From Wikipedia, the free encyclopediaIn machine learning, one-class classification, also known as unary classification, tries to identifyobjects of a specific class amongst all objects, by learning from a training set containing only the objects of that class. This is different from and more difficult than the traditional classification problem, which tries to distinguish betweentwo or more classes with the training set containing objects from all the classes. An example is the classification of the operational status of a nuclear plant as 'normal':In this scenario, there are (fortunately) few or no examples of catastrophic system states, only the statistics of normal operation are known.",
            "polynomial time.\nMachine  learning  approaches  are  traditionally  divided  into  three  broad  categories,\nwhich  correspond  to  learning  paradigms,  depending  on  the  nature  of  the  \"signal\"  or\n\"feedback\" available to the learning system:\nAlthough each algorithm has advantages and limitations, no single algorithm works for\nall problems.[45][46][47]\nSupervised  learning  algorithms  build  a  mathematical  model  of  a  set  of  data  that\ncontains both the inputs and the desired outputs.[48] The data, known as training data,\nconsists of a set of training examples. Each training example has one or more inputs",
            "Turing's  proposal  in  his  paper  \"Computing  Machinery  and  Intelligence\",  in  which  the\nquestion \"Can machines think?\" is replaced with the question \"Can machines do what\nwe (as thinking entities) can do?\".[19]\nModern-day  machine  learning  has  two  objectives.   One  is  to  classify  data  based  on\nmodels which have been developed; the other purpose is to make predictions for future\noutcomes based on these models. A hypothetical algorithm specific to classifying data\nmay use computer vision of moles coupled with supervised learning in order to train it\nto  classify  the  cancerous  moles.  A  machine  learning  algorithm  for  stock  trading  may",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 28\nMachine Learning CategorizationDifferent types of learning problems"
        ],
        "generated": "Machine Learning tasks can be classified into three broad categories: Supervised Learning, Unsupervised Learning, and One-class classification.",
        "ground_truth": "Supervised Learning, Unsupervised Learning, Reinforcement Learning"
    },
    {
        "query": "Why is data visualization so important for Data Science?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 35\nImportance of Visualization\nWhy is data visualization so important?\u201cBecause of the way the human brain processes information, using charts or graphs to visualize large amounts of complex data is easier than poring over spreadsheets or reports. Data visualization is a quick, easy way to convey concepts in a universal manner \u2013and you can experiment with different scenarios by making slight adjustments.\u201d (SAS, 2017)",
            "analytics techniques such as logistic regression methods, clustering methods, and\nclassification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,\nexplore, visualise, share and discover. The people who help organisations do this are data",
            "Datascienceinvolvesprinciples,processes,andtechniquesforunderstandingphenomenaviathe(automated)analysisofdata.(\u2026)theultimategoalofdatascienceisimprovingdecisionmaking,asthisgenerallyisofparamountinteresttobusiness.(\u2026)Data-drivendecisionmakingreferstothepracticeofbasingdecisionsontheanalysisofdataratherthanpurelyonintuition.\n(Source: Provost& Fawcett, 2013: Data Science and its Relationship to Big Data and Data-Driven Decision Making)",
            "Structuring the Field:Understanding Data Science",
            "Structuring the Field:2) Data Science Concepts"
        ],
        "generated": "Data visualization is important for Data Science because it allows for the easier processing of large amounts of complex data. By using charts or graphs to visualize data, concepts can be conveyed in a universal manner, making it easier for individuals to understand and analyze the information. Additionally, data visualization allows for the exploration of different scenarios by making slight adjustments, enabling data scientists to gain insights and make informed decisions based on the visual representation of the data.",
        "ground_truth": "Data visualization is essential in Data Science because it simplifies complex datasets by using graphs and charts, making them easier to interpret."
    },
    {
        "query": "What is text mining?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 7\nDefinition of Text MiningUnderstanding of terms in the context of the lecture\nSources: Schieber & Hilbert (2014c), p. 13\nThe term text mining refers to the analytical process for computer-assisted knowledge generation from text data.\nFrom a process perspective, text mining includes both the collection and preparation of texts and the exploitation of the results.Analysis techniques are used to evaluate and generate the text mining results.\nThe processing and analysis steps are integrated as functions in application systems.",
            "The processing and analysis steps are integrated as functions in application systems.\nText data can be both internal and external to the company; in the context of data processing, one also speaks of unstructured data.The goal of text mining is to generate new knowledge to be translated into action.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 6\nDefinition of Text MiningUnderstanding of the term in the literature\nSources: Schieber & Hilbert (2014c), p. 13\nInformation extraction\n\u2022Extraction of passages from texts\u2022Annotation of these passages with attributes\u2022Ex: \u2022Recognition of companies and people\u2022Assignment of functions of a person in the company\u2022Source: Hotho et al. (2005), p. 45ff.\nAnalysis method\n\u2022Methods for computer-aided text analysis \u2022(semi-)automatic structuring of texts\u2022Ex:\u2022Text Clustering\u2022Text Categorization \u2022Sources: He (2013), p. 501; Heyer et al. (2006), p. 3.",
            "Text Mining\nProceduremodel: Text miningprocedure",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 10\nText mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff."
        ],
        "generated": "Text mining refers to the analytical process for computer-assisted knowledge generation from text data. It involves both the collection and preparation of texts, as well as the exploitation of the results using analysis techniques. The goal of text mining is to generate new knowledge that can be translated into action.",
        "ground_truth": "Text mining is the computational process of extracting meaningful insights and patterns from textual data."
    },
    {
        "query": "What is the definition of Deep Learning by Najafabadi et al. (2016)?",
        "retrieved": [
            "Machine Learning & Deep LearningDeep Learning as a new disruptive technology\nA special class of Machine Learning algorithms is Deep Learning.\u201cThe main concept in deep leaning algorithms is automating the extraction of representations(abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representation.\u201d(Najafabadi et al., 2016)\u201cThese algorithms are largely motivated by the field of artificial intelligence, which has the general goal of emulating the human brain\u2019s abilityto observe, analyze, learn, and make decisions, especially for extremely complex problems.\u201d (Najafabadi et al., 2016)\nhttps://blogs.nvidia.com",
            "Deep Learning\nDeep learning is a subset of machine learning that focuses on utilizing neural networks\nto  perform  tasks  such  as  classification,  regression,  and  representation  learning.  The\nfield  takes  inspiration  from  biological  neuroscience  and  is  centered  around  stacking\nartificial neurons into layers and \"training\" them to process data. The adjective \"deep\"\nrefers  to  the  use  of  multiple  layers  (ranging  from  three  to  several  hundred  or\nthousands) in the network. Methods used can be either supervised, semi-supervised or\nunsupervised.[2]\nSome common deep learning network architectures include fully connected networks,",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 30\nDeep LearningDeep neural network architectures\n\u201cDeep learning is a relatively new term, although it has existed prior to the recent dramatic uptick in online searches. Enjoying a surge in research and industry, due mainly to its incredible successes in a number ofdifferent areas, deep learning is the process of applying deep neural network technologies -that is, neural network architectures with multiple hidden layers of neurons-to solve problems.\u201d(KDnuggets, 2016)\n(Source: Chen & Lin, 2014)\n(Source: Chen & Lin, 2014)",
            "Most modern deep learning models are based on multi-layered neural networks such as\nconvolutional  neural  networks  and  transformers,  although  they  can  also  include\npropositional  formulas  or  latent  variables  organized  layer-wise  in  deep  generative\nmodels such as the nodes in deep belief networks and deep Boltzmann machines.[7]\nFundamentally, deep learning refers to a class of machine learning algorithms in which\na hierarchy of layers is used to transform input data into a progressively more abstract\nand  composite  representation.  For  example,  in  an  image  recognition  model,  the  raw\ninput may be an image (represented as a tensor of pixels). The first representational",
            "Deep  learning  is  part  of  state-of-the-art  systems  in  various  disciplines,  particularly\ncomputer  vision  and  automatic  speech  recognition  (ASR).  Results  on  commonly  used\nevaluation sets such as TIMIT (ASR) and MNIST (image classification), as well as a range\nof  large-vocabulary  speech  recognition  tasks  have  steadily  improved.[104][138]\nConvolutional neural networks were superseded for ASR by LSTM.[137][139][140][141]\nbut are more successful in computer vision.\nYoshua Bengio, Geoffrey Hinton and Yann LeCun were awarded the 2018 Turing Award\nfor \"conceptual and engineering breakthroughs that have made deep neural networks a\ncritical component of computing\".[142]"
        ],
        "generated": "The definition of Deep Learning by Najafabadi et al. (2016) is: \"The main concept in deep learning algorithms is automating the extraction of representations (abstractions) from the data. Deep learning algorithms use a huge amount of unsupervised data to automatically extract complex representation.\"",
        "ground_truth": "Deep learning is an advanced AI technique that allows computers to learn complex patterns by analyzing vast amounts of data with neural networks."
    },
    {
        "query": "What is segmentation or cluster analysis used for?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 2\nRecap: Aims of the cluster analysis\nSegmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that\u2022between the elements of the same classes the greatest possible similarity,\u2022between the elements of different classes the greatest possible diversity is achieved",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 3\nAimsoftheclusteranalysis\n\u2015Segmentationorcluster analysis is used to group objects and/or characteristics into classes or groups, so that-between the elements of thesame classes as similar as possible,-between the elements of different classes the greatest possible dissimilarityis achieved.\u2015The clusters are not known beforehand.\u2015So-calledunsupervised learning methods are used, for example.",
            "algorithms  identify  commonalities  in  the  data  and  react  based  on  the  presence  or\nabsence  of  such  commonalities  in  each  new  piece  of  data.  Central  applications  of\nunsupervised  machine  learning  include  clustering,  dimensionality  reduction,[7]  and\ndensity estimation.[52]\nCluster analysis is the assignment of a set of observations into subsets (called clusters)\nso  that  observations  within  the  same  cluster  are  similar  according  to  one  or  more",
            "analytics techniques such as logistic regression methods, clustering methods, and\nclassification methods to draw insights from data. These practitioners have deep\nunderstanding of the business domain and apply that effectively to analyse data and deliver\nthe outcomes in a business understandable intuitive manner through advanced data\nvisualization tools.\u201d\nSAS (2012) \"are hybrids of technologists and quantitative analysts.\"\nMicrosoft Website (2013) \u201cso companies need to do a lot with their data: gather, collate, store, transform, clean, analyse,\nexplore, visualise, share and discover. The people who help organisations do this are data",
            "Basics ofsegmentation\nCluster types"
        ],
        "generated": "Segmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that between the elements of the same classes the greatest possible similarity, and between the elements of different classes the greatest possible diversity is achieved.",
        "ground_truth": "Segmentation, also known as cluster analysis, is the process of grouping similar objects together while maximizing the distinction between different groups."
    },
    {
        "query": "What is data mining explained by Cabena et al. (1997)?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 21\nData MiningDefinition and context\n\u201eData Mining is the process of extracting previously unknown, valid, and actionable informationfrom large databases and then using the information to make crucial business decisions.\u201c(Cabena et al. 1997)\n\u201eData Mining, as we use the term, is the exploration and analysis, by automatic or semiautomatic means, of large quantities of data in order to discover meaningful patterns and rules.\u201c(Berry et al. 1997)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 20\nB) Data MiningThe searchforthedigital treasures\nData Mining \u2013A metaphor from the mining industryMining: The industry or activity of removing substances, such as coal, metal, gold or diamonds, from the ground by digging.\nhttp://djitz.com\nhttp://pinterest.com\nData Mining: the process of using special software to look at large amounts of computer data in order to find out useful information, for example what types of product a company's customers buy.\nhttps://dictionary.cambridge.org/de/worterbuch/englisch/mining",
            "significantly,  but  while  machine  learning  focuses  on  prediction,  based  on  known\nproperties  learned  from  the  training  data,  data  mining  focuses  on  the  discovery  of\n(previously)  unknown  properties  in  the  data  (this  is  the  analysis  step  of  knowledge\ndiscovery in databases). Data mining uses many machine learning methods, but with\ndifferent goals; on the other hand, machine learning also employs data mining methods\nas  \"unsupervised  learning\"  or  as  a  preprocessing  step  to  improve  learner  accuracy.\nMuch of the confusion between these two research communities (which do often have",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 5\nIntroductionDefinition and Data Mining context\nOne possible definition:\nIn the context of data mining:-A portion of the observed data is generated by an unknown, anomalous process-This process differs from the standard processUntil now: -Assumption of one process that generates the data-Data Mining models reflecting that processNow: Interesting new observations that indicate differing mechanism behind data",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 24.05.2023 Folie 10\nText mining challenges\nThe challenges of data mining also apply to text mining:Very large amounts of (text) dataHigh dimensionality \"Noise\" in the dataUnderstanding the resultsHowever, additional difficulties arise:Texts are usually not intended for computer-based processingReason: texts have a complex and little standardized structureLanguage, morphology, syntax and semantics strongly depend on the author himself and the target audience of the text\nSources: Hidalgo (2002), p. 13ff."
        ],
        "generated": "According to Cabena et al. (1997), data mining is defined as \"the process of extracting previously unknown, valid, and actionable information from large databases and then using the information to make crucial business decisions.\"",
        "ground_truth": "Data mining is the process of uncovering previously unknown, useful insights from large datasets to support decision-making."
    },
    {
        "query": "What are process mining challenges?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 7\nProcess Mining Challenges\nCorrelation challenge-Identify the case an event belongs toTimestamps challenge-Logging is often delayed until the system has idle time: sequential events with the same timestamp, logs from different Business Process Management Software (BPMS)Longevity challenge-Long running processes might be too slow for snapshot windowScoping challenge-IS does not directly produce event logs. Logs are synthesizedGranularity challenge-Abstraction of model might be different from logDumas et al. (2013, 2018)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 33\nChallenges in Process Mining\nfrequent behavior\ntrace in the log\nAll behavior (including noise)\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 35\nChallenges in Process Mining\nnon-fitting model\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 36\nChallenges in Process Mining\nUnderfitting Model\nvan der Aalst (2017)",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 37\nChallenges in Process Mining\nOverfitting Model\nvan der Aalst (2017)"
        ],
        "generated": "Process mining challenges include the correlation challenge, timestamps challenge, longevity challenge, scoping challenge, and granularity challenge. Other challenges mentioned include frequent behavior, non-fitting model, underfitting model, and overfitting model.",
        "ground_truth": "Correlation challenge, Timestamps challenge, longevity challenge, scoping challenge, granularity challenge."
    },
    {
        "query": "What are the four quality criteria?",
        "retrieved": [
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 28.06.2023 Folie 32\nFour Quality Criteria\nApproaches to fix these issues use\nFitness-ability to replaySimplicity (Occam's razor)-simplest model to explain behavior, is the best modelPrecision-degree of behavior allowed by the model, but not in the logs-do not underfitGeneralization-work with incomplete behavior-do not overfit Dumas et al. (2018)",
            "The problemofqualityindices\n\u2015In general, the quality index falls as the number of classes increases. \u2015A conflict of objectives arises between\u2022as small a number of classes as possible and\u2022quality index as small as possible.Decision support: elbow criterionWith the help of this so-called criterion, the \"optimal\" choice of the number of classes can be made. The decision is made in favor of the number of classes s* with the quality b*, which is the same with \u2022a reduction in the number of classes sleads to a sharp increase in b \u2022an increase in the number of classes sleads only to a slight improvement in b.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 20\nEvaluation criteria\nIf one has two different segmentations K1und K2, the question arises,which is more suitable.Criteria for the evaluation of segmentations\nA distinction is made between measures for evaluating the\u2015Heterogeneity of a class (intra-class dissimilarity) -heterogeneity indices\u2015Difference of two classes (interclass difference) -dissimilarity indices\u2015Quality of a segmentation (quality index) -quality indices",
            "Outcome evaluation \nIn this step, it is checked whether the initial question could be answered by the text mining process. Here are assessthe results from the upstream step of applying the analytical methods using quality criteria appropriate to the method, andMatch the results from the upstream step of applying the analysis procedures with the problem definitionIf the check is positive, the next process step is executed.If the test is negative, it must first be analyzed where improvements are needed (preparation, data analysis,...)and then the process must jump back to this point to be executed again with changed parameters or other procedures",
            "Basics ofsegmentation\nEvaluation criteria"
        ],
        "generated": "The four quality criteria mentioned in the context are:\n1. Fitness-ability to replay\n2. Simplicity (Occam's razor)-simplest model to explain behavior, is the best model\n3. Precision-degree of behavior allowed by the model, but not in the logs-do not underfit\n4. Generalization-work with incomplete behavior-do not overfit",
        "ground_truth": "Fitness, Simplicity, Precision, Generalization."
    },
    {
        "query": "What are anomaly detection methods?",
        "retrieved": [
            "anomaly detection techniques detect anomalies in an unlabeled test data set under the\nassumption that the majority of the instances in the data set are normal, by looking for\ninstances  that  seem  to  fit  the  least  to  the  remainder  of  the  data  set.  Supervised\nanomaly detection techniques require a data set that has been labeled as \"normal\" and\n\"abnormal\"  and  involves  training  a  classifier  (the  key  difference  from  many  other\nstatistical  classification  problems  is  the  inherently  unbalanced  nature  of  outlier\ndetection).  Semi-supervised  anomaly  detection  techniques  construct  a  model",
            "Even though there exist several types of multivariate anomalies, most of the  approaches are using pointanomaliesas an assumption.Each of the large number of anomaly detection techniques have their unique strengths and weaknesses \u00f0situation basedapplication.Anomaly detection techniques typically assume that anomalies in data are rare when compared to normal instances \u00f0not always the case (e.g.anomalous virus traffic is more frequent).Every anomaly detection method has an idea in form of assumptions behind it \u00f0this can be used to check the fitness of that approach with regard toa specific topic.Most of the methods are commonly known methods like SVM, Clustering, Kernel density estimation,",
            "Anomaly Detection\nMethods",
            "Anomaly Detection\nIntroduction",
            "Data Science: Advanced Analytics\nAnomaly Detection"
        ],
        "generated": "Anomaly detection methods are techniques used to detect anomalies in data sets, with approaches such as supervised, semi-supervised, and unsupervised methods. These methods typically assume that anomalies are rare compared to normal instances and involve training classifiers to identify abnormal instances. Some commonly known anomaly detection methods include SVM, clustering, and kernel density estimation.",
        "ground_truth": "Classification based, neighbor based, clustering based, statistical methods, information theory based, spectral theory based."
    },
    {
        "query": "What is Agglomerative Clustering?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 10\nHierarchicalClustering Methods\nSegmentation methods that construct a sequence of partitions on the basis ofa set of objects N.\nAgglomerative ClusteringEach object initially represents a cluster of its own. Then clusters are successively merged until the desired cluster structure is obtained.\nDiversiveClusteringAll objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 3\nClustering Methods\nPartitionalClustering K-Means& K-MedoidsFor n objects or data tuples, a partitioning method constructs k partitions of the data, where each partition represents a cluster k <= n.\nHierarchicalClustering Agglomerative, DivisiveGroupingdata objects into a tree (dendrogram) of clusters\nDensity-BasedClustering DBSCANGroupingdatatuplesalongdensity-connectedpoints.\nGrid-BasedClustering STING, WaveCluster& CLIQUEMethoduses a multi-resolution grid data structure. E.g.spatial area is divided into rectangular cells (STING)",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 6\nSubdivision ofclusterapproachesAgglomerativeand single-modal methods\nFurthermore, one still distinguishes: \u2015Agglomerativeand divisive methods. The former start from one-element classes and combine elements into classes step by step. Divisive methods,on the other hand, start from an initial decomposition which is refined (i.e., divided) step by step. \u2015Single-modal methods that group objects or features into classes, and dual-modalmethods that simultaneously classify objects and features of a data matrix.",
            "In unsupervised machine learning, k-means clustering can be utilized to compress data\nby  grouping  similar  data  points  into  clusters.  This  technique  simplifies  handling\nextensive datasets that lack predefined labels and finds widespread use in fields such\nas image compression.[31]\nData  compression  aims  to  reduce  the  size  of  data  files,  enhancing  storage  efficiency\nand  speeding  up  data  transmission.  K-means  clustering,  an  unsupervised  machine\nlearning  algorithm,  is  employed  to  partition  a  dataset  into  a  specified  number  of\nclusters,  k,  each  represented  by  the  centroid  of  its  points.  This  process  condenses",
            "Basics ofsegmentation\nCluster types"
        ],
        "generated": "Agglomerative Clustering is a segmentation method that starts with each object representing a cluster of its own and then successively merges clusters until the desired cluster structure is obtained.",
        "ground_truth": "Each object initially represents a cluster of its own. Then clusters are successively merged until the desired cluster structure is obtained."
    },
    {
        "query": "What is a hierarchy regarding segmentation?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 9\nHierarchicalsegmentationExample\nA hierarchy is a union of disjoint segmentations, i.e., a sequence of disjoint segmentations for one class, two classes, ..., n classes. An overlap of the classes is excluded.K= { {1}, ..., {5}, {1,2,3}, {4,5}, {1,2,3,4,5} }\"Union of decompositions\"\n1\n 2\n 3\n 4\n 5\n1 2 3 4 5\n1 2 3 4 5",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 10\nQuasi-hierarchicalsegmentationExample\nA quasi-hierarchy is a union of non-disjoint segmentations, i.e., a sequence of non-disjoint segmentations for one class, two classes, ..., n classes. An overlap of classes is not excluded. Furthermore, it holds that the union of all real subsets of a class K yields just K again.K= { {1}, ..., {5}, {1,2,3} {2,4,5}, {1,2,3,4,5} }\n1 2 3 4 5\n1 2 3 4 5\n1\n 2\n 3\n 4\n 5\n2.",
            "\u2015Hierarchicalsegmentation methods are characterized by the fact that a cluster located at a higher fusion level completely contains the corresponding clusters located at a lower level. \u2015Non-hierarchical methods arebased on optimization methods that estimate class membership or attempt to iteratively improve classification quality by swapping elements between classes. \u2015Furthermore, a distinction is made between sharpand fuzzy segmentations. In the sharp approach, each object -if assigned to at least one class -is uniquely assigned to the corresponding class. In the fuzzy approach, there is no clear assignment to a class. Instead, share values are assigned that determine the degree to which",
            "HierarchicalClustering Methods\nforSegmentation",
            "Basics ofSegmentation\nIntroduction"
        ],
        "generated": "A hierarchy regarding segmentation is a union of disjoint segmentations, which means it is a sequence of disjoint segmentations for one class, two classes, ..., n classes, where an overlap of the classes is excluded.",
        "ground_truth": "Segmentation, also known as cluster analysis, is the process of grouping similar objects together while maximizing the distinction between different groups."
    },
    {
        "query": "What type of layers are in ANN?",
        "retrieved": [
            "Artificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in the input layer, you have as many nodes as input varibales + a constant (=bias)\u00a7Hidden units: Nodes in the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing",
            "Artificial Neural Networks (ANN)Recap: Example Network descriptionStructure:\u00a7An input layer with 3 input units\u00a7A hidden layer with 4 hidden units\u00a7An output layer with 2 output unitsConnections and weights:\u00a7Every unit of a layer is connected to every unit of the following layer\u00a7Those connections are not all of the same strength, instead they are weighted\u00a7Those weights are the parameter of an ANN model and need to be learnedFeed forward run:\u00a7Once the weights are learned, a new input vector can be fed into the ANN and will be propagated through the net until an output is generated\u00a7Every unit (except the input units) are calculated by applying a function (mostly sigmoid or tanh) to the weighted",
            "crosses that threshold. Typically, artificial neurons are aggregated into layers. Different\nlayers  may  perform  different  kinds  of  transformations  on  their  inputs.  Signals  travel\nfrom the first layer (the input layer) to the last layer (the output layer), possibly after\ntraversing the layers multiple times.\nThe original goal of the ANN approach was to solve problems in the same way that a\nhuman brain would. However, over time, attention moved to performing specific tasks,\nleading  to  deviations  from  biology.  Artificial  neural  networks  have  been  used  on  a\nvariety  of  tasks,  including  computer  vision,  speech  recognition,  machine  translation,",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 14.06.2023 Folie 4\nExample ANN 1 hidden layer, 3 input nodes, 4 hidden nodes, 2 output nodes\nArtificial Neural Networks (ANN)Recap: Classic ANN architecture and example calculation",
            "systems  \"learn\"  to  perform  tasks  by  considering  examples,  generally  without  being\nprogrammed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"artificial\nneurons\", which loosely model the neurons in a biological brain. Each connection, like\nthe  synapses  in  a  biological  brain,  can  transmit  information,  a  \"signal\",  from  one\nartificial neuron to another. An artificial neuron that receives a signal can process it and\nthen  signal  additional  artificial  neurons  connected  to  it.  In  common  ANN\nimplementations, the signal at a connection between artificial neurons is a real number,"
        ],
        "generated": "The types of layers in an Artificial Neural Network (ANN) are Input Layer, Hidden Layer(s), and Output Layer.",
        "ground_truth": "Input Layer, Hidden Layer, Output Layer."
    },
    {
        "query": "What is the definition of a data scientist from Davenport & Patil (2012)?",
        "retrieved": [
            "intelligence, statistics, databases, and optimization, along with a deep understanding of the\ncraft of problem formulation to engineer effective solutions.\u201d\nDavenport & Patil (2012) \u201cthe people who understand how to fish out answers to important business questions from\ntoday\u2019s tsunami of unstructured information.\u201d\nMohanty et al. (2013) \u201cthe practitioners of the analytics models solving business problems. They incorporate\nadvanced analytical approaches using sophisticated analytics and data visualization tools to\ndiscover patterns in data. In many cases, these practitioners work with well-established\nanalytics techniques such as logistic regression methods, clustering methods, and",
            "Chair of Business Information Systems, esp. Intelligent Systems and Services\nProf. Dr. Alfred Benedikt Brendel\nDresden | 12.04.2023\nFolie 20\nSome Definitions\u2026 \u2026 collected by Chatfield et al. (2014)\nSource Definition: Data scientists are \u2026\nGranville (2014) \u201cnot statisticians, nor data analysts, nor computer scientists, nor software engineers, nor\nbusiness analysts. They have some knowledge in each of these areas but also some outside\nof these areas.\u201d\nDhar (2013) \u201crequires an integrated skill set spanning mathematics, machine learning, artificial\nintelligence, statistics, databases, and optimization, along with a deep understanding of the",
            "explore, visualise, share and discover. The people who help organisations do this are data\nscientists. They turn data into products, insights and stories by adding value to raw\ninformation.\u201d",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 19.04.2023 Folie 5\nA Definition of Data Scienceby Provost & Fawcett (2013)\nTo understand Data Science, it requires to understand the 1) principles, 2) concepts, 3) techniques, 4) technologies and5) processes behind it!",
            "Data Science: Advanced Analytics\nIntroduction"
        ],
        "generated": "The definition of a data scientist from Davenport & Patil (2012) is \"the people who understand how to fish out answers to important business questions from today\u2019s tsunami of unstructured information.\"",
        "ground_truth": "A data scientist is someone who extracts insights from vast amounts of unstructured data to answer critical business questions."
    },
    {
        "query": "What is Diversive Clustering?",
        "retrieved": [
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 10\nHierarchicalClustering Methods\nSegmentation methods that construct a sequence of partitions on the basis ofa set of objects N.\nAgglomerative ClusteringEach object initially represents a cluster of its own. Then clusters are successively merged until the desired cluster structure is obtained.\nDiversiveClusteringAll objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained.",
            "Chair ofBusiness Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 26.04.2023 Folie 2\nRecap: Aims of the cluster analysis\nSegmentation or cluster analysis is used to group objects and/or characteristics into classes or groups so that\u2022between the elements of the same classes the greatest possible similarity,\u2022between the elements of different classes the greatest possible diversity is achieved",
            "algorithms  identify  commonalities  in  the  data  and  react  based  on  the  presence  or\nabsence  of  such  commonalities  in  each  new  piece  of  data.  Central  applications  of\nunsupervised  machine  learning  include  clustering,  dimensionality  reduction,[7]  and\ndensity estimation.[52]\nCluster analysis is the assignment of a set of observations into subsets (called clusters)\nso  that  observations  within  the  same  cluster  are  similar  according  to  one  or  more",
            "Chair of Business Information Systems, esp. Intelligent Systems and ServicesProf. Dr. Alfred Benedikt BrendelDresden | 21.06.2023 Folie 35\nClustering basedAdvantages\nClustering based techniques can operate in an unsupervised mode.Such techniques can often be adapted to other complex data types by simply plugging in a clustering algorithm that can handle the particular datatype.The testing phase for clustering basedtechniques is fast since the number of clusters against which every test instance needs to be compared is a small constant.",
            "Basics ofsegmentation\nCluster types"
        ],
        "generated": "Diversive Clustering is a segmentation method where all objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained.",
        "ground_truth": "All objects initially belong to one cluster. Then the cluster is divided into sub-clusters, which are successively divided into their own sub-clusters. This process continues until the desired cluster structure is obtained."
    },
    {
        "query": "What type of units are in ANN?",
        "retrieved": [
            "Artificial Neural Networks (ANN)Recap: Example Network descriptionStructure:\u00a7An input layer with 3 input units\u00a7A hidden layer with 4 hidden units\u00a7An output layer with 2 output unitsConnections and weights:\u00a7Every unit of a layer is connected to every unit of the following layer\u00a7Those connections are not all of the same strength, instead they are weighted\u00a7Those weights are the parameter of an ANN model and need to be learnedFeed forward run:\u00a7Once the weights are learned, a new input vector can be fed into the ANN and will be propagated through the net until an output is generated\u00a7Every unit (except the input units) are calculated by applying a function (mostly sigmoid or tanh) to the weighted",
            "systems  \"learn\"  to  perform  tasks  by  considering  examples,  generally  without  being\nprogrammed with any task-specific rules.\nAn ANN is a model based on a collection of connected units or nodes called \"artificial\nneurons\", which loosely model the neurons in a biological brain. Each connection, like\nthe  synapses  in  a  biological  brain,  can  transmit  information,  a  \"signal\",  from  one\nartificial neuron to another. An artificial neuron that receives a signal can process it and\nthen  signal  additional  artificial  neurons  connected  to  it.  In  common  ANN\nimplementations, the signal at a connection between artificial neurons is a real number,",
            "Artificial Neural Networks (ANN)Idea & Design of ANNIdea\u00a7Introduce hidden layers that act as artificial features that help to model the data better \u00a7You can think of the layers as new variables calculated from the input or previous   hidden unitsElements-Layers:\u00a7Input Layer: the features you want to use for prediction go in here\u00a7Hidden Layer(s): computational units creating artificial features\u00a7Output Layer: puts out prediction based on computations in hidden layer-Units:\u00a7Input units: Nodes in the input layer, you have as many nodes as input varibales + a constant (=bias)\u00a7Hidden units: Nodes in the various hidden layer, can be freely chosen to fit the problem\u00a7Output units: Nodes representing",
            "learn  (progressively  improve  their  ability)  to  do  tasks  by  considering  examples,\ngenerally without task-specific programming. For example, in image recognition, they\nmight learn to identify images that contain cats by analyzing example images that have\nbeen manually labeled as \"cat\" or \"no cat\" and using the analytic results to identify cats\nin other images. They have found most use in applications difficult to express with a\ntraditional computer algorithm using rule-based programming.\nAn ANN is based on a collection of connected units called artificial neurons, (analogous\nto biological neurons in a biological brain). Each connection (synapse) between neurons",
            "critical component of computing\".[142]\nArtificial  neural  networks  (ANNs)  or  connectionist  systems  are  computing  systems\ninspired by the biological neural networks that constitute animal brains. Such systems"
        ],
        "generated": "The type of units in an Artificial Neural Network (ANN) are input units, hidden units, and output units.",
        "ground_truth": "Input Units, Hidden Units, Output Units."
    }
]