# **RAG-Based Exam Generator** ğŸ“šğŸ¤–  

This project implements a **Retrieval-Augmented Generation (RAG) pipeline** to extract learning content from **PDF documents** and generate structured multiple-choice questions  using **LLMs**. It supports **query expansion**, **document retrieval**, **reranking**, and **automated question generation**.

---

## **ğŸš€ Installation & Setup**  

### **1ï¸âƒ£ Create a Virtual Environment**  
- Run the following command to create a virtual environment:  

    ```bash
    python -m venv venv
    ```

- Activate the environment:  
    - **Windows (CMD / PowerShell):**  
        ```bash
        venv\Scripts\activate
        ```
    - **MacOS/Linux:**  
        ```bash
        source venv/bin/activate
        ```

---

### **2ï¸âƒ£ Install Dependencies**  
Once the virtual environment is active, install the required dependencies: 

```bash
pip install -r requirements.txt
```

### **3ï¸âƒ£ Configure API Keys**  
Create a .env file in the project root directory and add the following: 

```env
OPENAI_API_KEY = [ENTER YOUR OPENAI API KEY HERE]
LANGCHAIN_API_KEY = [ENTER YOUR LANGCHAIN API KEY HERE]
```
This ensures secure authentication with OpenAI and LangChain APIs.

### **4ï¸âƒ£ Insert Data into the /data Folder**  
Place your PDF lecture slides or any educational materials into the /data directory. The system will automatically process these files.
Example file structure:
```kotlin
ğŸ“‚ project_root/
 â”£ ğŸ“‚ data/
 â”ƒ â”£ ğŸ“„ lecture1.pdf
 â”ƒ â”£ ğŸ“„ lecture2.pdf
 â”ƒ â”— ğŸ“„ my_notes.pdf
```

### **5ï¸âƒ£ Run the Main Pipeline**  
To start the exam generation process, execute:
```bash
python src/main.py
```
## **ğŸ›  Project Structure**  
```graphql
ğŸ“‚ project_root/
 â”£ ğŸ“‚ data/                   # PDFs for content extraction
 â”£ ğŸ“‚ evaluation/             # Evaluation results and metrics
 â”£ ğŸ“‚ generated_exams/        # Output MCQ files (JSON format)
 â”£ ğŸ“‚ src/                    # Source code
 â”ƒ â”£ ğŸ“‚ chroma_cache/        # Cached vector embeddings (ignored in Git)
 â”ƒ â”£ ğŸ“œ evaluation.py         # LLM-based exam evaluation
 â”ƒ â”£ ğŸ“œ rag_pipeline.py       # Main retrieval-augmented pipeline
 â”ƒ â”— ğŸ“œ main.py               # Entry point script
 â”£ ğŸ“œ .gitignore              # Files and folders ignored in version control
 â”£ ğŸ“œ LICENSE                 # Project licensing
 â”£ ğŸ“œ README.md               # Documentation (this file)
 â”— ğŸ“œ requirements.txt         # List of dependencies

```

## **ğŸ“Š Output Format**  
The generated exams are saved as JSON files in /generated_exams/, structured as follows:
```json
[
  {
    "Question_ID": 1,
    "Question": "What is the main goal of Machine Learning according to Mitchell (1997)?",
    "Answer_Options": {
      "A": "To create static program instructions",
      "B": "To generalize experience to improve performance",
      "C": "To follow empirical data without learning",
      "D": "To rely solely on supervised learning"
    },
    "Correct_Answer": { "B": "To generalize experience to improve performance" },
    "Source": "lecture1.pdf"
  }
]

```

## **ğŸ“œ License**  
This project is open-source under the Apache 2.0 License.
